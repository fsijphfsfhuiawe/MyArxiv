<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-16T00:00:00Z">2024-10-16</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context is Key(NMF): Modelling Topical Information Dynamics in Chinese
  Diaspora Media 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ross Deans Kristensen-McLachlan, Rebecca M. M. Hicke, Márton Kardos, Mette Thunø
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Does the People's Republic of China (PRC) interfere with European elections
through ethnic Chinese diaspora media? This question forms the basis of an
ongoing research project exploring how PRC narratives about European elections
are represented in Chinese diaspora media, and thus the objectives of PRC news
media manipulation. In order to study diaspora media efficiently and at scale,
it is necessary to use techniques derived from quantitative text analysis, such
as topic modelling. In this paper, we present a pipeline for studying
information dynamics in Chinese media. Firstly, we present KeyNMF, a new
approach to static and dynamic topic modelling using transformer-based
contextual embedding models. We provide benchmark evaluations to demonstrate
that our approach is competitive on a number of Chinese datasets and metrics.
Secondly, we integrate KeyNMF with existing methods for describing information
dynamics in complex systems. We apply this pipeline to data from five news
sites, focusing on the period of time leading up to the 2024 European
parliamentary elections. Our methods and results demonstrate the effectiveness
of KeyNMF for studying information dynamics in Chinese media and lay groundwork
for further work addressing the broader research questions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 2024 Computational Humanities Research Conference
  (CHR)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Chunking: Learning Efficient Text Segmentation via Logical
  Perception 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12788v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12788v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihao Zhao, Zhiyuan Ji, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG), while serving as a viable complement to
large language models (LLMs), often overlooks the crucial aspect of text
chunking within its pipeline, which impacts the quality of knowledge-intensive
tasks. This paper introduces the concept of Meta-Chunking, which refers to a
granularity between sentences and paragraphs, consisting of a collection of
sentences within a paragraph that have deep linguistic logical connections. To
implement Meta-Chunking, we designed two strategies based on LLMs: Margin
Sampling Chunking and Perplexity Chunking. The former employs LLMs to perform
binary classification on whether consecutive sentences need to be segmented,
making decisions based on the probability difference obtained from margin
sampling. The latter precisely identifies text chunk boundaries by analyzing
the characteristics of perplexity distribution. Additionally, considering the
inherent complexity of different texts, we propose a strategy that combines
Meta-Chunking with dynamic merging to achieve a balance between fine-grained
and coarse-grained text chunking. Experiments conducted on eleven datasets
demonstrate that Meta-Chunking can more efficiently improve the performance of
single-hop and multi-hop question answering based on RAG. For instance, on the
2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only
consuming 45.8% of the time. Our code is available at
https://github.com/IAAR-Shanghai/Meta-Chunking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ JudgeBench: A Benchmark for Evaluating LLM-based Judges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sijun Tan, Siyuan Zhuang, Kyle Montgomery, William Y. Tang, Alejandro Cuadron, Chenguang Wang, Raluca Ada Popa, Ion Stoica
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based judges have emerged as a scalable alternative to human evaluation
and are increasingly used to assess, compare, and improve models. However, the
reliability of LLM-based judges themselves is rarely scrutinized. As LLMs
become more advanced, their responses grow more sophisticated, requiring
stronger judges to evaluate them. Existing benchmarks primarily focus on a
judge's alignment with human preferences, but often fail to account for more
challenging tasks where crowdsourced human preference is a poor indicator of
factual and logical correctness. To address this, we propose a novel evaluation
framework to objectively evaluate LLM-based judges. Based on this framework, we
propose JudgeBench, a benchmark for evaluating LLM-based judges on challenging
response pairs spanning knowledge, reasoning, math, and coding. JudgeBench
leverages a novel pipeline for converting existing difficult datasets into
challenging response pairs with preference labels reflecting objective
correctness. Our comprehensive evaluation on a collection of prompted judges,
fine-tuned judges, multi-agent judges, and reward models shows that JudgeBench
poses a significantly greater challenge than previous benchmarks, with many
strong models (e.g., GPT-4o) performing just slightly better than random
guessing. Overall, JudgeBench offers a reliable platform for assessing
increasingly advanced LLM-based judges. Data and code are available at
https://github.com/ScalerLab/JudgeBench .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-Context Learning Enables Robot Action Prediction in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yida Yin, Zekai Wang, Yuvan Sharma, Dantong Niu, Trevor Darrell, Roei Herzig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Large Language Models (LLMs) have achieved remarkable success using
in-context learning (ICL) in the language domain. However, leveraging the ICL
capabilities within LLMs to directly predict robot actions remains largely
unexplored. In this paper, we introduce RoboPrompt, a framework that enables
off-the-shelf text-only LLMs to directly predict robot actions through ICL
without training. Our approach first heuristically identifies keyframes that
capture important moments from an episode. Next, we extract end-effector
actions from these keyframes as well as the estimated initial object poses, and
both are converted into textual descriptions. Finally, we construct a
structured template to form ICL demonstrations from these textual descriptions
and a task instruction. This enables an LLM to directly predict robot actions
at test time. Through extensive experiments and analysis, RoboPrompt shows
stronger performance over zero-shot and ICL baselines in simulated and
real-world settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned
  Concepts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12777v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12777v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid progress of diffusion-based content generation, significant
efforts are being made to unlearn harmful or copyrighted concepts from
pretrained diffusion models (DMs) to prevent potential model misuse. However,
it is observed that even when DMs are properly unlearned before release,
malicious finetuning can compromise this process, causing DMs to relearn the
unlearned concepts. This occurs partly because certain benign concepts (e.g.,
"skin") retained in DMs are related to the unlearned ones (e.g., "nudity"),
facilitating their relearning via finetuning. To address this, we propose
meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an
unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes
malicious finetuning on unlearned concepts, the related benign concepts
retained within it will be triggered to self-destruct, hindering the relearning
of unlearned concepts. Our meta-unlearning framework is compatible with most
existing unlearning methods, requiring only the addition of an
easy-to-implement meta objective. We validate our approach through empirical
experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4
and SDXL), supported by extensive ablation studies. Our code is available at
https://github.com/sail-sg/Meta-Unlearning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Identifying Task Groupings for Multi-Task Learning Using Pointwise
  V-Usable Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12774v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12774v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The success of multi-task learning can depend heavily on which tasks are
grouped together. Naively grouping all tasks or a random set of tasks can
result in negative transfer, with the multi-task models performing worse than
single-task models. Though many efforts have been made to identify task
groupings and to measure the relatedness among different tasks, it remains a
challenging research topic to define a metric to identify the best task
grouping out of a pool of many potential task combinations. We propose a metric
of task relatedness based on task difficulty measured by pointwise V-usable
information (PVI). PVI is a recently proposed metric to estimate how much
usable information a dataset contains given a model. We hypothesize that tasks
with not statistically different PVI estimates are similar enough to benefit
from the joint learning process. We conduct comprehensive experiments to
evaluate the feasibility of this metric for task grouping on 15 NLP datasets in
the general, biomedical, and clinical domains. We compare the results of the
joint learners against single learners, existing baseline methods, and recent
large language models, including Llama 2 and GPT-4. The results show that by
grouping tasks with similar PVI estimates, the joint learners yielded
competitive results with fewer total parameters, with consistent performance
across domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main paper 12 pages, Appendix 7 pages, 1 figure, 18 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unitary Multi-Margin <span class="highlight-title">BERT</span> for Robust Natural Language Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12759v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12759v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao-Yuan Chang, Kang L. Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in adversarial attacks on deep learning leave many
mission-critical natural language processing (NLP) systems at risk of
exploitation. To address the lack of computationally efficient adversarial
defense methods, this paper reports a novel, universal technique that
drastically improves the robustness of Bidirectional Encoder Representations
from Transformers (BERT) by combining the unitary weights with the multi-margin
loss. We discover that the marriage of these two simple ideas amplifies the
protection against malicious interference. Our model, the unitary multi-margin
BERT (UniBERT), boosts post-attack classification accuracies significantly by
5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,
the pre-attack and post-attack accuracy tradeoff can be adjusted via a single
scalar parameter to best fit the design requirements for the target
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StyleDistance: Stronger Content-Independent Style Embeddings with
  Synthetic Parallel Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12757v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12757v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, Chris Callison-Burch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Style representations aim to embed texts with similar writing styles closely
and texts with different styles far apart, regardless of content. However, the
contrastive triplets often used for training these representations may vary in
both style and content, leading to potential content leakage in the
representations. We introduce StyleDistance, a novel approach to training
stronger content-independent style embeddings. We use a large language model to
create a synthetic dataset of near-exact paraphrases with controlled style
variations, and produce positive and negative examples across 40 distinct style
features for precise contrastive learning. We assess the quality of our
synthetic data and embeddings through human and automatic evaluations.
StyleDistance enhances the content-independence of style embeddings, which
generalize to real-world benchmarks and outperform leading style
representations in downstream applications. Our model can be found at
https://huggingface.co/StyleDistance/styledistance .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparative Analysis of Extrinsic Factors for NER in French 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12750v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12750v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grace Yang, Zhiyi Li, Yandong Liu, Jungyeul Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Named entity recognition (NER) is a crucial task that aims to identify
structured information, which is often replete with complex, technical terms
and a high degree of variability. Accurate and reliable NER can facilitate the
extraction and analysis of important information. However, NER for other than
English is challenging due to limited data availability, as the high expertise,
time, and expenses are required to annotate its data. In this paper, by using
the limited data, we explore various factors including model structure, corpus
annotation scheme and data augmentation techniques to improve the performance
of a NER model for French. Our experiments demonstrate that these approaches
can significantly improve the model's F1 score from original CRF score of 62.41
to 79.39. Our findings suggest that considering different extrinsic factors and
combining these techniques is a promising approach for improving NER
performance where the size of data is limited.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CREAM: Consistency Regularized Self-Rewarding Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12735v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12735v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent self-rewarding large language models (LLM) have successfully applied
LLM-as-a-Judge to iteratively improve the alignment performance without the
need of human annotations for preference data. These methods commonly utilize
the same LLM to act as both the policy model (which generates responses) and
the reward model (which scores and ranks those responses). The ranked responses
are then used as preference pairs to train the LLM via direct alignment
technologies (e.g. DPO). However, it is noteworthy that throughout this
process, there is no guarantee of accuracy in the rewarding and ranking, which
is critical for ensuring accurate rewards and high-quality preference data.
Empirical results from relatively small LLMs (e.g., 7B parameters) also
indicate that improvements from self-rewarding may diminish after several
iterations in certain situations, which we hypothesize is due to accumulated
bias in the reward system. This bias can lead to unreliable preference data for
training the LLM. To address this issue, we first formulate and analyze the
generalized iterative preference fine-tuning framework for self-rewarding
language model. We then introduce the regularization to this generalized
framework to mitigate the overconfident preference labeling in the
self-rewarding process. Based on this theoretical insight, we propose a
Consistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages
the rewarding consistency across different iterations to regularize the
self-rewarding training, helping the model to learn from more reliable
preference data. With this explicit regularization, our empirical results
demonstrate the superiority of CREAM in improving both reward consistency and
alignment performance. The code is publicly available at
https://github.com/Raibows/CREAM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WorldMedQA-V: a multilingual, multimodal medical examination <span class="highlight-title">dataset</span> for
  multimodal language models evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12722v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12722v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        João Matos, Shan Chen, Siena Placino, Yingya Li, Juan Carlos Climent Pardo, Daphna Idan, Takeshi Tohyama, David Restrepo, Luis F. Nakayama, Jose M. M. Pascual-Leone, Guergana Savova, Hugo Aerts, Leo A. Celi, A. Ian Wong, Danielle S. Bitterman, Jack Gallifant
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal/vision language models (VLMs) are increasingly being deployed in
healthcare settings worldwide, necessitating robust benchmarks to ensure their
safety, efficacy, and fairness. Multiple-choice question and answer (QA)
datasets derived from national medical examinations have long served as
valuable evaluation tools, but existing datasets are largely text-only and
available in a limited subset of languages and countries. To address these
challenges, we present WorldMedQA-V, an updated multilingual, multimodal
benchmarking dataset designed to evaluate VLMs in healthcare. WorldMedQA-V
includes 568 labeled multiple-choice QAs paired with 568 medical images from
four countries (Brazil, Israel, Japan, and Spain), covering original languages
and validated English translations by native clinicians, respectively. Baseline
performance for common open- and closed-source models are provided in the local
language and English translations, and with and without images provided to the
model. The WorldMedQA-V benchmark aims to better match AI systems to the
diverse healthcare environments in which they are deployed, fostering more
equitable, effective, and representative applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>submitted for review, total of 14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WorldCuisines: A Massive-Scale Benchmark for Multilingual and
  Multicultural Visual Question Answering on Global Cuisines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12705v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12705v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Genta Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Nedjma Ousidhoum, Afifa Amriani, Anar Rzayev, Anirban Das, Ashmari Pramodya, Aulia Adila, Bryan Wilie, Candy Olivia Mawalim, Ching Lam Cheng, Daud Abolade, Emmanuele Chersoni, Enrico Santus, Fariz Ikhwantri, Garry Kuwanto, Hanyang Zhao, Haryo Akbarianto Wibowo, Holy Lovenia, Jan Christian Blaise Cruz, Jan Wira Gotama Putra, Junho Myung, Lucky Susanto, Maria Angelica Riera Machin, Marina Zhukova, Michael Anugraha, Muhammad Farid Adilazuarda, Natasha Santosa, Peerat Limkonchotiwat, Raj Dabre, Rio Alexander Audino, Samuel Cahyawijaya, Shi-Xiong Zhang, Stephanie Yulia Salim, Yi Zhou, Yinxuan Gui, David Ifeoluwa Adelani, En-Shiun Annie Lee, Shogo Okada, Ayu Purwarianti, Alham Fikri Aji, Taro Watanabe, Derry Tanti Wijaya, Alice Oh, Chong-Wah Ngo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) often struggle with culture-specific knowledge,
particularly in languages other than English and in underrepresented cultural
contexts. To evaluate their understanding of such knowledge, we introduce
WorldCuisines, a massive-scale benchmark for multilingual and multicultural,
visually grounded language understanding. This benchmark includes a visual
question answering (VQA) dataset with text-image pairs across 30 languages and
dialects, spanning 9 language families and featuring over 1 million data
points, making it the largest multicultural VQA benchmark to date. It includes
tasks for identifying dish names and their origins. We provide evaluation
datasets in two sizes (12k and 60k instances) alongside a training dataset (1
million instances). Our findings show that while VLMs perform better with
correct location context, they struggle with adversarial contexts and
predicting specific regional cuisines and languages. To support future
research, we release a knowledge base with annotated food entries and images
along with the VQA data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sarcasm Detection in a Less-Resourced Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lazar Đoković, Marko Robnik-Šikonja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The sarcasm detection task in natural language processing tries to classify
whether an utterance is sarcastic or not. It is related to sentiment analysis
since it often inverts surface sentiment. Because sarcastic sentences are
highly dependent on context, and they are often accompanied by various
non-verbal cues, the task is challenging. Most of related work focuses on
high-resourced languages like English. To build a sarcasm detection dataset for
a less-resourced language, such as Slovenian, we leverage two modern
techniques: a machine translation specific medium-size transformer model, and a
very large generative language model. We explore the viability of translated
datasets and how the size of a pretrained transformer affects its ability to
detect sarcasm. We train ensembles of detection models and evaluate models'
performance. The results show that larger models generally outperform smaller
ones and that ensembling can slightly improve sarcasm detection performance.
Our best ensemble approach achieves an $\text{F}_1$-score of 0.765 which is
close to annotators' agreement in the source language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, published in the Slovenian Conference on Artificial
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VividMed: Vision Language Model with Versatile Visual Grounding for
  Medicine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12694v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12694v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Vision Language Models (VLMs) have demonstrated
remarkable promise in generating visually grounded responses. However, their
application in the medical domain is hindered by unique challenges. For
instance, most VLMs rely on a single method of visual grounding, whereas
complex medical tasks demand more versatile approaches. Additionally, while
most VLMs process only 2D images, a large portion of medical images are 3D. The
lack of medical data further compounds these obstacles. To address these
challenges, we present VividMed, a vision language model with versatile visual
grounding for medicine. Our model supports generating both semantic
segmentation masks and instance-level bounding boxes, and accommodates various
imaging modalities, including both 2D and 3D data. We design a three-stage
training procedure and an automatic data synthesis pipeline based on open
datasets and models. Besides visual grounding tasks, VividMed also excels in
other common downstream tasks, including Visual Question Answering (VQA) and
report generation. Ablation studies empirically show that the integration of
visual grounding ability leads to improved performance on these tasks. Our code
is publicly available at https://github.com/function2-llx/MMMM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Building Better: Avoiding Pitfalls in Developing Language Resources when
  Data is Scarce 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language is a symbolic capital that affects people's lives in many ways
(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,
cultures, traditions, and societies in general. Hence, data in a given language
should be viewed as more than a collection of tokens. Good data collection and
labeling practices are key to building more human-centered and socially aware
technologies. While there has been a rising interest in mid- to low-resource
languages within the NLP community, work in this space has to overcome unique
challenges such as data scarcity and access to suitable annotators. In this
paper, we collect feedback from those directly involved in and impacted by NLP
artefacts for mid- to low-resource languages. We conduct a quantitative and
qualitative analysis of the responses and highlight the main issues related to
(1) data quality such as linguistic and cultural data suitability; and (2) the
ethics of common annotation practices such as the misuse of online community
services. Based on these findings, we make several recommendations for the
creation of high-quality language artefacts that reflect the cultural milieu of
its speakers, while simultaneously respecting the dignity and labor of data
workers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shicheng Xu, Liang Pang, Yunchang Zhu, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language alignment in Large Vision-Language Models (LVLMs)
successfully enables LLMs to understand visual input. However, we find that
existing vision-language alignment methods fail to transfer the existing safety
mechanism for text in LLMs to vision, which leads to vulnerabilities in toxic
image. To explore the cause of this problem, we give the insightful explanation
of where and how the safety mechanism of LVLMs operates and conduct comparative
analysis between text and vision. We find that the hidden states at the
specific transformer layers play a crucial role in the successful activation of
safety mechanism, while the vision-language alignment at hidden states level in
current methods is insufficient. This results in a semantic shift for input
images compared to text in hidden states, therefore misleads the safety
mechanism. To address this, we propose a novel Text-Guided vision-language
Alignment method (TGA) for LVLMs. TGA retrieves the texts related to input
vision and uses them to guide the projection of vision into the hidden states
space in LLMs. Experiments show that TGA not only successfully transfers the
safety mechanism for text in basic LLMs to vision in vision-language alignment
for LVLMs without any safety fine-tuning on the visual modality but also
maintains the general performance on various vision tasks (Safe and Good).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Morphological Compositional Generalization in Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12656v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12656v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mete Ismayilzada, Defne Circi, Jonne Sälevä, Hale Sirin, Abdullatif Köksal, Bhuwan Dhingra, Antoine Bosselut, Lonneke van der Plas, Duygu Ataman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated significant progress in
various natural language generation and understanding tasks. However, their
linguistic generalization capabilities remain questionable, raising doubts
about whether these models learn language similarly to humans. While humans
exhibit compositional generalization and linguistic creativity in language use,
the extent to which LLMs replicate these abilities, particularly in morphology,
is under-explored. In this work, we systematically investigate the
morphological generalization abilities of LLMs through the lens of
compositionality. We define morphemes as compositional primitives and design a
novel suite of generative and discriminative tasks to assess morphological
productivity and systematicity. Focusing on agglutinative languages such as
Turkish and Finnish, we evaluate several state-of-the-art instruction-finetuned
multilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs
struggle with morphological compositional generalization particularly when
applied to novel word roots, with performance declining sharply as
morphological complexity increases. While models can identify individual
morphological combinations better than chance, their performance lacks
systematicity, leading to significant accuracy gaps compared to humans.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Measurement Instruments to Training Data: Leveraging Theory-Driven
  Synthetic Training Data for Measuring Social Constructs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Birkenmaier, Matthias Roth, Indira Sen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computational text classification is a challenging task, especially for
multi-dimensional social constructs. Recently, there has been increasing
discussion that synthetic training data could enhance classification by
offering examples of how these constructs are represented in texts. In this
paper, we systematically examine the potential of theory-driven synthetic
training data for improving the measurement of social constructs. In
particular, we explore how researchers can transfer established knowledge from
measurement instruments in the social sciences, such as survey scales or
annotation codebooks, into theory-driven generation of synthetic data. Using
two studies on measuring sexism and political topics, we assess the added value
of synthetic training data for fine-tuning text classification models. Although
the results of the sexism study were less promising, our findings demonstrate
that synthetic data can be highly effective in reducing the need for labeled
data in political topic classification. With only a minimal drop in
performance, synthetic data allows for substituting large amounts of labeled
data. Furthermore, theory-driven synthetic data performed markedly better than
data generated without conceptual information in mind.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety,
  Toxicity, and Legal Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruimeng Ye, Yang Xiao, Bo Hui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) continue to advance, ensuring their alignment
with human values becomes increasingly critical. Traditional alignment methods
heavily rely on human feedback to fine-tune models. With the emergence of
superhuman models whose outputs may surpass human understanding, evaluating and
aligning these models using human judgments poses significant challenges. To
address the challenges, recent works use weak supervisors to elicit knowledge
from much stronger models. However, there are important disanalogies between
the empirical setup in the existing works and the genuine goal of alignment. We
remark that existing works investigate the phenomenon of weak-to-strong
generation in analogous setup (i.e., binary classification), rather than
practical alignment-relevant tasks (e.g., safety). In this paper, we bridge
this gap by extending weak-to-strong generation to the context of practical
alignment. We empirically demonstrate the widespread phenomenon of
weak-to-strong generation in three complicated alignment tasks: safety,
toxicity, and legal reasoning}. Furthermore, we explore efficient strategies
for improving alignment performance to enhance the quality of model outcomes.
Lastly, we summarize and analyze the challenges and potential solutions in
regard to specific alignment tasks, which we hope to catalyze the research
progress on the topic of weak-to-strong generalization. Our code is released at
https://github.com/yeruimeng/WTS.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parsing Akkadian Verbs with Prolog <span class="chip">ACL-02</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12617v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12617v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Macks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes a parsing/generation system for finite verbal forms in
Akkadian, with the possible addition of suffixes, implemented in Prolog. The
work described provides the framework and engine to interpret the D, N, and G
stems along with accusative, dative and ventive endings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 9 figures, presented at ACL-02 the Association of
  Computational Linguistics, 2002</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Model Kinship for Merging Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yedi Hu, Yunzhi Yao, Ningyu Zhang, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging has become one of the key technologies for enhancing the
capabilities and efficiency of Large Language Models (LLMs). However, our
understanding of the expected performance gains and principles when merging any
two models remains limited. In this work, we introduce model kinship, the
degree of similarity or relatedness between LLMs, analogous to biological
evolution. With comprehensive empirical analysis, we find that there is a
certain relationship between model kinship and the performance gains after
model merging, which can help guide our selection of candidate models. Inspired
by this, we propose a new model merging strategy: Top-k Greedy Merging with
Model Kinship, which can yield better performance on benchmark datasets.
Specifically, we discover that using model kinship as a criterion can assist us
in continuously performing model merging, alleviating the degradation (local
optima) in model evolution, whereas model kinship can serve as a guide to
escape these traps. Code is available at
https://github.com/zjunlp/ModelKinship.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Not All Votes Count! Programs as Verifiers Improve Self-Consistency of
  Language Models for Math Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12608v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12608v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vernon Y. H. Toh, Deepanway Ghosal, Soujanya Poria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown increasing proficiency in solving
mathematical reasoning problems. However, many current open-source LLMs often
still make calculation and semantic understanding errors in their intermediate
reasoning steps. In this work, we propose PROVE, a simple yet effective
framework that uses program-based verification as a heuristic to filter out
potentially incorrect reasoning paths before aggregating the final answers.
Instead of relying on vanilla majority voting, our approach rejects solutions
whose corresponding program outputs are inconsistent with the generated
solution, aggregating only those validated by Python programs. We conducted
extensive experiments on 13 open-source LLMs from various model families and
sizes, ranging from 0.5B to 13B parameters, across seven math benchmarks. We
demonstrate that PROVE consistently outperforms vanilla majority voting as a
heuristic for solving mathematical reasoning tasks across all datasets and
model sizes. Notably, PROVE increases accuracy on the GSM8K benchmark from
48.85% to 53.83% for Qwen2-0.5B-Instruct, from 65.66% to 73.01% for
Llama-3.2-1B-Instruct, from 73.39% to 79.61% for Gemma-2-2b-it, and from 41.32%
to 59.51% for Llama-2-7B-chat. Our codes are available at
https://github.com/declare-lab/prove.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CCSBench: Evaluating Compositional Controllability in LLMs for
  Scientific Document Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixi Ding, Jiaying Wu, Tongyao Zhu, Yanxia Qin, Qian Liu, Min-Yen Kan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To broaden the dissemination of scientific knowledge to diverse audiences,
scientific document summarization must simultaneously control multiple
attributes such as length and empirical focus. However, existing research
typically focuses on controlling single attributes, leaving the compositional
control of multiple attributes underexplored. To address this gap, we introduce
CCSBench, a benchmark for compositional controllable summarization in the
scientific domain. Our benchmark enables fine-grained control over both
explicit attributes (e.g., length), which are objective and straightforward,
and implicit attributes (e.g., empirical focus), which are more subjective and
conceptual. We conduct extensive experiments on GPT-4, LLaMA2, and other
popular LLMs under various settings. Our findings reveal significant
limitations in large language models' ability to balance trade-offs between
control attributes, especially implicit ones that require deeper understanding
and abstract reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Risk of Evidence Pollution for Malicious Social Text Detection in
  the Era of LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12600v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12600v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Herun Wan, Minnan Luo, Zhixiong Su, Guang Dai, Xiang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evidence-enhanced detectors present remarkable abilities in identifying
malicious social text with related evidence. However, the rise of large
language models (LLMs) brings potential risks of evidence pollution to confuse
detectors. This paper explores how to manipulate evidence, simulating potential
misuse scenarios including basic pollution, and rephrasing or generating
evidence by LLMs. To mitigate its negative impact, we propose three defense
strategies from both the data and model sides, including machine-generated text
detection, a mixture of experts, and parameter updating. Extensive experiments
on four malicious social text detection tasks with ten datasets present that
evidence pollution, especially the generate strategy, significantly compromises
existing detectors. On the other hand, the defense strategies could mitigate
evidence pollution, but they faced limitations for practical employment, such
as the need for annotated data and huge inference costs. Further analysis
illustrates that polluted evidence is of high quality, would compromise the
model calibration, and could ensemble to amplify the negative impact.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Reverse In-Context Knowledge Edits? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12586v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12586v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Youssef, Zhixue Zhao, Jörg Schlötterer, Christin Seifert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context knowledge editing (IKE) enables efficient modification of large
language model (LLM) outputs without parameter changes and at zero-cost.
However, it can be misused to manipulate responses opaquely, e.g., insert
misinformation or offensive content. Such malicious interventions could be
incorporated into high-level wrapped APIs where the final input prompt is not
shown to end-users. To address this issue, we investigate the detection and
reversal of IKE-edits. First, we demonstrate that IKE-edits can be detected
with high accuracy (F1 > 80\%) using only the top-10 output probabilities of
the next token, even in a black-box setting, e.g. proprietary LLMs with limited
output information. Further, we introduce the novel task of reversing IKE-edits
using specially tuned reversal tokens. We explore using both continuous and
discrete reversal tokens, achieving over 80\% accuracy in recovering original,
unedited outputs across multiple LLMs. Our continuous reversal tokens prove
particularly effective, with minimal impact on unedited prompts. Through
analysis of output distributions, attention patterns, and token rankings, we
provide insights into IKE's effects on LLMs and how reversal tokens mitigate
them. This work represents a significant step towards enhancing LLM resilience
against potential misuse of in-context editing, improving their transparency
and trustworthiness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STRUX: An LLM for Decision-Making with Structured Explanations <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Lu, Yebowen Hu, Hassan Foroosh, Wei Jin, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Countless decisions shape our daily lives, and it is paramount to understand
the how and why behind these choices. In this paper, we introduce a new LLM
decision-making framework called STRUX, which enhances LLM decision-making by
providing structured explanations. These include favorable and adverse facts
related to the decision, along with their respective strengths. STRUX begins by
distilling lengthy information into a concise table of key facts. It then
employs a series of self-reflection steps to determine which of these facts are
pivotal, categorizing them as either favorable or adverse in relation to a
specific decision. Lastly, we fine-tune an LLM to identify and prioritize these
key facts to optimize decision-making. STRUX has been evaluated on the
challenging task of forecasting stock investment decisions based on earnings
call transcripts and demonstrated superior performance against strong
baselines. It enhances decision transparency by allowing users to understand
the impact of different factors, representing a meaningful step towards
practical decision-making with LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures, submitted to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Claim Decomposition Benchmark for Long-form Answer Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12558v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12558v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihao Zhang, Yixing Fan, Ruqing Zhang, Jiafeng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement of LLMs has significantly boosted the performance of complex
long-form question answering tasks. However, one prominent issue of LLMs is the
generated "hallucination" responses that are not factual. Consequently,
attribution for each claim in responses becomes a common solution to improve
the factuality and verifiability. Existing researches mainly focus on how to
provide accurate citations for the response, which largely overlook the
importance of identifying the claims or statements for each response. To bridge
this gap, we introduce a new claim decomposition benchmark, which requires
building system that can identify atomic and checkworthy claims for LLM
responses. Specifically, we present the Chinese Atomic Claim Decomposition
Dataset (CACDD), which builds on the WebCPM dataset with additional expert
annotations to ensure high data quality. The CACDD encompasses a collection of
500 human-annotated question-answer pairs, including a total of 4956 atomic
claims. We further propose a new pipeline for human annotation and describe the
challenges of this task. In addition, we provide experiment results on
zero-shot, few-shot and fine-tuned LLMs as baselines. The results show that the
claim decomposition is highly challenging and requires further explorations.
All code and data are publicly available at
\url{https://github.com/FBzzh/CACDD}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CCIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-based Translation Inference with Iterative Bilingual Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andong Chen, Kehai Chen, Yang Xiang, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable understanding and generation capabilities of large language
models (LLMs) have greatly improved translation performance. However, incorrect
understanding of the sentence to be translated can degrade translation quality.
To address this issue, we proposed a novel Iterative Bilingual Understanding
Translation (IBUT) method based on the cross-lingual capabilities of LLMs and
the dual characteristics of translation tasks. The cross-lingual capability of
LLMs enables the generation of contextual understanding for both the source and
target languages separately. Furthermore, the dual characteristics allow IBUT
to generate effective cross-lingual feedback, iteratively refining contextual
understanding, thereby reducing errors and improving translation performance.
Experimental results showed that the proposed IBUT outperforms several strong
comparison methods, especially being generalized to multiple domains (e.g.,
news, commonsense, and cultural translation benchmarks).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in process</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MedAide: Towards an Omni Medical Aide via Specialized LLM-based
  Multi-Agent Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinjie Wei, Dingkang Yang, Yanshu Li, Qingyao Xu, Zhaoyu Chen, Mingcheng Li, Yue Jiang, Xiaolu Hou, Lihua Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM)-driven interactive systems currently show
potential promise in healthcare domains. Despite their remarkable capabilities,
LLMs typically lack personalized recommendations and diagnosis analysis in
sophisticated medical applications, causing hallucinations and performance
bottlenecks. To address these challenges, this paper proposes MedAide, an
LLM-based omni medical multi-agent collaboration framework for specialized
healthcare services. Specifically, MedAide first performs query rewriting
through retrieval-augmented generation to accomplish accurate medical intent
understanding. Immediately, we devise a contextual encoder to obtain intent
prototype embeddings, which are used to recognize fine-grained intents by
similarity matching. According to the intent relevance, the activated agents
collaborate effectively to provide integrated decision analysis. Extensive
experiments are conducted on four medical benchmarks with composite intents.
Experimental results from automated metrics and expert doctor evaluations show
that MedAide outperforms current LLMs and improves their medical proficiency
and strategic reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FiRST: Finetuning Router-Selective <span class="highlight-title">Transformer</span>s for Input-Adaptive
  Latency Reduction <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12513v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12513v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akriti Jain, Saransh Sharma, Koyel Mukherjee, Soumyabrata Pal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Auto-regressive Large Language Models (LLMs) demonstrate remarkable
performance across domanins such as vision and language processing. However,
due to sequential processing through a stack of transformer layers,
autoregressive decoding faces significant computation/latency challenges,
particularly in resource constrained environments like mobile and edge devices.
Existing approaches in literature that aim to improve latency via skipping
layers have two distinct flavors - 1) Early exit 2) Input-agnostic heuristics
where tokens exit at pre-determined layers irrespective of input sequence. Both
the above strategies have limitations - the former cannot be applied to handle
KV Caching necessary for speed-ups in modern framework and the latter does not
capture the variation in layer importance across tasks or more generally,
across input sequences. To address both limitations, we propose FIRST, an
algorithm that reduces inference latency by using layer-specific routers to
select a subset of transformer layers adaptively for each input sequence - the
prompt (during prefill stage) decides which layers will be skipped during
decoding. FIRST preserves compatibility with KV caching enabling faster
inference while being quality-aware. FIRST is model-agnostic and can be easily
enabled on any pre-trained LLM. We further improve performance by incorporating
LoRA adapters for fine-tuning on external datasets, enhancing task-specific
accuracy while maintaining latency benefits. Our approach reveals that input
adaptivity is critical - indeed, different task-specific middle layers play a
crucial role in evolving hidden representations depending on task. Extensive
experiments show that FIRST significantly reduces latency while retaining
competitive performance (as compared to baselines), making our approach an
efficient solution for LLM deployment in low-resource environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 6 figures, Submitted to ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Fairness in Natural Language Processing: From Traditional
  Methods to Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12511v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12511v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanny Jourdan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The burgeoning field of Natural Language Processing (NLP) stands at a
critical juncture where the integration of fairness within its frameworks has
become an imperative. This PhD thesis addresses the need for equity and
transparency in NLP systems, recognizing that fairness in NLP is not merely a
technical challenge but a moral and ethical necessity, requiring a rigorous
examination of how these technologies interact with and impact diverse human
populations. Through this lens, this thesis undertakes a thorough investigation
into the development of equitable NLP methodologies and the evaluation of
biases that prevail in current systems.
  First, it introduces an innovative algorithm to mitigate biases in
multi-class classifiers, tailored for high-risk NLP applications, surpassing
traditional methods in both bias mitigation and prediction accuracy. Then, an
analysis of the Bios dataset reveals the impact of dataset size on
discriminatory biases and the limitations of standard fairness metrics. This
awareness has led to explorations in the field of explainable AI, aiming for a
more complete understanding of biases where traditional metrics are limited.
Consequently, the thesis presents COCKATIEL, a model-agnostic explainability
method that identifies and ranks concepts in Transformer models, outperforming
previous approaches in sentiment analysis tasks. Finally, the thesis
contributes to bridging the gap between fairness and explainability by
introducing TaCo, a novel method to neutralize bias in Transformer model
embeddings.
  In conclusion, this thesis constitutes a significant interdisciplinary
endeavor that intertwines explicability and fairness to challenge and reshape
current NLP paradigms. The methodologies and critiques presented contribute to
the ongoing discourse on fairness in machine learning, offering actionable
solutions for more equitable and responsible AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD Thesis, Toulouse University</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ With a Grain of SALT: Are LLMs Fair Across Social Dimensions? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12499v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12499v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samee Arif, Zohaib Khan, Agha Ali Raza, Awais Athar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an analysis of biases in open-source Large Language
Models (LLMs) across various genders, religions, and races. We introduce a
methodology for generating a bias detection dataset using seven bias triggers:
General Debate, Positioned Debate, Career Advice, Story Generation,
Problem-Solving, Cover-Letter Writing, and CV Generation. We use GPT-4o to
generate a diverse set of prompts for each trigger across various genders,
religious and racial groups. We evaluate models from Llama and Gemma family on
the generated dataset. We anonymise the LLM-generated text associated with each
group using GPT-4o-mini and do a pairwise comparison using GPT-4o-as-a-Judge.
To quantify bias in the LLM-generated text we use the number of wins and losses
in the pairwise comparison. Our analysis spans three languages, English,
German, and Arabic to explore how language influences bias manifestation. Our
findings reveal that LLMs exhibit strong polarization toward certain groups
across each category, with a notable consistency observed across models.
However, when switching languages, variations and anomalies emerge, often
attributable to cultural cues and contextual differences.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ End-to-end Planner Training for Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathan Cornille, Florian Mai, Jingyuan Sun, Marie-Francine Moens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Through end-to-end training to predict the next token, LLMs have become
valuable tools for various tasks. Enhancing their core training in language
modeling can improve numerous downstream applications. A successful approach to
enhance language modeling uses a separate planning module to predict abstract
labels of future sentences and conditions the LM on these predictions. However,
this method is non-differentiable, preventing joint end-to-end tuning of the
planner with the LM. We propose an effective method to improve this approach by
enabling joint fine-tuning of the planner and the LM. We show that a naive way
of approximating the gradient of selecting a label via the straight-through
estimator is not effective. Instead, we propose to use the predicted label
probabilities as mixing weights to condition the LM on a weighted average of
label embeddings in a differentiable manner. This not only enables joint
fine-tuning of the planner and the LM, but also allows the LM to draw on the
full label distribution predicted by the planner, retaining more information.
Our experimental results show consistent improvements in perplexity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Insights from the Inverse: Reconstructing LLM Training Goals Through
  Inverse RL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12491v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12491v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jared Joselowitz, Arjun Jagota, Satyapriya Krishna, Sonali Parbhoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) trained with Reinforcement Learning from Human
Feedback (RLHF) have demonstrated remarkable capabilities, but their underlying
reward functions and decision-making processes remain opaque. This paper
introduces a novel approach to interpreting LLMs by applying inverse
reinforcement learning (IRL) to recover their implicit reward functions. We
conduct experiments on toxicity-aligned LLMs of varying sizes, extracting
reward models that achieve up to 80.40% accuracy in predicting human
preferences. Our analysis reveals key insights into the non-identifiability of
reward functions, the relationship between model size and interpretability, and
potential pitfalls in the RLHF process. We demonstrate that IRL-derived reward
models can be used to fine-tune new LLMs, resulting in comparable or improved
performance on toxicity benchmarks. This work provides a new lens for
understanding and improving LLM alignment, with implications for the
responsible development and deployment of these powerful systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KcMF: A Knowledge-compliant Framework for Schema and Entity Matching
  with Fine-tuning-free LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongqin Xu, Huan Li, Ke Chen, Lidan Shou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Schema and entity matching tasks are crucial for data integration and
management. While large language models (LLMs) have shown promising results in
these tasks, they suffer from hallucinations and confusion about task
instructions. In this paper, we present the Knowledge-Compliant Matching
Framework (KcMF), an LLM-based approach that addresses these issues without the
need for domain-specific fine-tuning. KcMF employs a pseudo-code-based task
decomposition strategy to adopt task-specific natural language statements that
guide LLM reasoning and reduce confusion. We also propose two mechanisms,
Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build domain
knowledge sets when unstructured domain knowledge is lacking. Additionally, we
introduce a result-ensembling strategy to leverage multiple knowledge sources
and suppress poorly formatted outputs. Comprehensive evaluations on schema and
entity matching tasks demonstrate that KcMF outperforms previous non-LLM
state-of-the-art (SOTA) methods by an average F1 score of 22.9% and competes
effectively with SOTA fine-tuned LLMs. Moreover, KcMF generalizes well across
different LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MlingConf: A Comprehensive Study of Multilingual Confidence Estimation
  on Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12478v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12478v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Kam-Fai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The tendency of Large Language Models (LLMs) to generate hallucinations
raises concerns regarding their reliability. Therefore, confidence estimations
indicating the extent of trustworthiness of the generations become essential.
However, current LLM confidence estimations in languages other than English
remain underexplored. This paper addresses this gap by introducing a
comprehensive investigation of Multilingual Confidence estimation (MlingConf)
on LLMs, focusing on both language-agnostic (LA) and language-specific (LS)
tasks to explore the performance and language dominance effects of multilingual
confidence estimations on different tasks. The benchmark comprises four
meticulously checked and human-evaluate high-quality multilingual datasets for
LA tasks and one for the LS task tailored to specific social, cultural, and
geographical contexts of a language. Our experiments reveal that on LA tasks
English exhibits notable linguistic dominance in confidence estimations than
other languages, while on LS tasks, using question-related language to prompt
LLMs demonstrates better linguistic dominance in multilingual confidence
estimations. The phenomena inspire a simple yet effective native-tone prompting
strategy by employing language-specific prompts for LS tasks, effectively
improving LLMs' reliability and accuracy on LS tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zerui Xu, Fang Wu, Tianfan Fu, Yue Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning (ML) exhibits promise in the clinical domain. However, it is
constrained by data scarcity and ethical considerations, as the generation of
clinical trials presents significant challenges due to stringent privacy
regulations, high costs, and the extended duration required for conducting
studies with human participants. Despite the advancements of large language
models (LLMs) in general generation tasks, their potential in facilitating the
generation of synthetic clinical trials is under-explored. To address this gap,
we introduce a novel Retrieval-Reasoning few-shot framework that leverages LLMs
to generate artificial yet realistic and diverse clinical trials with binary
success/failure labels. Experiments conducted on real clinical trials from the
\url{ClinicalTrials.gov} database demonstrate that our synthetic data can
effectively augment real datasets. Furthermore, by fine-tuning a pre-trained
model as a binary classifier on synthetic clinical trial datasets, we
demonstrate that this augmentation enhances model training for downstream tasks
such as trial outcome prediction. Our findings suggest that LLMs for synthetic
clinical trial generation hold promise for accelerating clinical research and
upholding ethical standards for patient privacy. The code is publicly available
at
https://anonymous.4open.science/r/Retrieval_Reasoning_Clinical_Trial_Generation-3EC4.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Predict Usage Options of Product <span class="highlight-title">Review</span>s with LLM-Generated
  Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leo Kohlenberg, Leonard Horns, Frederic Sadrieh, Nils Kiele, Matthis Clausen, Konstantin Ketterer, Avetis Navasardyan, Tamara Czinczoll, Gerard de Melo, Ralf Herbrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Annotating large datasets can be challenging. However, crowd-sourcing is
often expensive and can lack quality, especially for non-trivial tasks. We
propose a method of using LLMs as few-shot learners for annotating data in a
complex natural language task where we learn a standalone model to predict
usage options for products from customer reviews. We also propose a new
evaluation metric for this scenario, HAMS4, that can be used to compare a set
of strings with multiple reference sets. Learning a custom model offers
individual control over energy efficiency and privacy measures compared to
using the LLM directly for the sequence-to-sequence task. We compare this data
annotation approach with other traditional methods and demonstrate how LLMs can
enable considerable cost savings. We find that the quality of the resulting
data exceeds the level attained by third-party vendor services and that
GPT-4-generated labels even reach the level of domain experts. We make the code
and generated labels publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging the Language Gaps in Large Language Models with Inference-Time
  Cross-Lingual Intervention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing but exhibit significant performance gaps among different
languages. Most existing approaches to address these disparities rely on
pretraining or fine-tuning, which are resource-intensive. To overcome these
limitations without incurring significant costs, we propose Inference-Time
Cross-Lingual Intervention (INCLINE), a novel framework that enhances LLM
performance on low-performing (source) languages by aligning their internal
representations with those of high-performing (target) languages during
inference. INCLINE initially learns alignment matrices using parallel sentences
from source and target languages through a Least-Squares optimization, and then
applies these matrices during inference to transform the low-performing
language representations toward the high-performing language space. Extensive
experiments on nine benchmarks with five LLMs demonstrate that INCLINE
significantly improves performance across diverse tasks and languages, compared
to recent strong baselines. Our analysis demonstrates that INCLINE is highly
cost-effective and applicable to a wide range of applications. In addition, we
release the code to foster research along this line:
https://github.com/weixuan-wang123/INCLINE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Best of Both Worlds: Bridging Quality and Diversity in Data
  Selection with Bipartite Graph 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12458v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12458v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 5 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation
  for Korean LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12445v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12445v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyeonwoo Kim, Dahyun Kim, Jihoo Kim, Sukyung Lee, Yungi Kim, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Open Ko-LLM Leaderboard has been instrumental in benchmarking Korean
Large Language Models (LLMs), yet it has certain limitations. Notably, the
disconnect between quantitative improvements on the overly academic leaderboard
benchmarks and the qualitative impact of the models should be addressed.
Furthermore, the benchmark suite is largely composed of translated versions of
their English counterparts, which may not fully capture the intricacies of the
Korean language. To address these issues, we propose Open Ko-LLM Leaderboard2,
an improved version of the earlier Open Ko-LLM Leaderboard. The original
benchmarks are entirely replaced with new tasks that are more closely aligned
with real-world capabilities. Additionally, four new native Korean benchmarks
are introduced to better reflect the distinct characteristics of the Korean
language. Through these refinements, Open Ko-LLM Leaderboard2 seeks to provide
a more meaningful evaluation for advancing Korean LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar
  Question Generation Using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12444v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12444v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengze Hong, Yuanfeng Song, Di Jiang, Lu Wang, Zichang Guo, Chen Jason Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reliable responses of service chatbots are often achieved by employing
retrieval-based methods that restrict answers to a knowledge base comprising
predefined question-answer pairs (QA pairs). To accommodate potential
variations in how a customer's query may be expressed, it emerges as the
favored solution to augment these QA pairs with similar questions that are
possibly diverse while remaining semantic consistency. This augmentation task
is known as Similar Question Generation (SQG). Traditional methods that heavily
rely on human efforts or rule-based techniques suffer from limited diversity or
significant semantic deviation from the source question, only capable of
producing a finite number of useful questions.
  To address these limitations, we propose an SQG approach based on Large
Language Models (LLMs), capable of producing a substantial number of diverse
questions while maintaining semantic consistency to the source QA pair. This is
achieved by leveraging LLMs' natural language understanding capability through
fine-tuning with specially designed prompts. The experiments conducted on a
real customer-service dataset demonstrate that our method surpasses baseline
methods by a significant margin in terms of semantic diversity. Human
evaluation further confirms that integrating the answer that reflects the
customer's intention is crucial for increasing the number of generated
questions that meet business requirements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformity in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12428v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12428v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The conformity effect describes the tendency of individuals to align their
responses with the majority. Studying this bias in large language models (LLMs)
is crucial, as LLMs are increasingly used in various information-seeking and
decision-making tasks as conversation partners to improve productivity. Thus,
conformity to incorrect responses can compromise their effectiveness. In this
paper, we adapt psychological experiments to examine the extent of conformity
in state-of-the-art LLMs. Our findings reveal that all models tested exhibit
varying levels of conformity toward the majority, regardless of their initial
choice or correctness, across different knowledge domains. Notably, we are the
first to show that LLMs are more likely to conform when they are more uncertain
in their own prediction. We further explore factors that influence conformity,
such as training paradigms and input characteristics, finding that
instruction-tuned models are less susceptible to conformity, while increasing
the naturalness of majority tones amplifies conformity. Finally, we propose two
interventions--Devil's Advocate and Question Distillation--to mitigate
conformity, providing insights into building more robust language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages (8 pages main body), 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Theoretical Analysis of Hierarchical Language Recognition and Generation
  by <span class="highlight-title">Transformer</span>s without Positional Encoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12413v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12413v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daichi Hayakawa, Issei Sato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we provide constructive proof that Transformers can recognize
and generate hierarchical language efficiently with respect to model size, even
without the need for a specific positional encoding. Specifically, we show that
causal masking and a starting token enable Transformers to compute positional
information and depth within hierarchical structures. We demonstrate that
Transformers without positional encoding can generate hierarchical languages.
Furthermore, we suggest that explicit positional encoding might have a
detrimental effect on generalization with respect to sequence length.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>55 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revealing the Barriers of Language Agents in Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12409v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12409v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xie, Kexun Zhang, Jiangjie Chen, Siyu Yuan, Kai Zhang, Yikai Zhang, Lei Li, Yanghua Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous planning has been an ongoing pursuit since the inception of
artificial intelligence. Based on curated problem solvers, early planning
agents could deliver precise solutions for specific tasks but lacked
generalization. The emergence of large language models (LLMs) and their
powerful reasoning capabilities has reignited interest in autonomous planning
by automatically generating reasonable solutions for given tasks. However,
prior research and our experiments show that current language agents still lack
human-level planning abilities. Even the state-of-the-art reasoning model,
OpenAI o1, achieves only 15.6% on one of the complex real-world planning
benchmarks. This highlights a critical question: What hinders language agents
from achieving human-level planning? Although existing studies have highlighted
weak performance in agent planning, the deeper underlying issues and the
mechanisms and limitations of the strategies proposed to address them remain
insufficiently understood. In this work, we apply the feature attribution study
and identify two key factors that hinder agent planning: the limited role of
constraints and the diminishing influence of questions. We also find that
although current strategies help mitigate these challenges, they do not fully
resolve them, indicating that agents still have a long way to go before
reaching human-level intelligence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Coarse-Grained Matching in Video-Text Retrieval <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12407v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12407v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aozhu Chen, Hazel Doughty, Xirong Li, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-text retrieval has seen significant advancements, yet the ability of
models to discern subtle differences in captions still requires verification.
In this paper, we introduce a new approach for fine-grained evaluation. Our
approach can be applied to existing datasets by automatically generating hard
negative test captions with subtle single-word variations across nouns, verbs,
adjectives, adverbs, and prepositions. We perform comprehensive experiments
using four state-of-the-art models across two standard benchmarks (MSR-VTT and
VATEX) and two specially curated datasets enriched with detailed descriptions
(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our
analyses show that the current evaluation benchmarks fall short in detecting a
model's ability to perceive subtle single-word differences, 2) our fine-grained
evaluation highlights the difficulty models face in distinguishing such subtle
variations. To enhance fine-grained understanding, we propose a new baseline
that can be easily combined with current methods. Experiments on our
fine-grained evaluations demonstrate that this approach enhances a model's
ability to understand fine-grained differences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nominal Class Assignment in Swahili: A Computational Account 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12406v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12406v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giada Palmieri, Konstantinos Kogkalidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We discuss the open question of the relation between semantics and nominal
class assignment in Swahili. We approach the problem from a computational
perspective, aiming first to quantify the extent of this relation, and then to
explicate its nature, taking extra care to suppress morphosyntactic confounds.
Our results are the first of their kind, providing a quantitative evaluation of
the semantic cohesion of each nominal class, as well as a nuanced taxonomic
description of its semantic content.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tenth Italian Conference on Computational Linguistics (CliC-it-2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ProSA: Assessing and Understanding the <span class="highlight-title">Prompt</span> Sensitivity of LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingming Zhuo, Songyang Zhang, Xinyu Fang, Haodong Duan, Dahua Lin, Kai Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated impressive capabilities across
various tasks, but their performance is highly sensitive to the prompts
utilized. This variability poses challenges for accurate assessment and user
satisfaction. Current research frequently overlooks instance-level prompt
variations and their implications on subjective evaluations. To address these
shortcomings, we introduce ProSA, a framework designed to evaluate and
comprehend prompt sensitivity in LLMs. ProSA incorporates a novel sensitivity
metric, PromptSensiScore, and leverages decoding confidence to elucidate
underlying mechanisms. Our extensive study, spanning multiple tasks, uncovers
that prompt sensitivity fluctuates across datasets and models, with larger
models exhibiting enhanced robustness. We observe that few-shot examples can
alleviate this sensitivity issue, and subjective evaluations are also
susceptible to prompt sensitivities, particularly in complex,
reasoning-oriented tasks. Furthermore, our findings indicate that higher model
confidence correlates with increased prompt robustness. We believe this work
will serve as a helpful tool in studying prompt sensitivity of LLMs. The
project is released at: https://github.com/open-compass/ProSA .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024, Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tracking Universal Features Through Fine-Tuning and Model Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niels Horn, Desmond Elliott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study how features emerge, disappear, and persist across models fine-tuned
on different domains of text. More specifically, we start from a base one-layer
Transformer language model that is trained on a combination of the BabyLM
corpus, and a collection of Python code from The Stack. This base model is
adapted to two new domains of text: TinyStories, and the Lua programming
language, respectively; and then these two models are merged using these two
models using spherical linear interpolation. Our exploration aims to provide
deeper insights into the stability and transformation of features across
typical transfer-learning scenarios using small-scale models and sparse
auto-encoders.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Prompt</span> Compression for Large Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12388v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12388v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongqian Li, Yinhong Liu, Yixuan Su, Nigel Collier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging large language models (LLMs) for complex natural language tasks
typically requires long-form prompts to convey detailed requirements and
information, which results in increased memory usage and inference costs. To
mitigate these challenges, multiple efficient methods have been proposed, with
prompt compression gaining significant research interest. This survey provides
an overview of prompt compression techniques, categorized into hard prompt
methods and soft prompt methods. First, the technical approaches of these
methods are compared, followed by an exploration of various ways to understand
their mechanisms, including the perspectives of attention optimization,
Parameter-Efficient Fine-Tuning (PEFT), modality fusion, and new synthetic
language. We also examine the downstream adaptations of various prompt
compression techniques. Finally, the limitations of current prompt compression
methods are analyzed, and several future directions are outlined, such as
optimizing the compression encoder, combining hard and soft prompts methods,
and leveraging insights from multimodality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of Attribution Bias in Retrieval-Augmented Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amin Abolghasemi, Leif Azzopardi, Seyyed Hadi Hashemi, Maarten de Rijke, Suzan Verberne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attributing answers to source documents is an approach used to enhance the
verifiability of a model's output in retrieval augmented generation (RAG).
Prior work has mainly focused on improving and evaluating the attribution
quality of large language models (LLMs) in RAG, but this may come at the
expense of inducing biases in the attribution of answers. We define and examine
two aspects in the evaluation of LLMs in RAG pipelines, namely attribution
sensitivity and bias with respect to authorship information. We explicitly
inform an LLM about the authors of source documents, instruct it to attribute
its answers, and analyze (i) how sensitive the LLM's output is to the author of
source documents, and (ii) whether the LLM exhibits a bias towards
human-written or AI-generated source documents. We design an experimental setup
in which we use counterfactual evaluation to study three LLMs in terms of their
attribution sensitivity and bias in RAG pipelines. Our results show that adding
authorship information to source documents can significantly change the
attribution quality of LLMs by 3% to 18%. Moreover, we show that LLMs can have
an attribution bias towards explicit human authorship, which can serve as a
competing hypothesis for findings of prior work that shows that LLM-generated
content may be preferred over human-written contents. Our findings indicate
that metadata of source documents can influence LLMs' trust, and how they
attribute their answers. Furthermore, our research highlights attribution bias
and sensitivity as a novel aspect of brittleness in LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying
  Real-World Claims <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12377v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12377v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To tackle the AVeriTeC shared task hosted by the FEVER-24, we introduce a
system that only employs publicly available large language models (LLMs) for
each step of automated fact-checking, dubbed the Herd of Open LLMs for
verifying real-world claims (HerO). HerO employs multiple LLMs for each step of
automated fact-checking. For evidence retrieval, a language model is used to
enhance a query by generating hypothetical fact-checking documents. We prompt
pretrained and fine-tuned LLMs for question generation and veracity prediction
by crafting prompts with retrieved in-context samples. HerO achieved 2nd place
on the leaderboard with the AVeriTeC score of 0.57, suggesting the potential of
open LLMs for verifying real-world claims. For future research, we make our
code publicly available at https://github.com/ssu-humane/HerO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A system description paper for the AVeriTeC shared task, hosted by
  the seventh FEVER workshop (co-located with EMNLP 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PRefLexOR: Preference-based Recursive Language Modeling for Exploratory
  Optimization of Reasoning and Agentic Thinking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Markus J. Buehler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Proactive Agent: Shifting LLM Agents from Reactive Responses to Active
  Assistance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12361v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12361v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaxi Lu, Shenzhi Yang, Cheng Qian, Guirong Chen, Qinyu Luo, Yesai Wu, Huadong Wang, Xin Cong, Zhong Zhang, Yankai Lin, Weiwen Liu, Yasheng Wang, Zhiyuan Liu, Fangming Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Agents powered by large language models have shown remarkable abilities in
solving complex tasks. However, most agent systems remain reactive, limiting
their effectiveness in scenarios requiring foresight and autonomous
decision-making. In this paper, we tackle the challenge of developing proactive
agents capable of anticipating and initiating tasks without explicit human
instructions. We propose a novel data-driven approach for this problem.
Firstly, we collect real-world human activities to generate proactive task
predictions. These predictions are then labeled by human annotators as either
accepted or rejected. The labeled data is used to train a reward model that
simulates human judgment and serves as an automatic evaluator of the
proactiveness of LLM agents. Building on this, we develop a comprehensive data
generation pipeline to create a diverse dataset, ProactiveBench, containing
6,790 events. Finally, we demonstrate that fine-tuning models with the proposed
ProactiveBench can significantly elicit the proactiveness of LLM agents.
Experimental results show that our fine-tuned model achieves an F1-Score of
66.47% in proactively offering assistance, outperforming all open-source and
close-source models. These results highlight the potential of our method in
creating more proactive and effective agent systems, paving the way for future
advancements in human-agent collaboration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GECTurk WEB: An Explainable Online Platform for Turkish Grammatical
  Error Detection and Correction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Gebeşçe, Gözde Gül Şahin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sophisticated grammatical error detection/correction tools are available for
a small set of languages such as English and Chinese. However, it is not
straightforward -- if not impossible -- to adapt them to morphologically rich
languages with complex writing rules like Turkish which has more than 80
million speakers. Even though several tools exist for Turkish, they primarily
focus on spelling errors rather than grammatical errors and lack features such
as web interfaces, error explanations and feedback mechanisms. To fill this
gap, we introduce GECTurk WEB, a light, open-source, and flexible web-based
system that can detect and correct the most common forms of Turkish writing
errors, such as the misuse of diacritics, compound and foreign words, pronouns,
light verbs along with spelling mistakes. Our system provides native speakers
and second language learners an easily accessible tool to detect/correct such
mistakes and also to learn from their mistakes by showing the explanation for
the violated rule(s). The proposed system achieves 88,3 system usability score,
and is shown to help learn/remember a grammatical rule (confirmed by 80% of the
participants). The GECTurk WEB is available both as an offline tool at
https://github.com/GGLAB-KU/gecturkweb or online at www.gecturk.net.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A linguistic analysis of undesirable outcomes in the era of generative
  AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniele Gambetta, Gizem Gezici, Fosca Giannotti, Dino Pedreschi, Alistair Knott, Luca Pappalardo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has focused on the medium and long-term impacts of generative
AI, posing scientific and societal challenges mainly due to the detection and
reliability of machine-generated information, which is projected to form the
major content on the Web soon. Prior studies show that LLMs exhibit a lower
performance in generation tasks (model collapse) as they undergo a fine-tuning
process across multiple generations on their own generated content
(self-consuming loop). In this paper, we present a comprehensive simulation
framework built upon the chat version of LLama2, focusing particularly on the
linguistic aspects of the generated content, which has not been fully examined
in existing studies. Our results show that the model produces less lexical rich
content across generations, reducing diversity. The lexical richness has been
measured using the linguistic measures of entropy and TTR as well as
calculating the POSTags frequency. The generated content has also been examined
with an $n$-gram analysis, which takes into account the word order, and
semantic networks, which consider the relation between different words. These
findings suggest that the model collapse occurs not only by decreasing the
content diversity but also by distorting the underlying linguistic patterns of
the generated text, which both highlight the critical importance of carefully
choosing and curating the initial input text, which can alleviate the model
collapse problem. Furthermore, we conduct a qualitative analysis of the
fine-tuned models of the pipeline to compare their performances on generic NLP
tasks to the original model. We find that autophagy transforms the initial
model into a more creative, doubtful and confused one, which might provide
inaccurate answers and include conspiracy theories in the model responses,
spreading false and biased information on the Web.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding the Role of LLMs in Multimodal Evaluation Benchmarks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Botian Jiang, Lei Li, Xiaonan Li, Zhaowei Li, Xiachong Feng, Lingpeng Kong, Qi Liu, Xipeng Qiu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of Multimodal Large Language Models (MLLMs) has been
accompanied by the development of various benchmarks to evaluate their
capabilities. However, the true nature of these evaluations and the extent to
which they assess multimodal reasoning versus merely leveraging the underlying
Large Language Model (LLM) backbone remain unclear. This paper presents a
comprehensive investigation into the role of LLM backbones in MLLM evaluation,
focusing on two critical aspects: the degree to which current benchmarks truly
assess multimodal reasoning and the influence of LLM prior knowledge on
performance. Specifically, we introduce a modified evaluation protocol to
disentangle the contributions of the LLM backbone from multimodal integration,
and an automatic knowledge identification technique for diagnosing whether LLMs
equip the necessary knowledge for corresponding multimodal questions. Our study
encompasses four diverse MLLM benchmarks and eight state-of-the-art MLLMs. Key
findings reveal that some benchmarks allow high performance even without visual
inputs and up to 50\% of error rates can be attributed to insufficient world
knowledge in the LLM backbone, indicating a heavy reliance on language
capabilities. To address knowledge deficiencies, we propose a knowledge
augmentation pipeline that achieves significant performance gains, with
improvements of up to 60\% on certain datasets, resulting in a approximately 4x
increase in performance. Our work provides crucial insights into the role of
the LLM backbone in MLLMs, and highlights the need for more nuanced
benchmarking approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neuron-based Personality Trait Induction in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12327v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12327v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Deng, Tianyi Tang, Yanbin Yin, Wenhao Yang, Wayne Xin Zhao, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become increasingly proficient at
simulating various personality traits, an important capability for supporting
related applications (e.g., role-playing). To further improve this capacity, in
this paper, we present a neuron-based approach for personality trait induction
in LLMs, with three major technical contributions. First, we construct
PersonalityBench, a large-scale dataset for identifying and evaluating
personality traits in LLMs. This dataset is grounded in the Big Five
personality traits from psychology and is designed to assess the generative
capabilities of LLMs towards specific personality traits. Second, by leveraging
PersonalityBench, we propose an efficient method for identifying
personality-related neurons within LLMs by examining the opposite aspects of a
given trait. Third, we develop a simple yet effective induction method that
manipulates the values of these identified personality-related neurons. This
method enables fine-grained control over the traits exhibited by LLMs without
training and modifying model parameters. Extensive experiments validate the
efficacy of our neuron identification and trait induction methods. Notably, our
approach achieves comparable performance as fine-tuned models, offering a more
efficient and flexible solution for personality trait induction in LLMs. We
provide access to all the mentioned resources at
https://github.com/RUCAIBox/NPTI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Low-Resource Language Model Training: Comprehensive Analysis
  of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12325v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12325v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kosuke Akimoto, Masafumi Oyamada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we address the challenge of optimizing training setups for
Large Language Models (LLMs) of low-resource language with a limited amount of
corpus. Existing works adopt multi-epoch, multi-lingual, and two-stage training
to utilize the limited target language corpus efficiently. However, there is
still a lack of understanding about the optimal hyperparameter setups for
combining these three approaches to train LLMs. We exhaustively explore
training setups for low-resource language LLM, combining these three
approaches, and found the following insights for efficiently reducing the cost
of hyperparameter search: (1) As the amount of target language corpus
decreases, the optimal training approach shifts from monolingual single-stage
training to multi-lingual two-stage training at a compute budget dependent
threshold. (2) The optimal model scale remains stable regardless of the amount
of target language corpus, allowing the use of the compute-optimal scale of
monolingual training. (3) The optimal number of epochs can be extrapolated from
smaller-scale experiments to larger scale using our proposed model. Also, we
provide evidence that, in single-stage training, the target language validation
loss follows a power law with respect to the target language ratio, with an
exponent independent of the amount of data, model scale, and language pair.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reversal of Thought: Enhancing Large Language Models with
  Preference-Guided Reverse Reasoning Warm-up 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12323v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12323v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Yuan, Dehui Du, Hao Zhang, Zixiang Di, Usman Naseem
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable performance in reasoning
tasks but face limitations in mathematical and complex logical reasoning.
Existing methods to improve LLMs' logical capabilities either involve traceable
or verifiable logical sequences that generate more reliable responses by
constructing logical structures yet increase computational costs, or introduces
rigid logic template rules, reducing flexibility. In this paper, we propose
Reversal of Thought (RoT), a novel framework aimed at enhancing the logical
reasoning abilities of LLMs. RoT utilizes a Preference-Guided Reverse Reasoning
warm-up strategy, which integrates logical symbols for pseudocode planning
through meta-cognitive mechanisms and pairwise preference self-evaluation to
generate task-specific prompts solely through demonstrations, aligning with
LLMs' cognitive preferences shaped by Reinforcement Learning with Human
Feedback (RLHF). Through reverse reasoning, we ultilize a Cognitive Preference
Manager to assess knowledge boundaries and further expand LLMs' reasoning
capabilities by aggregating solution logic for known tasks and stylistic
templates for unknown tasks. Experiments across various tasks demonstrate that
RoT surpasses existing baselines in both reasoning accuracy and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open Domain Question Answering with Conflicting Contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12311v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12311v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyi Liu, Qiang Ning, Kishaloy Halder, Wei Xiao, Zheng Qi, Phu Mon Htut, Yi Zhang, Neha Anna John, Bonan Min, Yassine Benajiba, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open domain question answering systems frequently rely on information
retrieved from large collections of text (such as the Web) to answer questions.
However, such collections of text often contain conflicting information, and
indiscriminately depending on this information may result in untruthful and
inaccurate answers. To understand the gravity of this problem, we collect a
human-annotated dataset, Question Answering with Conflicting Contexts (QACC),
and find that as much as 25% of unambiguous, open domain questions can lead to
conflicting contexts when retrieved using Google Search. We evaluate and
benchmark three powerful Large Language Models (LLMs) with our dataset QACC and
demonstrate their limitations in effectively addressing questions with
conflicting information. To explore how humans reason through conflicting
contexts, we request our annotators to provide explanations for their
selections of correct answers. We demonstrate that by finetuning LLMs to
explain their answers, we can introduce richer information into their training
that guide them through the process of reasoning with conflicting contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering
  Vectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12299v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12299v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weixuan Wang, Jingyuan Yang, Wei Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable performance across many
tasks, yet aligning them with desired behaviors remains challenging. Activation
intervention has emerged as an effective and economical method to modify the
behavior of LLMs. Despite considerable interest in this area, current
intervention methods exclusively employ a fixed steering vector to modify model
activations, lacking adaptability to diverse input semantics. To address this
limitation, we propose Semantics-Adaptive Dynamic Intervention (SADI), a novel
method that constructs a dynamic steering vector to intervene model activations
at inference time. More specifically, SADI utilizes activation differences in
contrastive pairs to precisely identify critical elements of an LLM (i.e.,
attention heads, hidden states, and neurons) for targeted intervention. During
inference, SADI dynamically steers model behavior by scaling element-wise
activations based on the directions of input semantics. Experimental results
show that SADI outperforms established baselines by substantial margins,
improving task performance without training. SADI's cost-effectiveness and
generalizability across various LLM backbones and tasks highlight its potential
as a versatile alignment technique. In addition, we release the code to foster
research along this line:https://github.com/weixuan-wang123/SADI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large
  Language Models and Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Sun, Xinchen Wang, Youdi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) possess impressive reasoning abilities but are
prone to generating incorrect information, often referred to as hallucinations.
While incorporating external Knowledge Graphs (KGs) can partially mitigate this
issue, existing methods primarily treat KGs as static knowledge repositories,
overlooking the critical disparity between KG and LLM knowledge, and failing to
fully exploit the reasoning capabilities inherent in KGs. To address these
limitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for
seamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis
to construct a hierarchical pyramid structure. This structure is designed to
reflect the input question and generate more validated deductive knowledge,
thereby enhancing the alignment of LLMs and KGs and ensuring more cohesive
integration. Furthermore, PDA employs a recursive mechanism to harness the
underlying reasoning abilities of KGs, resulting in more accurate knowledge
retrieval for question-answering tasks. Our experimental results reveal a
substantial performance advantage of PDA over state-of-the-art baselines, with
improvements reaching 26.70% and 26.78%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards LLM-based Cognitive Models of Students with Misconceptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12294v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12294v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately modeling student cognition is crucial for developing effective
AI-driven educational technologies. A key challenge is creating realistic
student models that satisfy two essential properties: (1) accurately
replicating specific misconceptions, and (2) correctly solving problems where
these misconceptions are not applicable. This dual requirement reflects the
complex nature of student understanding, where misconceptions coexist with
correct knowledge. This paper investigates whether Large Language Models (LLMs)
can be instruction-tuned to meet this dual requirement and effectively simulate
student thinking in algebra. We introduce MalAlgoPy, a novel Python library
that generates datasets reflecting authentic student solution patterns through
a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,
we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned
to faithfully emulate realistic student behavior. Our findings reveal that LLMs
trained on misconception examples can efficiently learn to replicate errors.
However, the training diminishes the model's ability to solve problems
correctly, particularly for problem types where the misconceptions are not
applicable, thus failing to satisfy second property of CSMs. We demonstrate
that by carefully calibrating the ratio of correct to misconception examples in
the training data - sometimes as low as 0.25 - it is possible to develop CSMs
that satisfy both properties. Our insights enhance our understanding of
AI-based student models and pave the way for effective adaptive learning
systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How much do contextualized representations encode long-range context? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12292v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12292v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simeng Sun, Cheng-Ping Hsieh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We analyze contextual representations in neural autoregressive language
models, emphasizing long-range contexts that span several thousand tokens. Our
methodology employs a perturbation setup and the metric
\emph{Anisotropy-Calibrated Cosine Similarity}, to capture the degree of
contextualization of long-range patterns from the perspective of representation
geometry. We begin the analysis with a case study on standard decoder-only
Transformers, demonstrating that similar perplexity can exhibit markedly
different downstream task performance, which can be explained by the difference
in contextualization of long-range content. Next, we extend the analysis to
other models, covering recent novel architectural designs and various training
configurations. The representation-level results illustrate a reduced capacity
for high-complexity (i.e., less compressible) sequences across architectures,
and that fully recurrent models rely heavily on local context, whereas hybrid
models more effectively encode the entire sequence structure. Finally,
preliminary analysis of model size and training configurations on the encoding
of long-range context suggest potential directions for improving existing
language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Prompt</span>-Based Knowledge Graph Foundation Model for Universal In-Context
  Reasoning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12288v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12288v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanning Cui, Zequn Sun, Wei Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extensive knowledge graphs (KGs) have been constructed to facilitate
knowledge-driven tasks across various scenarios. However, existing work usually
develops separate reasoning models for different KGs, lacking the ability to
generalize and transfer knowledge across diverse KGs and reasoning settings. In
this paper, we propose a prompt-based KG foundation model via in-context
learning, namely KG-ICL, to achieve a universal reasoning ability.
Specifically, we introduce a prompt graph centered with a query-related example
fact as context to understand the query relation. To encode prompt graphs with
the generalization ability to unseen entities and relations in queries, we
first propose a unified tokenizer that maps entities and relations in prompt
graphs to predefined tokens. Then, we propose two message passing neural
networks to perform prompt encoding and KG reasoning, respectively. We conduct
evaluation on 43 different KGs in both transductive and inductive settings.
Results indicate that the proposed KG-ICL outperforms baselines on most
datasets, showcasing its outstanding generalization and universal reasoning
capabilities. The source code is accessible on GitHub:
https://github.com/nju-websoft/KG-ICL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the 38th Conference on Neural Information Processing
  Systems (NeurIPS 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical
  Decision-Support Setting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxime Kayser, Bayar Menzat, Cornelius Emde, Bogdan Bercean, Alex Novak, Abdala Espinosa, Bartlomiej W. Papiez, Susanne Gaube, Thomas Lukasiewicz, Oana-Maria Camburu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing capabilities of AI models are leading to their wider use,
including in safety-critical domains. Explainable AI (XAI) aims to make these
models safer to use by making their inference process more transparent.
However, current explainability methods are seldom evaluated in the way they
are intended to be used: by real-world end users. To address this, we conducted
a large-scale user study with 85 healthcare practitioners in the context of
human-AI collaborative chest X-ray analysis. We evaluated three types of
explanations: visual explanations (saliency maps), natural language
explanations, and a combination of both modalities. We specifically examined
how different explanation types influence users depending on whether the AI
advice and explanations are factually correct. We find that text-based
explanations lead to significant over-reliance, which is alleviated by
combining them with saliency maps. We also observe that the quality of
explanations, that is, how much factually correct information they entail, and
how much this aligns with AI correctness, significantly impacts the usefulness
of the different explanation types.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Oversmoothing: Evaluating DDPM and MSE for Scalable Speech
  Synthesis in ASR <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12279v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12279v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christoph Minixhofer, Ondrej Klejch, Peter Bell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetically generated speech has rapidly approached human levels of
naturalness. However, the paradox remains that ASR systems, when trained on TTS
output that is judged as natural by humans, continue to perform badly on real
speech. In this work, we explore whether this phenomenon is due to the
oversmoothing behaviour of models commonly used in TTS, with a particular focus
on the behaviour of TTS-for-ASR as the amount of TTS training data is scaled
up. We systematically compare Denoising Diffusion Probabilistic Models (DDPM)
to Mean Squared Error (MSE) based models for TTS, when used for ASR model
training. We test the scalability of the two approaches, varying both the
number hours, and the number of different speakers. We find that for a given
model size, DDPM can make better use of more data, and a more diverse set of
speakers, than MSE models. We achieve the best reported ratio between real and
synthetic speech WER to date (1.46), but also find that a large gap remains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review at ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Controlled Automatic Task-Specific Synthetic Data Generation for
  Hallucination Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Xie, Karan Aggarwal, Aitzaz Ahmad, Stephen Lau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to automatically generate non-trivial
task-specific synthetic datasets for hallucination detection. Our approach
features a two-step generation-selection pipeline, using hallucination pattern
guidance and a language style alignment during generation. Hallucination
pattern guidance leverages the most important task-specific hallucination
patterns while language style alignment aligns the style of the synthetic
dataset with benchmark text. To obtain robust supervised detectors from
synthetic datasets, we also adopt a data mixture strategy to improve
performance robustness and generalization. Our results on three datasets show
that our generated hallucination text is more closely aligned with
non-hallucinated text versus baselines, to train hallucination detectors with
better generalization. Our hallucination detectors trained on synthetic
datasets outperform in-context-learning (ICL)-based detectors by a large margin
of 32%. Our extensive experiments confirm the benefits of our approach with
cross-task and cross-generator generalization. Our data-mixture-based training
further improves the generalization and robustness of hallucination detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kallini et al. (2024) do not compare impossible languages with
  constituency-based ones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Hunter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A central goal of linguistic theory is to find a precise characterization of
the notion "possible human language", in the form of a computational device
that is capable of describing all and only the languages that can be acquired
by a typically developing human child. The success of recent large language
models (LLMs) in NLP applications arguably raises the possibility that LLMs
might be computational devices that meet this goal. This would only be the case
if, in addition to succeeding in learning human languages, LLMs struggle to
learn "impossible" human languages. Kallini et al. (2024; "Mission: Impossible
Language Models", Proc. ACL) conducted experiments aiming to test this by
training GPT-2 on a variety of synthetic languages, and found that it learns
some more successfully than others. They present these asymmetries as support
for the idea that LLMs' inductive biases align with what is regarded as
"possible" for human languages, but the most significant comparison has a
confound that makes this conclusion unwarranted. In this paper I explain the
confound and suggest some ways forward towards constructing a comparison that
appropriately tests the underlying issue.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Automatic and Cost-Efficient Peer-<span class="highlight-title">Review</span> Framework for Language
  Generation Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12265v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12265v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Chen, Weihang Su, Zhumin Chu, Haitao Li, Qinyao Ai, Yiqun Liu, Min Zhang, Shaoping Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of large language models (LLMs), how to
efficiently evaluate them has become an important research question. Existing
evaluation methods often suffer from high costs, limited test formats, the need
of human references, and systematic evaluation biases. To address these
limitations, our study introduces the Auto-PRE, an automatic LLM evaluation
framework based on peer review. In contrast to previous studies that rely on
human annotations, Auto-PRE selects evaluator LLMs automatically based on their
inherent traits including consistency, self-confidence, and pertinence. We
conduct extensive experiments on three tasks: summary generation, non-factoid
question-answering, and dialogue generation. Experimental results indicate our
Auto-PRE achieves state-of-the-art performance at a lower cost. Moreover, our
study highlights the impact of prompt strategies and evaluation formats on
evaluation performance, offering guidance for method optimization in the
future.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for
  Retrieval-Augmented Generation with Enhanced Data Diversity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintao Liu, Ruixue Ding, Linhao Zhang, Pengjun Xie, Fie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) aims to enhance large language models
(LLMs) to generate more accurate and reliable answers with the help of the
retrieved context from external knowledge sources, thereby reducing the
incidence of hallucinations. Despite the advancements, evaluating these systems
remains a crucial research area due to the following issues: (1) Limited data
diversity: The insufficient diversity of knowledge sources and query types
constrains the applicability of RAG systems; (2) Obscure problems location:
Existing evaluation methods have difficulty in locating the stage of the RAG
pipeline where problems occur; (3) Unstable retrieval evaluation: These methods
often fail to effectively assess retrieval performance, particularly when the
chunking strategy changes. To tackle these challenges, we propose a
Comprehensive Full-chain Evaluation (CoFE-RAG) framework to facilitate thorough
evaluation across the entire RAG pipeline, including chunking, retrieval,
reranking, and generation. To effectively evaluate the first three phases, we
introduce multi-granularity keywords, including coarse-grained and fine-grained
keywords, to assess the retrieved context instead of relying on the annotation
of golden chunks. Moreover, we release a holistic benchmark dataset tailored
for diverse data scenarios covering a wide range of document formats and query
types. We demonstrate the utility of the CoFE-RAG framework by conducting
experiments to evaluate each stage of RAG systems. Our evaluation method
provides unique insights into the effectiveness of RAG systems in handling
diverse data scenarios, offering a more nuanced understanding of their
capabilities and limitations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EPS-MoE: Expert Pipeline Scheduler for Cost-Efficient MoE Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulei Qian, Fengcun Li, Xiangyang Ji, Xiaoyu Zhao, Jianchao Tan, Kefeng Zhang, Xunliang Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) has revolutionized the field of artificial
intelligence, with their capabilities expanding rapidly due to advances in deep
learning and increased computational resources. The mixture-of-experts (MoE)
model has emerged as a prominent architecture in the field of LLM, better
balancing the model performance and computational efficiency. MoE architecture
allows for effective scaling and efficient parallel processing, but the GEMM
(General Matrix Multiply) of MoE and the large parameters introduce challenges
in terms of computation efficiency and communication overhead, which becomes
the throughput bottleneck during inference. Applying a single parallelism
strategy like EP, DP, PP, etc. to MoE architecture usually achieves sub-optimal
inference throughput, the straightforward combinations of existing different
parallelisms on MoE can not obtain optimal inference throughput yet. This paper
introduces EPS-MoE, a novel expert pipeline scheduler for MoE that goes beyond
the existing inference parallelism schemes. Our approach focuses on optimizing
the computation of MoE FFN (FeedForward Network) modules by dynamically
selecting the best kernel implementation of GroupGemm and DenseGemm for
different loads and adaptively overlapping these computations with
\textit{all2all} communication, leading to a substantial increase in
throughput. Our experimental results demonstrate an average 21% improvement in
prefill throughput over existing parallel inference methods. Specifically, we
validated our method on DeepSeekV2, a highly optimized model claimed to achieve
a prefill throughput of 100K tokens per second. By applying EPS-MoE, we further
accelerated it to at least 120K tokens per second.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with
  Large Language Models for Multi-Behavior Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On A Scale From 1 to 5: Quantifying Hallucination in Faithfulness
  Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaonan Jing, Srinivas Billa, Danny Godbout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucination has been a popular topic in natural language generation (NLG).
In real-world applications, unfaithful content can result in bad data quality
or loss of trust from end users. Thus, it is crucial to fact-check before
adopting NLG for production usage, which can be expensive if done manually. In
this paper, we investigate automated faithfulness evaluation in guided NLG. We
developed a rubrics template and use large language models (LLMs) to score the
generation into quantifiable scales. We compared popular LLMs as well as the
widely adopted natural language inference (NLI) models in scoring quality and
sensitivity. In addition, we developed methods to generation synthetic
unfaithful data, as well as a heuristics to quantify the percentage of
hallucination. Our results on 4 travel-domain industry dataset show that GPT-4
can provide accurate judgement and explanation on whether a source and a
generation are factually consistent. Furthermore, we found that tuning NLI
models on synthetic data can improve performance. Lastly, we present insights
on latency and cost for deploying such system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmnixR: Evaluating Omni-modality Language Models on Reasoning across
  Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lichang Chen, Hexiang Hu, Mingda Zhang, Yiwen Chen, Zifeng Wang, Yandong Li, Pranav Shyam, Tianyi Zhou, Heng Huang, Ming-Hsuan Yang, Boqing Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce OmnixR, an evaluation suite designed to benchmark SoTA
Omni-modality Language Models, such as GPT-4o and Gemini. Evaluating OLMs,
which integrate multiple modalities such as text, vision, and audio, presents
unique challenges. Particularly, the user message might often consist of
multiple modalities, such that OLMs have to establish holistic understanding
and reasoning across modalities to accomplish the task. Existing benchmarks are
limited to single modality or dual-modality tasks, overlooking comprehensive
multi-modal assessments of model reasoning. To address this, OmnixR offers two
evaluation variants: (1)synthetic subset: a synthetic dataset generated
automatically by translating text into multiple modalities--audio, images,
video, and hybrids (Omnify). (2)realistic subset: a real-world dataset,
manually curated and annotated by experts, for evaluating cross-modal reasoning
in natural settings. OmnixR presents a unique evaluation towards assessing OLMs
over a diverse mix of modalities, such as a question that involves video,
audio, and text, providing a rigorous cross-modal reasoning testbed unlike any
existing benchmarks. Our experiments find that all state-of-the-art OLMs
struggle with OmnixR questions that require integrating information from
multiple modalities to answer. Further analysis highlights differences in
reasoning behavior, underscoring the challenges of omni-modal AI alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harbani Jaggi, Kashyap Murali, Eve Fleisig, Erdem Bıyık
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When annotators disagree, predicting the labels given by individual
annotators can capture nuances overlooked by traditional label aggregation. We
introduce three approaches to predicting individual annotator ratings on the
toxicity of text by incorporating individual annotator-specific information: a
neural collaborative filtering (NCF) approach, an in-context learning (ICL)
approach, and an intermediate embedding-based architecture. We also study the
utility of demographic information for rating prediction. NCF showed limited
utility; however, integrating annotator history, demographics, and survey
information permits both the embedding-based architecture and ICL to
substantially improve prediction accuracy, with the embedding-based
architecture outperforming the other methods. We also find that, if
demographics are predicted from survey information, using these imputed
demographics as features performs comparably to using true demographic data.
This suggests that demographics may not provide substantial information for
modeling ratings beyond what is captured in survey responses. Our findings
raise considerations about the relative utility of different types of annotator
information and provide new approaches for modeling annotators in subjective
NLP tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Negative-<span class="highlight-title">Prompt</span>-driven Alignment for Generative Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12194v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12194v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiqi Qiao, Ning Xv, Biao Liu, Xin Geng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have achieved remarkable capabilities, but aligning
their outputs with human values and preferences remains a significant
challenge. Existing alignment methods primarily focus on positive examples
while overlooking the importance of negative responses in guiding models away
from undesirable behaviors. For instance, the widely-used alignment datasets
reveals a scarcity of explicit negative examples that contradict human values,
hindering its ability to discourage harmful or biased outputs during training.
To address this limitation, we propose NEAT, i.e., NEgative-prompt-driven
AlignmenT, to introduce negative prompts to generate undesirable responses
alongside positive examples during the optimization process. NEAT explicitly
penalizes the model for producing harmful outputs, guiding it not only toward
desirable behaviors but also steering it away from generating undesirable,
biased responses. This dual feedback mechanism enables better alignment with
human preferences, crucial in contexts where avoiding harm is paramount.
Starting from a pre-trained language model, NEAT performs online alignment by
incorporating a ranking loss derived from an expanded preference dataset
containing both positive and negative examples. Extensive experiments validate
NEAT's effectiveness in significantly enhancing language models' alignment with
human values and preferences.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BIRD: A Trustworthy Bayesian Inference Framework for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Feng, Ben Zhou, Weidong Lin, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predictive models often need to work with incomplete information in
real-world tasks. Consequently, they must provide reliable probability or
confidence estimation, especially in large-scale decision making and planning
tasks. Current large language models (LLM) are insufficient for such accurate
estimations, but they can generate relevant factors that may affect the
probabilities, produce coarse-grained probabilities when the information is
more complete, and help determine which factors are relevant to specific
downstream contexts. In this paper, we make use of these capabilities of LLMs
to provide a significantly more accurate probabilistic estimation. We propose
BIRD, a novel probabilistic inference framework that aligns a Bayesian network
with LLM abductions and then estimates more accurate probabilities in a
deduction step. We show BIRD provides reliable probability estimations that are
30\% better than those provided directly by LLM baselines. These estimates can
further contribute to better and more trustworthy decision-making.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Energy and Carbon Considerations of Fine-Tuning <span class="highlight-title">BERT</span> <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10267v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10267v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaorong Wang, Clara Na, Emma Strubell, Sorelle Friedler, Sasha Luccioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP
community, existing work quantifying energy costs and associated carbon
emissions has largely focused on language model pre-training. Although a single
pre-training run draws substantially more energy than fine-tuning, fine-tuning
is performed more frequently by many more individual actors, and thus must be
accounted for when considering the energy and carbon footprint of NLP. In order
to better characterize the role of fine-tuning in the landscape of energy and
carbon emissions in NLP, we perform a careful empirical study of the
computational costs of fine-tuning across tasks, datasets, hardware
infrastructure and measurement modalities. Our experimental results allow us to
place fine-tuning energy and carbon costs into perspective with respect to
pre-training and inference, and outline recommendations to NLP researchers and
practitioners who wish to improve their fine-tuning energy efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings; First two authors contributed equally; 12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ÚFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual
  Coreference Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.14391v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.14391v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milan Straka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present CorPipe, the winning entry to the CRAC 2023 Shared Task on
Multilingual Coreference Resolution. Our system is an improved version of our
earlier multilingual coreference pipeline, and it surpasses other participants
by a large margin of 4.5 percent points. CorPipe first performs mention
detection, followed by coreference linking via an antecedent-maximization
approach on the retrieved spans. Both tasks are trained jointly on all
available corpora using a shared pretrained language model. Our main
improvements comprise inputs larger than 512 subwords and changing the mention
decoding to support ensembling. The source code is available at
https://github.com/ufal/crac2023-corpipe.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CRAC 2023 (the Sixth Workshop on Computational Models of
  Reference, Anaphora and Coreference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ÚFAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for
  Coreference Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.07278v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.07278v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milan Straka, Jana Straková
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We describe the winning submission to the CRAC 2022 Shared Task on
Multilingual Coreference Resolution. Our system first solves mention detection
and then coreference linking on the retrieved spans with an
antecedent-maximization approach, and both tasks are fine-tuned jointly with
shared Transformer weights. We report results of fine-tuning a wide range of
pretrained models. The center of this contribution are fine-tuned multilingual
models. We found one large multilingual model with sufficiently large encoder
to increase performance on all datasets across the board, with the benefit not
limited only to the underrepresented languages or groups of typologically
relative languages. The source code is available at
https://github.com/ufal/crac2022-corpipe.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CRAC 2022 (Fifth Workshop on Computational Models of
  Reference, Anaphora and Coreference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Source Conversational AI with SpeechBrain 1.0 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00463v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00463v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,
focused particularly on speech processing tasks such as speech recognition,
speech enhancement, speaker recognition, text-to-speech, and much more. It
promotes transparency and replicability by releasing both the pre-trained
models and the complete "recipes" of code and algorithms required for training
them. This paper presents SpeechBrain 1.0, a significant milestone in the
evolution of the toolkit, which now has over 200 recipes for speech, audio, and
language processing tasks, and more than 100 models available on Hugging Face.
SpeechBrain 1.0 introduces new technologies to support diverse learning
modalities, Large Language Model (LLM) integration, and advanced decoding
strategies, along with novel models, tasks, and modalities. It also includes a
new benchmark repository, offering researchers a unified platform for
evaluating models across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Journal of Machine Learning research (JMLR), Machine
  Learning Open Source Software</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of
  the Noisy Channel <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brendan King, Jeffrey Flanigan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training task-oriented dialogue systems typically requires turn-level
annotations for interacting with their APIs: e.g. a dialogue state and the
system actions taken at each step. These annotations can be costly to produce,
error-prone, and require both domain and annotation expertise. With advances in
LLMs, we hypothesize that unlabeled data and a schema definition are sufficient
for building a working task-oriented dialogue system, completely unsupervised.
We consider a novel unsupervised setting of only (1) a well-defined API schema
(2) a set of unlabeled dialogues between a user and agent. We propose an
innovative approach using expectation-maximization (EM) that infers turn-level
annotations as latent variables using a noisy channel model to build an
end-to-end dialogue agent. Evaluating our approach on the MultiWOZ benchmark,
our method more than doubles the dialogue success rate of a strong GPT-3.5
baseline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be presented at Empirical Methods in Natural Language Processing
  (EMNLP 2024). 18 Pages, 8 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding Figurative Meaning through Explainable Visual Entailment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01474v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01474v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arkadiy Saakyan, Shreyas Kulkarni, Tuhin Chakrabarty, Smaranda Muresan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (VLMs) have demonstrated strong capabilities in
tasks requiring a fine-grained understanding of literal meaning in images and
text, such as visual question-answering or visual entailment. However, there
has been little exploration of these models' capabilities when presented with
images and captions containing figurative meaning, such as metaphors or humor.
To close this gap, we propose a new task framing the figurative meaning
understanding problem as an explainable visual entailment task, where the model
has to predict whether the image (premise) entails a caption (hypothesis) and
justify the predicted label with a textual explanation. The figurative
phenomena can be present either in the image, the caption, or both. Utilizing a
human-AI collaboration approach, we build the accompanying expert-verified
dataset V-FLUTE, containing 6,027 {image, caption, label, explanation}
instances spanning five diverse figurative phenomena: metaphors, similes,
idioms, sarcasm, and humor. Through automatic evaluation, we find that VLMs
struggle to generalize from literal to figurative meaning, particularly when it
is present in images. Further, we identify common types of errors in VLM
reasoning via human evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ToBlend: Token-Level Blending With an Ensemble of LLMs to Attack
  AI-Generated Text Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Huang, Haewoon Kwak, Jisun An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The robustness of AI-content detection models against sophisticated
adversarial strategies, such as paraphrasing or word switching, is a rising
concern in natural language generation (NLG) applications. This study proposes
ToBlend, a novel token-level ensemble text generation method to challenge the
robustness of current AI-content detection approaches by utilizing multiple
sets of candidate generative large language models (LLMs). By randomly sampling
token(s) from candidate LLMs sets, we find ToBlend significantly drops the
performance of most mainstream AI-content detection methods. We evaluate the
text quality produced under different ToBlend settings based on annotations
from experienced human experts. We proposed a fine-tuned Llama3.1 model to
distinguish the ToBlend generated text more accurately. Our findings underscore
our proposed text generation approach's great potential in deceiving and
improving detection models. Our datasets, codes, and annotations are
open-sourced.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ARR Oct-2024 Cycle</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ITINERA: Integrating Spatial Optimization with Large Language Models for
  Open-domain Urban Itinerary Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07204v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07204v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Citywalk, a recently popular form of urban travel, requires genuine
personalization and understanding of fine-grained requests compared to
traditional itinerary planning. In this paper, we introduce the novel task of
Open-domain Urban Itinerary Planning (OUIP), which generates personalized urban
itineraries from user requests in natural language. We then present ITINERA, an
OUIP system that integrates spatial optimization with large language models to
provide customized urban itineraries based on user needs. This involves
decomposing user requests, selecting candidate points of interest (POIs),
ordering the POIs based on cluster-aware spatial optimization, and generating
the itinerary. Experiments on real-world datasets and the performance of the
deployed system demonstrate our system's capacity to deliver personalized and
spatially coherent itineraries compared to current solutions. Source codes of
ITINERA are available at https://github.com/YihongT/ITINERA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CELL your Model: Contrastive Explanations for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11785v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11785v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronny Luss, Erik Miehling, Amit Dhurandhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI,
such as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a scoring function that has meaning to the user and not necessarily a
specific real valued quantity (viz. class label). We offer two algorithms for
finding contrastive explanations: i) A myopic algorithm, which although
effective in creating contrasts, requires many model calls and ii) A budgeted
algorithm, our main algorithmic contribution, which intelligently creates
contrasts adhering to a query budget, necessary for longer contexts. We show
the efficacy of these methods on diverse natural language tasks such as
open-text generation, automated red teaming, and explaining conversational
degradation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Disentangling Singlish Discourse Particles with Task-Driven
  Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20366v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20366v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linus Tze En Foo, Lynnette Hui Xian Ng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Singlish, or formally Colloquial Singapore English, is an English-based
creole language originating from the SouthEast Asian country Singapore. The
language contains influences from Sinitic languages such as Chinese dialects,
Malay, Tamil and so forth. A fundamental task to understanding Singlish is to
first understand the pragmatic functions of its discourse particles, upon which
Singlish relies heavily to convey meaning. This work offers a preliminary
effort to disentangle the Singlish discourse particles (lah, meh and hor) with
task-driven representation learning. After disentanglement, we cluster these
discourse particles to differentiate their pragmatic functions, and perform
Singlish-to-English machine translation. Our work provides a computational
method to understanding Singlish discourse particles, and opens avenues towards
a deeper comprehension of the language and its usage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DOCE: Finding the Sweet Spot for Execution-Based Code Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13745v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13745v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haau-Sing Li, Patrick Fernandes, Iryna Gurevych, André F. T. Martins
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, a diverse set of decoding and reranking procedures have been shown
effective for LLM-based code generation. However, a comprehensive framework
that links and experimentally compares these methods is missing. We address
this by proposing Decoding Objectives for Code Execution, a comprehensive
framework that includes candidate generation, $n$-best reranking, minimum Bayes
risk (MBR) decoding, and self-debugging as the core components. We then study
the contributions of these components through execution-based evaluation
metrics. Our findings highlight the importance of execution-based methods and
the difference gap between execution-based and execution-free methods.
Furthermore, we assess the impact of filtering based on trial unit tests, a
simple and effective strategy that has been often overlooked in prior works. We
also propose self-debugging on multiple candidates, obtaining state-of-the-art
performance on reranking for code generation. We expect our framework to
provide a solid guideline for future research on code generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages (32 including appendix), 5 figures, 25 tables. Prompts are
  provided in the GitHub repository to avoid potential text overlap with other
  papers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music
  Scores for All Singing Tasks <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13832v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13832v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Changhao Pan, Wenxiang Guo, Ruiqi Li, Zhiyuan Zhu, Jialei Wang, Wenhao Xu, Jingyu Lu, Zhiqing Hong, Chuxin Wang, LiChao Zhang, Jinzheng He, Ziyue Jiang, Yuxin Chen, Chen Yang, Jiecheng Zhou, Xinyu Cheng, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scarcity of high-quality and multi-task singing datasets significantly
hinders the development of diverse controllable and personalized singing tasks,
as existing singing datasets suffer from low quality, limited diversity of
languages and singers, absence of multi-technique information and realistic
music scores, and poor task suitability. To tackle these problems, we present
GTSinger, a large global, multi-technique, free-to-use, high-quality singing
corpus with realistic music scores, designed for all singing tasks, along with
its benchmarks. Particularly, (1) we collect 80.59 hours of high-quality
singing voices, forming the largest recorded singing dataset; (2) 20
professional singers across nine widely spoken languages offer diverse timbres
and styles; (3) we provide controlled comparison and phoneme-level annotations
of six commonly used singing techniques, helping technique modeling and
control; (4) GTSinger offers realistic music scores, assisting real-world
musical composition; (5) singing voices are accompanied by manual
phoneme-to-audio alignments, global style labels, and 16.16 hours of paired
speech for various singing tasks. Moreover, to facilitate the use of GTSinger,
we conduct four benchmark experiments: technique-controllable singing voice
synthesis, technique recognition, style transfer, and speech-to-singing
conversion. The corpus and demos can be found at http://gtsinger.github.io. We
provide the dataset and the code for processing data and conducting benchmarks
at https://huggingface.co/datasets/GTSinger/GTSinger and
https://github.com/GTSinger/GTSinger.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024 (Spotlight)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reward-Robust RLHF in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15360v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15360v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzi Yan, Xingzhou Lou, Jialian Li, Yiping Zhang, Jian Xie, Chao Yu, Yu Wang, Dong Yan, Yuan Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) continue to progress toward more advanced
forms of intelligence, Reinforcement Learning from Human Feedback (RLHF) is
increasingly seen as a key pathway toward achieving Artificial General
Intelligence (AGI). However, the reliance on reward-model-based (RM-based)
alignment methods introduces significant challenges due to the inherent
instability and imperfections of Reward Models (RMs), which can lead to
critical issues such as reward hacking and misalignment with human intentions.
In this paper, we introduce a reward-robust RLHF framework aimed at addressing
these fundamental challenges, paving the way for more reliable and resilient
learning in LLMs. Our approach introduces a novel optimization objective that
carefully balances performance and robustness by incorporating Bayesian Reward
Model Ensembles (BRME) to model the uncertainty set of reward functions. This
allows the framework to integrate both nominal performance and minimum reward
signals, ensuring more stable learning even with imperfect RMs. Empirical
results demonstrate that our framework consistently outperforms baselines
across diverse benchmarks, showing improved accuracy and long-term stability.
We also provide a theoretical analysis, demonstrating that reward-robust RLHF
approaches the stability of constant reward settings, which proves to be
acceptable even in a stochastic-case analysis. Together, these contributions
highlight the framework potential to enhance both the performance and stability
of LLM alignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust ASR Error Correction with Conservative Data Filtering <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13300v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13300v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takuma Udagawa, Masayuki Suzuki, Masayasu Muraoka, Gakuto Kurata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Error correction (EC) based on large language models is an emerging
technology to enhance the performance of automatic speech recognition (ASR)
systems. Generally, training data for EC are collected by automatically pairing
a large set of ASR hypotheses (as sources) and their gold references (as
targets). However, the quality of such pairs is not guaranteed, and we observed
various types of noise which can make the EC models brittle, e.g. inducing
overcorrection in out-of-domain (OOD) settings. In this work, we propose two
fundamental criteria that EC training data should satisfy: namely, EC targets
should (1) improve linguistic acceptability over sources and (2) be inferable
from the available context (e.g. source phonemes). Through these criteria, we
identify low-quality EC pairs and train the models not to make any correction
in such cases, the process we refer to as conservative data filtering. In our
experiments, we focus on Japanese ASR using a strong Conformer-CTC as the
baseline and finetune Japanese LLMs for EC. Through our evaluation on a suite
of 21 internal benchmarks, we demonstrate that our approach can significantly
reduce overcorrection and improve both the accuracy and quality of ASR results
in the challenging OOD settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Details Make a Difference: Object State-Sensitive Neurorobotic Task
  Planning <span class="chip">ICANN24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09988v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09988v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaowen Sun, Xufeng Zhao, Jae Hee Lee, Wenhao Lu, Matthias Kerzel, Stefan Wermter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The state of an object reflects its current status or condition and is
important for a robot's task planning and manipulation. However, detecting an
object's state and generating a state-sensitive plan for robots is challenging.
Recently, pre-trained Large Language Models (LLMs) and Vision-Language Models
(VLMs) have shown impressive capabilities in generating plans. However, to the
best of our knowledge, there is hardly any investigation on whether LLMs or
VLMs can also generate object state-sensitive plans. To study this, we
introduce an Object State-Sensitive Agent (OSSA), a task-planning agent
empowered by pre-trained neural networks. We propose two methods for OSSA: (i)
a modular model consisting of a pre-trained vision processing module (dense
captioning model, DCM) and a natural language processing model (LLM), and (ii)
a monolithic model consisting only of a VLM. To quantitatively evaluate the
performances of the two methods, we use tabletop scenarios where the task is to
clear the table. We contribute a multimodal benchmark dataset that takes object
states into consideration. Our results show that both methods can be used for
object state-sensitive tasks, but the monolithic approach outperforms the
modular approach. The code for OSSA is available at
https://github.com/Xiao-wen-Sun/OSSA
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICANN24, Switzerland</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain
  Readability Assessment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14463v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14463v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tarek Naous, Michael J. Ryan, Anton Lavrouk, Mohit Chandra, Wei Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a comprehensive evaluation of large language models for
multilingual readability assessment. Existing evaluation resources lack domain
and language diversity, limiting the ability for cross-domain and cross-lingual
analyses. This paper introduces ReadMe++, a multilingual multi-domain dataset
with human annotations of 9757 sentences in Arabic, English, French, Hindi, and
Russian, collected from 112 different data sources. This benchmark will
encourage research on developing robust multilingual readability assessment
methods. Using ReadMe++, we benchmark multilingual and monolingual language
models in the supervised, unsupervised, and few-shot prompting settings. The
domain and language diversity in ReadMe++ enable us to test more effective
few-shot prompting, and identify shortcomings in state-of-the-art unsupervised
methods. Our experiments also reveal exciting results of superior domain
generalization and enhanced cross-lingual transfer capabilities by models
trained on ReadMe++. We will make our data publicly available and release a
python package tool for multilingual sentence readability prediction using our
trained models at: https://github.com/tareknaous/readme
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Explainable to Interpretable Deep Learning for Natural Language
  Processing in Healthcare: How Far from Reality? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11894v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11894v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangming Huang, Yingya Li, Shoaib Jameel, Yunfei Long, Giorgos Papanastasiou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning (DL) has substantially enhanced natural language processing
(NLP) in healthcare research. However, the increasing complexity of DL-based
NLP necessitates transparent model interpretability, or at least
explainability, for reliable decision-making. This work presents a thorough
scoping review of explainable and interpretable DL in healthcare NLP. The term
"eXplainable and Interpretable Artificial Intelligence" (XIAI) is introduced to
distinguish XAI from IAI. Different models are further categorized based on
their functionality (model-, input-, output-based) and scope (local, global).
Our analysis shows that attention mechanisms are the most prevalent emerging
IAI technique. The use of IAI is growing, distinguishing it from XAI. The major
challenges identified are that most XIAI does not explore "global" modelling
processes, the lack of best practices, and the lack of systematic evaluation
and benchmarks. One important opportunity is to use attention mechanisms to
enhance multi-modal XIAI for personalized medicine. Additionally, combining DL
with causal logic holds promise. Our discussion encourages the integration of
XIAI in Large Language Models (LLMs) and domain-specific smaller models. In
conclusion, XIAI adoption in healthcare requires dedicated in-house expertise.
Collaboration with domain experts, end-users, and policymakers can lead to
ready-to-use XIAI methods across NLP and medical tasks. While challenges exist,
XIAI techniques offer a valuable foundation for interpretable NLP algorithms in
healthcare.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by Computational and Structural
  Biotechnology Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>ing Explicit and Implicit Knowledge for Multi-hop Question
  Answering Based on Human Reading Process <span class="chip">COLING 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.19350v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.19350v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangming Huang, Yunfei Long, Cunjin Luo, Jiaxing Shen, Xia Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to
simulate human reasoning and inference processes, achieving proficient
performance in multi-hop QA. However, a gap persists between PLMs' reasoning
abilities and those of humans when tackling complex problems. Psychological
studies suggest a vital connection between explicit information in passages and
human prior knowledge during reading. Nevertheless, current research has given
insufficient attention to linking input passages and PLMs' pre-training-based
knowledge from the perspective of human cognition studies. In this study, we
introduce a Prompting Explicit and Implicit knowledge (PEI) framework, which
uses prompts to connect explicit and implicit knowledge, aligning with human
reading process for multi-hop QA. We consider the input passages as explicit
knowledge, employing them to elicit implicit knowledge through unified prompt
reasoning. Furthermore, our model incorporates type-specific reasoning via
prompts, a form of implicit knowledge. Experimental results show that PEI
performs comparably to the state-of-the-art on HotpotQA. Ablation studies
confirm the efficacy of our model in bridging and integrating explicit and
implicit knowledge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted at COLING 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram
  <span class="highlight-title">Dataset</span> of Over Half a Million Posts for Multilingual Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03293v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03293v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The work presented in this paper makes three scientific contributions with a
specific focus on mining and analysis of COVID-19-related posts on Instagram.
First, it presents a multilingual dataset of 500,153 Instagram posts about
COVID-19 published between January 2020 and September 2024. This dataset,
available at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in
161 different languages as well as 535,021 distinct hashtags. After the
development of this dataset, multilingual sentiment analysis was performed,
which involved classifying each post as positive, negative, or neutral. The
results of sentiment analysis are presented as a separate attribute in this
dataset. Second, it presents the results of performing sentiment analysis per
year from 2020 to 2024. The findings revealed the trends in sentiment related
to COVID-19 on Instagram since the beginning of the pandemic. For instance,
between 2020 and 2024, the sentiment trends show a notable shift, with positive
sentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from
44.19% to 58.34%. Finally, the paper also presents findings of
language-specific sentiment analysis. This analysis highlighted similar and
contrasting trends of sentiment across posts published in different languages
on Instagram. For instance, out of all English posts, 49.68% were positive,
14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts,
4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting
distinct differences in the sentiment distribution between these two languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Token Reweighting for Interpretable and Controllable Text
  Embeddings in CLIP <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eunji Kim, Kyuhong Shim, Simyung Chang, Sungroh Yoon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A text encoder within Vision-Language Models (VLMs) like CLIP plays a crucial
role in translating textual input into an embedding space shared with images,
thereby facilitating the interpretative analysis of vision tasks through
natural language. Despite the varying significance of different textual
elements within a sentence depending on the context, efforts to account for
variation of importance in constructing text embeddings have been lacking. We
propose a framework of Semantic Token Reweighting to build Interpretable text
embeddings (SToRI), which incorporates controllability as well. SToRI refines
the text encoding process in CLIP by differentially weighting semantic elements
based on contextual importance, enabling finer control over emphasis responsive
to data-driven insights and user preferences. The efficacy of SToRI is
demonstrated through comprehensive experiments on few-shot image classification
and image retrieval tailored to user preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>DSI: <span class="highlight-title">Prompt</span>-based Rehearsal-free Instance-wise Incremental
  Learning for Document Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan-Luc Huynh, Thuy-Trang Vu, Weiqing Wang, Yinwei Wei, Trung Le, Dragan Gasevic, Yuan-Fang Li, Thanh-Toan Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSI needs full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
prompt-based rehearsal-free approach for instance-wise incremental learning
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that BERT-based PromptDSI matches IncDSI
in managing forgetting while improving new corpora performance by more than 4%
Hits@10 on NQ320k and upto 3% MRR@10 on MS MARCO 300k.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Comparative Trap: Pairwise Comparisons Amplifies Biased Preferences
  of LLM Evaluators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12319v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12319v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hawon Jeong, ChaeHun Park, Jimin Hong, Hojoon Lee, Jaegul Choo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) are increasingly used as evaluators for
natural language generation tasks, ensuring unbiased assessments is essential.
However, LLM evaluators often display biased preferences, such as favoring
verbosity and authoritative tones. Our empirical analysis reveals that these
biases are exacerbated in pairwise evaluation, where LLMs directly compare two
outputs and easily prioritize superficial attributes. In contrast, pointwise
evaluation, which assesses outputs independently, is less susceptible to such
bias because each output is judged in isolation. To address the limitations of
the pairwise evaluation, we introduce a novel evaluation method, PRePair, which
integrates pointwise reasoning within a pairwise framework. PRePair effectively
alleviates biased preference, improving performance on the adversarial
benchmark (LLMBar) while outperforming pointwise evaluation on the standard
benchmark (MT-Bench).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Data Privacy in Large Language Models through Private
  Association Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18221v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18221v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Venditti, Elena Sofia Ruzzetti, Giancarlo A. Xompero, Cristina Giannone, Andrea Favalli, Raniero Romagnoli, Fabio Massimo Zanzotto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) require a significant redesign in solutions to
preserve privacy in data-intensive applications due to their text-generation
capabilities. Indeed, LLMs tend to memorize and emit private information when
maliciously prompted. In this paper, we introduce Private Association Editing
(PAE) as a novel defense approach for private data leakage. PAE is designed to
effectively remove Personally Identifiable Information (PII) without retraining
the model. Experimental results demonstrate the effectiveness of PAE with
respect to alternative baseline methods. We believe PAE will serve as a
critical tool in the ongoing effort to protect data privacy in LLMs,
encouraging the development of safer models for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DIRAS: Efficient LLM Annotation of Document Relevance in Retrieval
  Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingwei Ni, Tobias Schimanski, Meihong Lin, Mrinmaya Sachan, Elliott Ash, Markus Leippold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation (RAG) is widely employed to ground responses
to queries on domain-specific documents. But do RAG implementations leave out
important information when answering queries that need an integrated analysis
of information (e.g., Tell me good news in the stock market today.)? To address
these concerns, RAG developers need to annotate information retrieval (IR) data
for their domain of interest, which is challenging because (1) domain-specific
queries usually need nuanced definitions of relevance beyond shallow semantic
relevance; and (2) human or GPT-4 annotation is costly and cannot cover all
(query, document) pairs (i.e., annotation selection bias), thus harming the
effectiveness in evaluating IR recall. To address these challenges, we propose
DIRAS (Domain-specific Information Retrieval Annotation with Scalability), a
manual-annotation-free schema that fine-tunes open-sourced LLMs to consider
nuanced relevance definition and annotate (partial) relevance labels with
calibrated relevance scores. Extensive evaluation shows that DIRAS enables
smaller (8B) LLMs to achieve GPT-4-level performance on annotating and ranking
unseen (query, document) pairs, and is helpful for real-world RAG development.
All code, LLM generations, and human annotations can be found in
\url{https://github.com/EdisonNi-hku/DIRAS}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through
  N-shot Guided <span class="highlight-title">Prompt</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09879v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09879v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanchit Ahuja, Kumar Tanmay, Hardik Hansrajbhai Chauhan, Barun Patra, Kriti Aggarwal, Luciano Del Corro, Arindam Mitra, Tejas Indulal Dhamecha, Ahmed Awadallah, Monojit Choudhary, Vishrav Chaudhary, Sunayana Sitaram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable success of LLMs in English, there is a significant gap
in performance in non-English languages. In order to address this, we introduce
a novel recipe for creating a multilingual synthetic instruction tuning
dataset, sPhinX, which is created by selectively translating instruction
response pairs from English into 50 languages. We test the effectiveness of
sPhinx by using it to fine-tune two state-of-the-art models, Mistral-7B and
Phi-Small and then evaluating them across a comprehensive suite of multilingual
benchmarks that test reasoning, question answering, reading comprehension and
machine translation. Our results show that Mistral-7B and Phi-Small fine-tuned
with sPhinX perform better on an average by 5%pt for both the models when
compared to the base variants of these models. We also devise a strategy to
incorporate N-shot examples in each fine-tuning sample which further boosts the
performance of these models by 9%pt and 4%pt respectively respectively compared
to vanilla fine-tuning. To show efficacy of our data curation approach, we also
directly translate our original dataset to the target languages, and observe an
increase of 7%pt and 4%pt on both the models respectively. sPhinX outperforms
other multilingual instruction tuning datasets in both efficiency and
diversity, reducing dataset creation costs. It also maintains strong
performance on standard English LLM benchmarks, with minimal regression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 12 tables, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL systems have become crucial for translating natural language into
SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, the Execution Accuracy
(EX), the most prevalent evaluation metric, still shows many false positives
and negatives. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our metric improves
agreement with human experts (from 62 to 87.04 in Cohen's kappa) with
comprehensive context and sophisticated criteria. Our extensive experiments
yield several key insights: (1) Models' performance increases by over 2.6
points on average, substantially affecting rankings on Spider and BIRD
benchmarks; (2) The underestimation of models in EX primarily stems from
annotation quality issues; and (3) Model performance on particularly
challenging questions tends to be overestimated. This work contributes to a
more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixture of Experts Made Personalized: Federated <span class="highlight-title">Prompt</span> Learning for
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Luo, Chen Chen, Shandong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning for pre-trained Vision-Language Models (VLMs) like CLIP has
demonstrated potent applicability across diverse downstream tasks. This
lightweight approach has quickly gained traction from federated learning (FL)
researchers who seek to efficiently adapt VLMs to heterogeneous scenarios.
However, current federated prompt learning methods are habitually restricted to
the traditional FL paradigm, where the participating clients are generally only
allowed to download a single globally aggregated model from the server. While
justifiable for training full-sized models under federated settings, in this
work, we argue that this paradigm is ill-suited for lightweight prompts. By
facilitating the clients to download multiple pre-aggregated prompts as fixed
non-local experts, we propose Personalized Federated Mixture of Adaptive
Prompts (pFedMoAP), a novel FL framework that personalizes the prompt learning
process through the lens of Mixture of Experts (MoE). pFedMoAP implements a
local attention-based gating network that learns to generate enhanced text
features for better alignment with local image data on the client, benefiting
from both local and downloaded non-local adaptive prompt experts. The non-local
experts are sparsely selected from a server-maintained pool, fostering
collaborative learning across clients. To evaluate the proposed algorithm, we
conduct extensive experiments across 9 datasets under various heterogeneous
federated settings. The results show that pFedMoAP consistently outperforms the
state-of-the-art alternatives, underscoring its efficacy in personalizing
prompt learning for CLIP within the federated learning paradigm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Few-shot Learning for Multi-label Classification of Scientific
  Documents with Many Classes <span class="chip">SP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Schopf, Alexander Blatzheim, Nektarios Machner, Florian Matthes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific document classification is a critical task and often involves many
classes. However, collecting human-labeled data for many classes is expensive
and usually leads to label-scarce scenarios. Moreover, recent work has shown
that sentence embedding model fine-tuning for few-shot classification is
efficient, robust, and effective. In this work, we propose FusionSent
(Fusion-based Sentence Embedding Fine-tuning), an efficient and prompt-free
approach for few-shot classification of scientific documents with many classes.
FusionSent uses available training examples and their respective label texts to
contrastively fine-tune two different sentence embedding models. Afterward, the
parameters of both fine-tuned models are fused to combine the complementary
knowledge from the separate fine-tuning steps into a single model. Finally, the
resulting sentence embedding model is frozen to embed the training instances,
which are then used as input features to train a classification head. Our
experiments show that FusionSent significantly outperforms strong baselines by
an average of $6.0$ $F_{1}$ points across multiple scientific document
classification datasets. In addition, we introduce a new dataset for
multi-label classification of scientific documents, which contains 203,961
scientific articles and 130 classes from the arXiv category taxonomy. Code and
data are available at https://github.com/sebischair/FusionSent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 7th International Conference on Natural Language and
  Speech Processing (ICNLSP 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating
  Adequacy, Fluency, and Elegance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09945v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09945v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable performance in general
translation tasks. However, the increasing demand for high-quality translations
that are not only adequate but also fluent and elegant. To assess the extent to
which current LLMs can meet these demands, we introduce a suitable benchmark
for translating classical Chinese poetry into English. This task requires not
only adequacy in translating culturally and historically significant content
but also a strict adherence to linguistic fluency and poetic elegance. Our
study reveals that existing LLMs fall short of this task. To address these
issues, we propose RAT, a \textbf{R}etrieval-\textbf{A}ugmented machine
\textbf{T}ranslation method that enhances the translation process by
incorporating knowledge related to classical poetry. Additionally, we propose
an automatic evaluation metric based on GPT-4, which better assesses
translation quality in terms of adequacy, fluency, and elegance, overcoming the
limitations of traditional metrics. Our dataset and code will be made
available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic
  Preference Optimization <span class="highlight-title">Dataset</span> Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08688v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08688v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a novel methodology for generating synthetic Preference
Optimization (PO) datasets using multi-agent workflows. We evaluate the
effectiveness and potential of these workflows in automating and enhancing the
dataset generation process. PO dataset generation requires two modules: (1)
response evaluation, and (2) response generation. In the response evaluation
module, the responses from Large Language Models (LLMs) are evaluated and
ranked - a task typically carried out by human annotators that we automate
using LLMs. We assess the response evaluation module in a 2 step process. In
step 1, we assess LLMs as evaluators using three distinct prompting strategies.
In step 2, we apply the winning prompting strategy to compare the performance
of LLM-as-a-Judge, LLMs-as-a-Jury, and LLM Debate. Our evaluation shows that
GPT-4o-as-a-Judge is more consistent across all datasets. For the response
generation module, we use the identified LLM evaluator configuration and
compare different configurations of the LLM Feedback Loop. We use the win rate
to determine the best multi-agent configuration for generation. Experimenting
with various configurations, we find that the LLM Feedback Loop, with Llama as
the generator and Gemma as the reviewer, achieves a notable 71.8% and 73.8% win
rate over single-agent Llama and Gemma, respectively. After identifying the
best configurations for both modules, we generate our PO datasets using the
above pipeline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Token-based Decision Criteria Are Suboptimal in In-context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16535v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16535v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hakaze Cho, Yoshihiro Sakai, Mariko Kato, Kenshiro Tanaka, Akira Ishii, Naoya Inoue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-Context Learning (ICL) typically utilizes classification criteria from
output probabilities of manually selected label tokens. However, we argue that
such token-based classification criteria lead to suboptimal decision
boundaries, despite delicate calibrations through translation and constrained
rotation applied. To address this problem, we propose Hidden Calibration, which
renounces token probabilities and uses the nearest centroid classifier on the
LM's last hidden states. In detail, we assign the label of the nearest centroid
previously estimated from a calibration set to the test sample as the predicted
label. Our experiments on 6 models and 10 classification datasets indicate that
Hidden Calibration consistently outperforms current token-based baselines by
about 20%~50%, achieving a strong state-of-the-art in ICL. Our further analysis
demonstrates that Hidden Calibration finds better classification criteria with
less inter-class overlap, and LMs provide linearly separable intra-class
clusters with the help of demonstrations, which supports Hidden Calibration and
gives new insights into the principle of ICL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 15 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UNDIAL: Self-Distillation with Adjusted Logits for Robust Unlearning in
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10052v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10052v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yijiang River Dong, Hongzhou Lin, Mikhail Belkin, Ramon Huerta, Ivan Vulić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mitigating the retention of sensitive or private information in large
language models is essential for enhancing privacy and safety. Existing
unlearning methods, like Gradient Ascent and Negative Preference Optimization,
directly tune models to remove unwanted information. However, these methods
often become unstable because they fine-tune by maximizing cross-entropy loss,
which is the opposite of traditional loss minimization in learning. This
reversal creates instability, especially on larger datasets, as the model
struggles to balance unlearning with maintaining language capacity, leading to
over-unlearning. In this paper, we introduce UnDIAL (Unlearning via
Self-Distillation on Adjusted Logits), a novel and robust unlearning method.
Our approach leverages self-distillation to adjust logits and selectively
reduce the influence of targeted tokens. This technique ensures smooth
convergence and avoids catastrophic forgetting, even in challenging unlearning
tasks with large datasets and sequential unlearning requests. Extensive
experiments show that UnDIAL can achieve both robustness in unlearning and
scalability while maintaining stable training dynamics and resilience to
hyperparameter tuning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Instruction Following: Evaluating Inferential Rule Following of
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08440v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08440v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wangtao Sun, Chenxiang Zhang, XueYou Zhang, Xuanqing Yu, Ziyang Huang, Pei Chen, Haotian Xu, Shizhu He, Jun Zhao, Kang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Large Language Models (LLMs) have demonstrated strong ability, they
are further supposed to be controlled and guided by in real-world scenarios to
be safe, accurate, and intelligent. This demands the possession of capability
of LLMs. However, no prior work has made a clear evaluation of the inferential
rule-following capability of LLMs. Previous studies that try to evaluate the
inferential rule-following capability of LLMs fail to distinguish the
inferential rule-following scenarios from the instruction-following scenarios.
Therefore, this paper first clarifies the concept of inferential rule-following
and proposes a comprehensive benchmark, RuleBench, to evaluate a diversified
range of inferential rule-following abilities. Our experimental results on a
variety of LLMs show that they are still limited in following rules. Our
analysis based on the evaluation results provides insights into the
improvements for LLMs toward a better inferential rule-following intelligent
agent. We further propose Inferential Rule-Following Tuning (IRFT). The
experimental results show that through IRFT, LLMs can learn abstract
rule-following abilities from purely synthetic data and then generalize to
RuleBench. The data and code can be found at:
https://anonymous.4open.science/r/llm-rule-following-B3E3/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VersiCode: Towards Version-controllable Code Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07411v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07411v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongtong Wu, Weigang Wu, Xingyu Wang, Kang Xu, Suyu Ma, Bo Jiang, Ping Yang, Zhenchang Xing, Yuan-Fang Li, Gholamreza Haffari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have made tremendous strides in code generation,
but existing research fails to account for the dynamic nature of software
development, marked by frequent library updates. This gap significantly limits
LLMs' deployment in realistic settings. In this paper, we propose two novel
tasks aimed at bridging this gap: version-specific code completion (VSCC) and
version-aware code migration (VACM). In conjunction, we introduce VersiCode, a
comprehensive Python dataset specifically designed to evaluate LLMs on these
two tasks, together with a novel evaluation metric, Critical Diff Check
(CDC@1), which assesses code generation against evolving API requirements. We
conduct an extensive evaluation on VersiCode, which reveals that
version-controllable code generation is indeed a significant challenge, even
for GPT-4o and other strong frontier models. We believe the novel tasks,
dataset, and metric open up a new, important research direction that will
further enhance LLMs' real-world applicability. The code and resources can be
found at https://github.com/wutong8023/VersiCode.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic
  Evaluation Framework for LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11507v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11507v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanying Wang, Zeyu Ma, Pengfei Liu, Mingang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While various vertical domain large language models (LLMs) have been
developed, the challenge of automatically evaluating their performance across
different domains remains significant. Current benchmark-based evaluation
methods exhibit rigid, aimless interactions and rely on pre-collected static
datasets that are costly to build, inflexible across domains, and misaligned
with practical user needs. To address this issue, we revisit the evaluation
components and introduce two concepts: Benchmark+, which extends traditional
question-answer benchmark into a more flexible "strategy-criterion" format; and
Assessment+, which enhances the interaction process, enabling deeper
exploration and supporting both quantitative metrics and qualitative insights.
These concepts capture the nuanced behaviors of LLMs through richer, multi-turn
interactions. We propose an agent-based evaluation framework called TestAgent,
which implements these concepts through retrieval augmented generation and
reinforcement learning. Experiments on tasks ranging from constructing vertical
domain evaluation to activating existing benchmarks demonstrate the
effectiveness of TestAgent across various scenarios. We believe this work
offers an interesting perspective on automatic evaluation for LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LoraMap: Harnessing the Power of LoRA Connections 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16264v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16264v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyeryun Park, Jeongwon Kwak, Dongsuk Jang, Sumin Park, Jinwook Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fact-checking techniques can mitigate hallucinations in Large Language Models
(LLMs), a prominent issue in specialized domains. As parameter-efficient
techniques such as Low-Rank Adaptation (LoRA) can overcome substantial
computational overhead, some studies have explored the integration of multiple
LoRAs. While previous studies focus on parallel integration, this paper
investigates methods to establish connections among multiple LoRAs. We create
three reasoning datasets tailored to fact-checking and fine-tune individual
LoRAs, allowing them to view and reason from diverse perspectives. Then, we
explore strategies for allocating these reasoning LoRAs and introduce LoraMap,
an approach to map connections between them. The results of the fact-checking
task demonstrate that the performance of LoraMap is superior to LoraHub, an
existing method for integrating LoRAs. LoraMap also outperforms with
significantly fewer trainable parameters than LoraConcat, which concatenates
LoRAs and further fine-tunes them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 12 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mental Disorders Detection in the Era of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07129v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07129v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gleb Kuzmin, Petr Strepetov, Maksim Stankevich, Artem Shelmanov, Ivan Smirnov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper compares the effectiveness of traditional machine learning
methods, encoder-based models, and large language models (LLMs) on the task of
detecting depression and anxiety. Five datasets were considered, each differing
in format and the method used to define the target pathology class. We tested
AutoML models based on linguistic features, several variations of encoder-based
Transformers such as BERT, and state-of-the-art LLMs as pathology
classification models. The results demonstrated that LLMs outperform
traditional methods, particularly on noisy and small datasets where training
examples vary significantly in text length and genre. However, psycholinguistic
features and encoder-based models can achieve performance comparable to
language models when trained on texts from individuals with clinically
confirmed depression, highlighting their potential effectiveness in targeted
clinical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MFC-Bench: Benchmarking Multimodal Fact-Checking with Large
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11288v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11288v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengkang Wang, Hongzhan Lin, Ziyang Luo, Zhen Ye, Guang Chen, Jing Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) have significantly improved multimodal
reasoning tasks, such as visual question answering and image captioning. These
models embed multimodal facts within their parameters, rather than relying on
external knowledge bases to store factual information explicitly. However, the
content discerned by LVLMs may deviate from actual facts due to inherent bias
or incorrect inference. To address this issue, we introduce MFC-Bench, a
rigorous and comprehensive benchmark designed to evaluate the factual accuracy
of LVLMs across three stages of verdict prediction for MFC: Manipulation,
Out-of-Context, and Veracity Classification. Through our evaluation on
MFC-Bench, we benchmarked a dozen diverse and representative LVLMs, uncovering
that current models still fall short in multimodal fact-checking and
demonstrate insensitivity to various forms of manipulated content. We hope that
MFC-Bench could raise attention to the trustworthy AI potentially assisted by
LVLMs in the future. The MFC-Bench and accompanying resources are publicly
accessible at https://github.com/wskbest/MFC-Bench, contributing to ongoing
research in the multimodal fact-checking field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A corpus-based investigation of pitch contours of monosyllabic words in
  conversational Taiwan Mandarin 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07891v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07891v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyun Jin, Mirjam Ernestus, R. Harald Baayen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Mandarin, the tonal contours of monosyllabic words produced in isolation
or in careful speech are characterized by four lexical tones: a high-level tone
(T1), a rising tone (T2), a dipping tone (T3) and a falling tone (T4). However,
in spontaneous speech, the actual tonal realization of monosyllabic words can
deviate significantly from these canonical tones due to intra-syllabic
co-articulation and inter-syllabic co-articulation with adjacent tones. In
addition, Chuang et al. (2024) recently reported that the tonal contours of
disyllabic Mandarin words with T2-T4 tone pattern are co-determined by their
meanings. Following up on their research, we present a corpus-based
investigation of how the pitch contours of monosyllabic words are realized in
spontaneous conversational Mandarin, focusing on the effects of contextual
predictors on the one hand, and the way in words' meanings co-determine pitch
contours on the other hand. We analyze the F0 contours of 3824 tokens of 63
different word types in a spontaneous Taiwan Mandarin corpus, using the
generalized additive (mixed) model to decompose a given observed pitch contour
into a set of component pitch contours. We show that the tonal context
substantially modify a word's canonical tone. Once the effect of tonal context
is controlled for, T2 and T3 emerge as low flat tones, contrasting with T1 as a
high tone, and with T4 as a high-to-mid falling tone. The neutral tone (T0),
which in standard descriptions, is realized based on the preceding tone,
emerges as a low tone in its own right, modified by the other predictors in the
same way as the standard tones T1, T2, T3, and T4. We also show that word, and
even more so, word sense, co-determine words' F0 contours. Analyses of variable
importance using random forests further supported the substantial effect of
tonal context and an effect of word sense.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reverse Stable Diffusion: What <span class="highlight-title">prompt</span> was used to generate this image? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.01472v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.01472v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image diffusion models have recently attracted the interest of many
researchers, and inverting the diffusion process can play an important role in
better understanding the generative process and how to engineer prompts in
order to obtain the desired images. To this end, we study the task of
predicting the prompt embedding given an image generated by a generative
diffusion model. We consider a series of white-box and black-box models (with
and without access to the weights of the diffusion network) to deal with the
proposed task. We propose a novel learning framework comprising a joint prompt
regression and multi-label vocabulary classification objective that generates
improved prompts. To further improve our method, we employ a curriculum
learning procedure that promotes the learning of image-prompt pairs with lower
labeling noise (i.e. that are better aligned). We conduct experiments on the
DiffusionDB data set, predicting text prompts from images generated by Stable
Diffusion. In addition, we make an interesting discovery: training a diffusion
model on the prompt generation task can make the model generate images that are
much better aligned with the input prompts, when the model is directly reused
for text-to-image generation. Our code is publicly available for download at
https://github.com/CroitoruAlin/Reverse-Stable-Diffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in Computer Vision and Image Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models in the Clinic: A Comprehensive Benchmark <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00716v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00716v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fenglin Liu, Zheng Li, Hongjian Zhou, Qingyu Yin, Jingfeng Yang, Xianfeng Tang, Chen Luo, Ming Zeng, Haoming Jiang, Yifan Gao, Priyanka Nigam, Sreyashi Nag, Bing Yin, Yining Hua, Xuan Zhou, Omid Rohanian, Anshul Thakur, Lei Clifton, David A. Clifton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The adoption of large language models (LLMs) to assist clinicians has
attracted remarkable attention. Existing works mainly adopt the close-ended
question-answering (QA) task with answer options for evaluation. However, many
clinical decisions involve answering open-ended questions without pre-set
options. To better understand LLMs in the clinic, we construct a benchmark
ClinicBench. We first collect eleven existing datasets covering diverse
clinical language generation, understanding, and reasoning tasks. Furthermore,
we construct six novel datasets and clinical tasks that are complex but common
in real-world practice, e.g., open-ended decision-making, long document
processing, and emerging drug analysis. We conduct an extensive evaluation of
twenty-two LLMs under both zero-shot and few-shot settings. Finally, we invite
medical experts to evaluate the clinical usefulness of LLMs. The benchmark data
is available at https://github.com/AI-in-Health/ClinicBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CLongEval: A Chinese Benchmark for Evaluating Long-Context Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03514v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03514v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zexuan Qiu, Jingjing Li, Shijue Huang, Xiaoqi Jiao, Wanjun Zhong, Irwin King
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing Large Language Models (LLMs) with robust long-context capabilities
has been the recent research focus, resulting in the emergence of long-context
LLMs proficient in Chinese. However, the evaluation of these models remains
underdeveloped due to a lack of benchmarks. To address this gap, we present
CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs.
CLongEval is characterized by three key features: (1) Sufficient data volume,
comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability,
accommodating to models with context windows size from 1K to 100K; (3) High
quality, with over 2,000 manually annotated question-answer pairs in addition
to the automatically constructed labels. With CLongEval, we undertake a
comprehensive assessment of 6 open-source long-context LLMs and 2 leading
commercial counterparts that feature both long-context abilities and
proficiency in Chinese. We also provide in-depth analysis based on the
empirical results, trying to shed light on the critical capabilities that
present challenges in long-context settings. The dataset, evaluation scripts,
and model outputs are released.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TaCo: Targeted Concept Erasure Prevents Non-Linear Classifiers From
  Detecting Protected Attributes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.06499v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.06499v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanny Jourdan, Louis Béthune, Agustin Picard, Laurent Risser, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring fairness in NLP models is crucial, as they often encode sensitive
attributes like gender and ethnicity, leading to biased outcomes. Current
concept erasure methods attempt to mitigate this by modifying final latent
representations to remove sensitive information without retraining the entire
model. However, these methods typically rely on linear classifiers, which leave
models vulnerable to non-linear adversaries capable of recovering sensitive
information.
  We introduce Targeted Concept Erasure (TaCo), a novel approach that removes
sensitive information from final latent representations, ensuring fairness even
against non-linear classifiers. Our experiments show that TaCo outperforms
state-of-the-art methods, achieving greater reductions in the prediction
accuracy of sensitive attributes by non-linear classifier while preserving
overall task performance. Code is available on
https://github.com/fanny-jourdan/TaCo.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Inference with Large Language Model: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09822v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09822v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Causal inference has been a pivotal challenge across diverse domains such as
medicine and economics, demanding a complicated integration of human knowledge,
mathematical reasoning, and data mining capabilities. Recent advancements in
natural language processing (NLP), particularly with the advent of large
language models (LLMs), have introduced promising opportunities for traditional
causal inference tasks. This paper reviews recent progress in applying LLMs to
causal inference, encompassing various tasks spanning different levels of
causation. We summarize the main causal problems and approaches, and present a
comparison of their evaluation results in different causal scenarios.
Furthermore, we discuss key findings and outline directions for future
research, underscoring the potential implications of integrating LLMs in
advancing causal inference methodologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 2 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explore, Select, Derive, and Recall: Augmenting LLM with Human-like
  Memory for Mobile Task Automation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.03003v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.03003v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunjae Lee, Junyoung Choi, Jungjae Lee, Munim Hasan Wasi, Hojun Choi, Steven Y. Ko, Sangeun Oh, Insik Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of large language models (LLMs) has opened up new opportunities in
the field of mobile task automation. Their superior language understanding and
reasoning capabilities allow users to automate complex and repetitive tasks.
However, due to the inherent unreliability and high operational cost of LLMs,
their practical applicability is quite limited. To address these issues, this
paper introduces MobileGPT, an innovative LLM-based mobile task automator
equipped with a human-like app memory. MobileGPT emulates the cognitive process
of humans interacting with a mobile app -- explore, select, derive, and recall.
This approach allows for a more precise and efficient learning of a task's
procedure by breaking it down into smaller, modular sub-tasks that can be
re-used, re-arranged, and adapted for various objectives. We implement
MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its
performance on a dataset of 185 tasks across 18 mobile apps. The results
indicate that MobileGPT can automate and learn new tasks with 82.7% accuracy,
and is able to adapt them to different contexts with near perfect (98.75%)
accuracy while reducing both latency and cost by 62.5% and 68.8%, respectively,
compared to the GPT-4 powered baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reconsidering Degeneration of Token Embeddings with Definitions for
  Encoder-based <span class="highlight-title">Pre-train</span>ed Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01308v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01308v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ying Zhang, Dongyuan Li, Manabu Okumura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning token embeddings based on token co-occurrence statistics has proven
effective for both pre-training and fine-tuning in natural language processing.
However, recent studies have pointed out that the distribution of learned
embeddings degenerates into anisotropy (i.e., non-uniform distribution), and
even pre-trained language models (PLMs) suffer from a loss of semantics-related
information in embeddings for low-frequency tokens. This study first analyzes
the fine-tuning dynamics of encoder-based PLMs and demonstrates their
robustness against degeneration. On the basis of this analysis, we propose
DefinitionEMB, a method that utilizes definitions to re-construct isotropically
distributed and semantics-related token embeddings for encoder-based PLMs while
maintaining original robustness during fine-tuning. Our experiments demonstrate
the effectiveness of leveraging definitions from Wiktionary to re-construct
such embeddings for two encoder-based PLMs: RoBERTa-base and BART-large.
Furthermore, the re-constructed embeddings for low-frequency tokens improve the
performance of these models across various GLUE and four text summarization
datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ I Want to Break Free! Persuasion and Anti-Social Behavior of LLMs in
  Multi-Agent Settings with Social Hierarchy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07109v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07109v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gian Maria Campedelli, Nicolò Penzo, Massimo Stefan, Roberto Dessì, Marco Guerini, Bruno Lepri, Jacopo Staiano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Model (LLM)-based agents become increasingly autonomous and
will more freely interact with each other, studying interactions between them
becomes crucial to anticipate emergent phenomena and potential risks. Drawing
inspiration from the widely popular Stanford Prison Experiment, we contribute
to this line of research by studying interaction patterns of LLM agents in a
context characterized by strict social hierarchy. We do so by specifically
studying two types of phenomena: persuasion and anti-social behavior in
simulated scenarios involving a guard and a prisoner agent who seeks to achieve
a specific goal (i.e., obtaining additional yard time or escape from prison).
Leveraging 200 experimental scenarios for a total of 2,000 machine-machine
conversations across five different popular LLMs, we provide a set of
noteworthy findings. We first document how some models consistently fail in
carrying out a conversation in our multi-agent setup where power dynamics are
at play. Then, for the models that were able to engage in successful
interactions, we empirically show how the goal that an agent is set to achieve
impacts primarily its persuasiveness, while having a negligible effect with
respect to the agent's anti-social behavior. Third, we highlight how agents'
personas, and particularly the guard's personality, drive both the likelihood
of successful persuasion from the prisoner and the emergence of anti-social
behaviors. Fourth, we show that even without explicitly prompting for specific
personalities, anti-social behavior emerges by simply assigning agents' roles.
These results bear implications for the development of interactive LLM agents
as well as the debate on their societal impact.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Do Humans Write Code? Large Models Do It the Same Way Too 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15729v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15729v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Li, Xuzheng He, Haozhe Wang, Linlin Wang, Liang He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Program-of-Thought (PoT) replaces natural language-based Chain-of-Thought
(CoT) as the most popular method in Large Language Models (LLMs) mathematical
reasoning tasks by utilizing external tool calls to circumvent computational
errors. However, our evaluation of the GPT-4 and Llama series reveals that
using PoT introduces more reasoning errors, such as incorrect formulas or
flawed logic, compared to CoT. To address this issue, we propose Human-Think
Language (HTL), which leverages a suite of strategies that help integrate PoT
and CoT, encompassing: (1) a new generation paradigm that uses full CoT
reasoning to control code generation. (2) Focus Attention, that directs model
attention to the CoT reasoning during PoT to generate more logical code. (3)
reinforcement learning that utilizes the accuracy of both CoT and PoT responses
as rewards to prevent repetitive reasoning steps in LLMs when solving difficult
math problems. Our method achieves an average improvement of 6.5% on the
Llama-Base model and 4.3% on the Mistral-Base model across 8 mathematical
calculation datasets. It also shows significant effectiveness on five
out-of-domain datasets by controlling the model's information flow, exhibiting
strong transferability. Additionally, HTL shows the most significant
improvement in non-mathematical natural language inference task, contributing
to a unified reasoning task framework
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring and Benchmarking Large Language Models' Capabilities to
  Generate Persuasive Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17753v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17753v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amalie Brogaard Pauli, Isabelle Augenstein, Ira Assent
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We are exposed to much information trying to influence us, such as teaser
messages, debates, politically framed news, and propaganda - all of which use
persuasive language. With the recent interest in Large Language Models (LLMs),
we study the ability of LLMs to produce persuasive text. As opposed to prior
work which focuses on particular domains or types of persuasion, we conduct a
general study across various domains to measure and benchmark to what degree
LLMs produce persuasive language - both when explicitly instructed to rewrite
text to be more or less persuasive and when only instructed to paraphrase. We
construct the new dataset Persuasive-Pairs of pairs of a short text and its
rewrite by an LLM to amplify or diminish persuasive language. We multi-annotate
the pairs on a relative scale for persuasive language: a valuable resource in
itself, and for training a regression model to score and benchmark persuasive
language, including for new LLMs across domains. In our analysis, we find that
different 'personas' in LLaMA3's system prompt change persuasive language
substantially, even when only instructed to paraphrase.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deciphering Cross-Modal Alignment in Large Vision-Language Models with
  Modality Integration Rate 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qidong Huang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Dahua Lin, Weiming Zhang, Nenghai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Modality Integration Rate (MIR), an effective, robust, and
generalized metric to indicate the multi-modal pre-training quality of Large
Vision Language Models (LVLMs). Large-scale pre-training plays a critical role
in building capable LVLMs, while evaluating its training quality without the
costly supervised fine-tuning stage is under-explored. Loss, perplexity, and
in-context evaluation results are commonly used pre-training metrics for Large
Language Models (LLMs), while we observed that these metrics are less
indicative when aligning a well-trained LLM with a new modality. Due to the
lack of proper metrics, the research of LVLMs in the critical pre-training
stage is hindered greatly, including the training data choice, efficient module
design, etc. In this paper, we propose evaluating the pre-training quality from
the inter-modal distribution distance perspective and present MIR, the Modality
Integration Rate, which is 1) \textbf{Effective} to represent the pre-training
quality and show a positive relation with the benchmark performance after
supervised fine-tuning. 2) \textbf{Robust} toward different training/evaluation
data. 3) \textbf{Generalize} across training configurations and architecture
choices. We conduct a series of pre-training experiments to explore the
effectiveness of MIR and observe satisfactory results that MIR is indicative
about training data selection, training strategy schedule, and model
architecture design to get better pre-training results. We hope MIR could be a
helpful metric for building capable LVLMs and inspire the following research
about modality alignment in different areas. Our code is at:
https://github.com/shikiw/Modality-Integration-Rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://github.com/shikiw/Modality-Integration-Rate</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Changes in Nation Perception with Nationality-Assigned
  Personas in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13993v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13993v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahammed Kamruzzaman, Gene Louis Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Persona assignment has become a common strategy for customizing LLM use to
particular tasks and contexts. In this study, we explore how evaluation of
different nations change when LLMs are assigned specific nationality personas.
We assign 193 different nationality personas (e.g., an American person) to four
LLMs and examine how the LLM evaluations (or ''perceptions'')of countries
change. We find that all LLM-persona combinations tend to favor Western
European nations, though nation-personas push LLM behaviors to focus more on
and treat the nation-persona's own region more favorably. Eastern European,
Latin American, and African nations are treated more negatively by different
nationality personas. We additionally find that evaluations by nation-persona
LLMs of other nations correlate with human survey responses but fail to match
the values closely. Our study provides insight into how biases and stereotypes
are realized within LLMs when adopting different national personas. In line
with the ''Blueprint for an AI Bill of Rights'', our findings underscore the
critical need for developing mechanisms to ensure that LLM outputs promote
fairness and avoid over-generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print, Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptation Odyssey in LLMs: Why Does Additional <span class="highlight-title">Pretrain</span>ing Sometimes
  Fail to Improve? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05581v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05581v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fırat Öncel, Matthias Bethge, Beyza Ermis, Mirco Ravanelli, Cem Subakan, Çağatay Yıldız
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the last decade, the generalization and adaptation abilities of deep
learning models were typically evaluated on fixed training and test
distributions. Contrary to traditional deep learning, large language models
(LLMs) are (i) even more overparameterized, (ii) trained on unlabeled text
corpora curated from the Internet with minimal human intervention, and (iii)
trained in an online fashion. These stark contrasts prevent researchers from
transferring lessons learned on model generalization and adaptation in deep
learning contexts to LLMs. To this end, our short paper introduces empirical
observations that aim to shed light on further training of already pretrained
language models. Specifically, we demonstrate that training a model on a text
domain could degrade its perplexity on the test portion of the same domain. We
observe with our subsequent analysis that the performance degradation is
positively correlated with the similarity between the additional and the
original pretraining dataset of the LLM. Our further token-level perplexity
observations reveals that the perplexity degradation is due to a handful of
tokens that are not informative about the domain. We hope these findings will
guide us in determining when to adapt a model vs when to rely on its
foundational capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Infinite-Long Prefix in <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14036v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14036v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingyu Liang, Zhenmei Shi, Zhao Song, Chiwun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompting and context-based fine-tuning methods, which we call Prefix
Learning, have been proposed to enhance the performance of language models on
various downstream tasks. They are empirically efficient and effective,
matching the performance of full parameter fine-tuning, but the theoretical
understandings are limited. In this paper, we aim to address this limitation by
studying their ability from the perspective of prefix length. In particular, we
provide a convergence guarantee for training an ultra-long prefix in a stylized
setting using the Neural Tangent Kernel (NTK) framework. Based on this strong
theoretical guarantee, we design and implement an algorithm that only needs to
introduce and fine-tune a few extra trainable parameters instead of an
infinite-long prefix in each layer of a transformer, and can approximate the
prefix attention to a guaranteed polynomial-small error. Preliminary
experimental results on vision, natural language, and math data show that our
method achieves superior or competitive performance compared to existing
methods like full parameters fine-tuning, P-Tuning V2, and LoRA. This
demonstrates our method is promising for parameter-efficient fine-tuning. Our
code can be found at
\url{https://github.com/ChristianYang37/chiwun/tree/main/src/NTK-Attention}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SeRTS: Self-Rewarding Tree Search for Biomedical Retrieval-Augmented
  Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11258v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11258v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minda Hu, Licheng Zong, Hongru Wang, Jingyan Zhou, Jingjing Li, Yichen Gao, Kam-Fai Wong, Yu Li, Irwin King
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown great potential in the biomedical
domain with the advancement of retrieval-augmented generation (RAG). However,
existing retrieval-augmented approaches face challenges in addressing diverse
queries and documents, particularly for medical knowledge queries, resulting in
sub-optimal performance. To address these limitations, we propose a novel
plug-and-play LLM-based retrieval method called Self-Rewarding Tree Search
(SeRTS) based on Monte Carlo Tree Search (MCTS) and a self-rewarding paradigm.
By combining the reasoning capabilities of LLMs with the effectiveness of tree
search, SeRTS boosts the zero-shot performance of retrieving high-quality and
informative results for RAG. We further enhance retrieval performance by
fine-tuning LLMs with Proximal Policy Optimization (PPO) objectives using the
trajectories collected by SeRTS as feedback. Controlled experiments using the
BioASQ-QA dataset with GPT-3.5-Turbo and LLama2-7b demonstrate that our method
significantly improves the performance of the BM25 retriever and surpasses the
strong baseline of self-reflection in both efficiency and scalability.
Moreover, SeRTS generates higher-quality feedback for PPO training than
self-reflection. Our proposed method effectively adapts LLMs to document
retrieval tasks, enhancing their ability to retrieve highly relevant documents
for RAG in the context of medical knowledge queries. This work presents a
significant step forward in leveraging LLMs for accurate and comprehensive
biomedical question answering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Assamese NLP Capabilities: Introducing a Centralized <span class="highlight-title">Dataset</span>
  Repository 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11291v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11291v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        S. Tamang, D. J. Bora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a centralized, open-source dataset repository designed
to advance NLP and NMT for Assamese, a low-resource language. The repository,
available at GitHub, supports various tasks like sentiment analysis, named
entity recognition, and machine translation by providing both pre-training and
fine-tuning corpora. We review existing datasets, highlighting the need for
standardized resources in Assamese NLP, and discuss potential applications in
AI-driven research, such as LLMs, OCR, and chatbots. While promising,
challenges like data scarcity and linguistic diversity remain. The repository
aims to foster collaboration and innovation, promoting Assamese language
research in the digital age.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 1 table, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MERLIN: Multimodal Embedding Refinement via LLM-based Iterative
  Navigation for Text-Video Retrieval-Rerank Pipeline <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12508v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12508v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid expansion of multimedia content has made accurately retrieving
relevant videos from large collections increasingly challenging. Recent
advancements in text-video retrieval have focused on cross-modal interactions,
large-scale foundation model training, and probabilistic modeling, yet often
neglect the crucial user perspective, leading to discrepancies between user
queries and the content retrieved. To address this, we introduce MERLIN
(Multimodal Embedding Refinement via LLM-based Iterative Navigation), a novel,
training-free pipeline that leverages Large Language Models (LLMs) for
iterative feedback learning. MERLIN refines query embeddings from a user
perspective, enhancing alignment between queries and video content through a
dynamic question answering process. Experimental results on datasets like
MSR-VTT, MSVD, and ActivityNet demonstrate that MERLIN substantially improves
Recall@1, outperforming existing systems and confirming the benefits of
integrating LLMs into multimodal retrieval systems for more responsive and
context-aware multimedia retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Industry Track Accepted (Camera-Ready Version)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PAD: Personalized Alignment at Decoding-Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04070v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04070v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruizhe Chen, Xiaotian Zhang, Meng Luo, Wenhao Chai, Zuozhu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aligning with personalized preferences, which vary significantly across
cultural, educational, and political differences, poses a significant challenge
due to the computational costs and data demands of traditional alignment
methods. In response, this paper presents Personalized Alignment at
Decoding-time (PAD), a novel framework designed to align LLM outputs with
diverse personalized preferences during the inference phase, eliminating the
need for additional training. By introducing a unique personalized reward
modeling strategy, this framework decouples the text generation process from
personalized preferences, facilitating the generation of generalizable
token-level personalized rewards. The PAD algorithm leverages these rewards to
guide the decoding process, dynamically tailoring the base model's predictions
to personalized preferences. Extensive experimental results demonstrate that
PAD not only outperforms existing training-based alignment methods in terms of
aligning with diverse preferences but also shows significant generalizability
to preferences unseen during training and scalability across different base
models. This work advances the capability of LLMs to meet user needs in
real-time applications, presenting a substantial step forward in personalized
LLM alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper presents Personalized Alignment at Decoding-time (PAD), a
  novel framework designed to align LLM outputs with diverse personalized
  preferences during the inference phase</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $α$-DPO: Adaptive Reward Margin is What Direct Preference
  Optimization Needs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10148v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10148v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junkang Wu, Xue Wang, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Rong Jin, Xiangnan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aligning large language models (LLMs) with human values and intentions is
crucial for their utility, honesty, and safety. Reinforcement learning from
human feedback (RLHF) is a popular approach to achieve this alignment, but it
faces challenges in computational efficiency and training stability. Recent
methods like Direct Preference Optimization (DPO) and Simple Preference
Optimization (SimPO) have proposed offline alternatives to RLHF, simplifying
the process by reparameterizing the reward function. However, DPO depends on a
potentially suboptimal reference model, and SimPO's assumption of a fixed
target reward margin may lead to suboptimal decisions in diverse data settings.
In this work, we propose $\alpha$-DPO, an adaptive preference optimization
algorithm designed to address these limitations by introducing a dynamic reward
margin. Specifically, $\alpha$-DPO employs an adaptive preference distribution,
balancing the policy model and the reference model to achieve personalized
reward margins. We provide theoretical guarantees for $\alpha$-DPO,
demonstrating its effectiveness as a surrogate optimization objective and its
ability to balance alignment and diversity through KL divergence control.
Empirical evaluations on AlpacaEval 2 and Arena-Hard show that $\alpha$-DPO
consistently outperforms DPO and SimPO across various model settings,
establishing it as a robust approach for fine-tuning LLMs. Our method achieves
significant improvements in win rates, highlighting its potential as a powerful
tool for LLM alignment. The code is available at
https://github.com/junkangwu/alpha-DPO
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Instruction Tuning for Large Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.10792v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.10792v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, Guoyin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper surveys research works in the quickly advancing field of
instruction tuning (IT), a crucial technique to enhance the capabilities and
controllability of large language models (LLMs). Instruction tuning refers to
the process of further training LLMs on a dataset consisting of
\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the
gap between the next-word prediction objective of LLMs and the users' objective
of having LLMs adhere to human instructions. In this work, we make a systematic
review of the literature, including the general methodology of IT, the
construction of IT datasets, the training of IT models, and applications to
different modalities, domains and applications, along with an analysis on
aspects that influence the outcome of IT (e.g., generation of instruction
outputs, size of the instruction dataset, etc). We also review the potential
pitfalls of IT along with criticism against it, along with efforts pointing out
current deficiencies of existing strategies and suggest some avenues for
fruitful research. Project page: github.com/xiaoya-li/Instruction-Tuning-Survey
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>V3; Last update: Oct 16, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding
  for Neural Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11632v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11632v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Maximum a posteriori decoding, a commonly used method for neural machine
translation (NMT), aims to maximize the estimated posterior probability.
However, high estimated probability does not always lead to high translation
quality. Minimum Bayes Risk (MBR) decoding (\citealp{kumar2004minimum}) offers
an alternative by seeking hypotheses with the highest expected utility. In this
paper, we show that Quality Estimation (QE) reranking
(\citealp{fernandes-etal-2022-quality}), which uses a QE model as a reranker,
can be viewed as a variant of MBR. Inspired by this, we propose source-based
MBR (sMBR) decoding, a novel approach that utilizes synthetic sources
(generated via back-translation or paraphrasing) as ``support hypotheses'' and
a reference-free quality estimation metric as the utility function, marking the
first work to solely use sources in MBR decoding. Experiments show that sMBR
outperforms QE reranking and the standard MBR decoding. Our findings suggest
that sMBR is a promising approach for NMT decoding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Seeker: Enhancing Exception Handling in Code with LLM-based Multi-Agent
  Approach <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06949v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06949v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanming Zhang, Yuxuan Chen, Yuan Yuan, Minlie Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In real world software development, improper or missing exception handling
can severely impact the robustness and reliability of code. Exception handling
mechanisms require developers to detect, capture, and manage exceptions
according to high standards, but many developers struggle with these tasks,
leading to fragile code. This problem is particularly evident in open source
projects and impacts the overall quality of the software ecosystem. To address
this challenge, we explore the use of large language models (LLMs) to improve
exception handling in code. Through extensive analysis, we identify three key
issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception
Types, and Distorted Handling Solutions. These problems are widespread across
real world repositories, suggesting that robust exception handling practices
are often overlooked or mishandled. In response, we propose Seeker, a multi
agent framework inspired by expert developer strategies for exception handling.
Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler to assist
LLMs in detecting, capturing, and resolving exceptions more effectively. Our
work is the first systematic study on leveraging LLMs to enhance exception
handling practices, providing valuable insights for future improvements in code
reliability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 7 figures. Submitted ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Investigating the Transferability of Code Repair for Low-Resource
  Programming Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14867v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14867v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyle Wong, Alfonso Amayuelas, Liangming Pan, William Yang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable performance on code
generation tasks. A recent use case is iterative code repair, where an LLM
fixes an incorrect program by rationalizing about errors and generating new
code. Recent works augment the code repair process by integrating modern
techniques such as chain-of-thought reasoning or distillation, but only study
their benefits on high-resource languages like Python, and ignore low-resource
languages like Perl. To address this gap of knowledge, we investigate the
benefits of distilling code repair for both high and low resource languages to
determine if the techniques that are effective in a high resource setting are
also applicable in a low resource setting. Our evaluation shows that distilling
the ability to repair code has language dependent benefits. To explain this
behavior, we perform a further analysis and find that contrary to preexisting
beliefs, the correlation between reasoning ability and code correction ability
is weak. We hypothesize this weak correlation is magnified in low-resource
settings where base models lack deep knowledge of a programming language,
leading to wavering benefits of code repair.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield
  Better Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06554v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06554v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanjun Chen, Dawei Zhu, Yirong Sun, Xinghao Chen, Wei Zhang, Xiaoyu Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from Human Feedback significantly enhances Natural
Language Processing by aligning language models with human expectations. A
critical factor in this alignment is the strength of reward models used during
training. This study explores whether stronger reward models invariably lead to
better language models. In this paper, through experiments on relevance,
factuality, and completeness tasks using the QA-FEEDBACK dataset and reward
models based on Longformer, we uncover a surprising paradox: language models
trained with moderately accurate reward models outperform those guided by
highly accurate ones. This challenges the widely held belief that stronger
reward models always lead to better language models, and opens up new avenues
for future research into the key factors driving model performance and how to
choose the most suitable reward models. Code and additional details are
available at https://github.com/EIT-NLP/AccuracyParadox-RLHF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 27 figures (including 18 in the appendix), submitted to
  EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human
  Belief Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17232v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17232v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun-Shiuan Chuang, Krirk Nirunwiroj, Zach Studdiford, Agam Goyal, Vincent V. Frigo, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Creating human-like large language model (LLM) agents is crucial for faithful
social simulation. Having LLMs role-play based on demographic information
sometimes improves human likeness but often does not. This study assessed
whether LLM alignment with human behavior can be improved by integrating
information from empirically-derived human belief networks. Using data from a
human survey, we estimated a belief network encompassing 64 topics loading on
nine non-overlapping latent factors. We then seeded LLM-based agents with an
opinion on one topic, and assessed the alignment of its expressed opinions on
remaining test topics with corresponding human data. Role-playing based on
demographic information alone did not align LLM and human opinions, but seeding
the agent with a single belief greatly improved alignment for topics related in
the belief network, and not for topics outside the network. These results
suggest a novel path for human-LLM belief alignment in work seeking to simulate
and understand patterns of belief distributions in society.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Breaking Language Barriers in Multilingual Mathematical Reasoning:
  Insights and Observations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.20246v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.20246v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nuo Chen, Zinan Zheng, Ning Wu, Ming Gong, Dongmei Zhang, Jia Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing research predominantly focuses on developing powerful language
learning models (LLMs) for mathematical reasoning within monolingual languages,
with few explorations in preserving efficacy in a multilingual context. To
bridge this gap, this paper pioneers exploring and training powerful
Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we
construct the first multilingual math reasoning instruction dataset,
MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue
of training data scarcity in xMR tasks. Based on the collected dataset, we
propose different training strategies to build powerful xMR LLMs, named
MathOctopus, notably outperform conventional open-source LLMs and exhibit
superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B
reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond
remarkable results, we unearth several pivotal observations and insights from
extensive experiments: (1) When extending the rejection sampling strategy to
the multilingual context, it proves effective for model performances, albeit
limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)
across multiple languages not only significantly enhances model performance
multilingually but also elevates their monolingual performance. This indicates
that crafting multilingual corpora can be regarded as a vital strategy for
enhancing model performance in a specific language, especially in mathematical
reasoning tasks. For instance, MathOctopus-7B improves its counterparts that
trained on English from 42.2% to 50.8% on GSM8K testset. Codes are available at
https://github.com/microsoft/MathOctopus.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explainable Natural Language Processing for Corporate Sustainability
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17487v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17487v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keane Ong, Rui Mao, Ranjan Satapathy, Ricardo Shirota Filho, Erik Cambria, Johan Sulaeman, Gianmarco Mengaldo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sustainability commonly refers to entities, such as individuals, companies,
and institutions, having a non-detrimental (or even positive) impact on the
environment, society, and the economy. With sustainability becoming a synonym
of acceptable and legitimate behaviour, it is being increasingly demanded and
regulated. Several frameworks and standards have been proposed to measure the
sustainability impact of corporations, including United Nations' sustainable
development goals and the recently introduced global sustainability reporting
framework, amongst others. However, the concept of corporate sustainability is
complex due to the diverse and intricate nature of firm operations (i.e.
geography, size, business activities, interlinks with other stakeholders). As a
result, corporate sustainability assessments are plagued by subjectivity both
within data that reflect corporate sustainability efforts (i.e. corporate
sustainability disclosures) and the analysts evaluating them. This subjectivity
can be distilled into distinct challenges, such as incompleteness, ambiguity,
unreliability and sophistication on the data dimension, as well as limited
resources and potential bias on the analyst dimension. Put together,
subjectivity hinders effective cost attribution to entities non-compliant with
prevailing sustainability expectations, potentially rendering sustainability
efforts and its associated regulations futile. To this end, we argue that
Explainable Natural Language Processing (XNLP) can significantly enhance
corporate sustainability analysis. Specifically, linguistic understanding
algorithms (lexical, semantic, syntactic), integrated with XAI capabilities
(interpretability, explainability, faithfulness), can bridge gaps in analyst
resources and mitigate subjectivity problems within data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ JOOCI: a Framework for Learning Comprehensive Speech Representations <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11086v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11086v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hemant Yadav, Rajiv Ratn Shah, Sunayana Sitaram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information in speech can be divided into two categories: what is being said
(content) and how it is expressed (other). Current state-of-the-art (SOTA)
techniques model speech at fixed segments, usually 10-25 ms, using a single
embedding. Given the orthogonal nature of other and content information,
attempting to optimize both within a single embedding results in suboptimal
solutions. This approach divides the models capacity, limiting its ability to
build complex hierarchical features effectively. In this work, we present an
end-to-end speech representation learning framework designed to jointly
optimize the other and content information (JOOCI) in speech. By using separate
learnable parameters, JOOCI addresses this optimization challenge by modeling
other and content information independently. Our results show that JOOCI
consistently outperforms other SOTA models of similar size (100 million
parameters) and pre-training data used (960 hours) by a significant margin when
evaluated on a range of speech downstream tasks in the SUPERB benchmark, as
shown in Table 1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Translation Canvas: An Explainable Interface to Pinpoint and Analyze
  Translation Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10861v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10861v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chinmay Dandekar, Wenda Xu, Xi Xu, Siqi Ouyang, Lei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of machine translation research, evaluation
toolkits have become essential for benchmarking system progress. Tools like
COMET and SacreBLEU offer single quality score assessments that are effective
for pairwise system comparisons. However, these tools provide limited insights
for fine-grained system-level comparisons and the analysis of instance-level
defects. To address these limitations, we introduce Translation Canvas, an
explainable interface designed to pinpoint and analyze translation systems'
performance: 1) Translation Canvas assists machine translation researchers in
comprehending system-level model performance by identifying common errors
(their frequency and severity) and analyzing relationships between different
systems based on various evaluation metrics. 2) It supports fine-grained
analysis by highlighting error spans with explanations and selectively
displaying systems' predictions. According to human evaluation, Translation
Canvas demonstrates superior performance over COMET and SacreBLEU packages
under enjoyability and understandability criteria.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Discovering Elementary Discourse Units in Textual Data Using Canonical
  Correlation Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12997v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12997v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akanksha Mehndiratta, Krishna Asawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Canonical Correlation Analysis (CCA) has been exploited immensely for
learning latent representations in various fields. This study takes a step
further by demonstrating the potential of CCA in identifying Elementary
Discourse Units(EDUs) that captures the latent information within the textual
data. The probabilistic interpretation of CCA discussed in this study utilizes
the two-view nature of textual data, i.e. the consecutive sentences in a
document or turns in a dyadic conversation, and has a strong theoretical
foundation. Furthermore, this study proposes a model for Elementary Discourse
Unit(EDU) segmentation that discovers EDUs in textual data without any
supervision. To validate the model, the EDUs are utilized as textual unit for
content selection in textual similarity task. Empirical results on Semantic
Textual Similarity(STSB) and Mohler datasets confirm that, despite represented
as a unigram, the EDUs deliver competitive results and can even beat various
sophisticated supervised techniques. The model is simple, linear, adaptable and
language independent making it an ideal baseline particularly when labeled
training data is scarce or nonexistent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge Circuits in <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>s <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024, 32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Examining Long-Context Large Language Models for Environmental <span class="highlight-title">Review</span>
  Document Comprehension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07321v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07321v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hung Phan, Anurag Acharya, Rounak Meyur, Sarthak Chaturvedi, Shivam Sharma, Mike Parker, Dan Nally, Ali Jannesari, Karl Pazdernik, Mahantesh Halappanavar, Sai Munikoti, Sameera Horawalavithana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As LLMs become increasingly ubiquitous, researchers have tried various
techniques to augment the knowledge provided to these models. Long context and
retrieval-augmented generation (RAG) are two such methods that have recently
gained popularity. In this work, we examine the benefits of both of these
techniques by utilizing question answering (QA) task in a niche domain. While
the effectiveness of LLM-based QA systems has already been established at an
acceptable level in popular domains such as trivia and literature, it has not
often been established in niche domains that traditionally require specialized
expertise. We construct the NEPAQuAD1.0 benchmark to evaluate the performance
of five long-context LLMs -- Claude Sonnet, Gemini, GPT-4, Llama 3.1, and
Mistral -- when answering questions originating from Environmental Impact
Statements prepared by U.S. federal government agencies in accordance with the
National Environmental Environmental Act (NEPA). We specifically measure the
ability of LLMs to understand the nuances of legal, technical, and
compliance-related information present in NEPA documents in different
contextual scenarios. We test the LLMs' internal prior NEPA knowledge by
providing questions without any context, as well as assess how LLMs synthesize
the contextual information present in long NEPA documents to facilitate the
question/answering task. We compare the performance of the models in handling
different types of questions (e.g., problem-solving, divergent, etc.). Our
results suggest that RAG powered models significantly outperform those provided
with only the PDF context in terms of answer accuracy, regardless of the choice
of the LLM. Our further analysis reveals that many models perform better
answering closed type questions (Yes/No) than divergent and problem-solving
questions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">137</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual Prototype Evolving for Test-Time Generalization of Vision-Language
  Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12790v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12790v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ce Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test-time adaptation, which enables models to generalize to diverse data with
unlabeled test samples, holds significant value in real-world scenarios.
Recently, researchers have applied this setting to advanced pre-trained
vision-language models (VLMs), developing approaches such as test-time prompt
tuning to further extend their practical applicability. However, these methods
typically focus solely on adapting VLMs from a single modality and fail to
accumulate task-specific knowledge as more samples are processed. To address
this, we introduce Dual Prototype Evolving (DPE), a novel test-time adaptation
approach for VLMs that effectively accumulates task-specific knowledge from
multi-modalities. Specifically, we create and evolve two sets of
prototypes--textual and visual--to progressively capture more accurate
multi-modal representations for target classes during test time. Moreover, to
promote consistent multi-modal representations, we introduce and optimize
learnable residuals for each test sample to align the prototypes from both
modalities. Extensive experimental results on 15 benchmark datasets demonstrate
that our proposed DPE consistently outperforms previous state-of-the-art
methods while also exhibiting competitive computational efficiency. Code is
available at https://github.com/zhangce01/DPE-CLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024. Project page:
  https://zhangce01.github.io/DPE-CLIP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Curse of Multi-Modalities: Evaluating Hallucinations of Large
  Multimodal Models across Language, Visual, and Audio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12787v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12787v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sicong Leng, Yun Xing, Zesen Cheng, Yang Zhou, Hang Zhang, Xin Li, Deli Zhao, Shijian Lu, Chunyan Miao, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large multimodal models (LMMs) have significantly
enhanced performance across diverse tasks, with ongoing efforts to further
integrate additional modalities such as video and audio. However, most existing
LMMs remain vulnerable to hallucinations, the discrepancy between the factual
multimodal input and the generated textual output, which has limited their
applicability in various real-world scenarios. This paper presents the first
systematic investigation of hallucinations in LMMs involving the three most
common modalities: language, visual, and audio. Our study reveals two key
contributors to hallucinations: overreliance on unimodal priors and spurious
inter-modality correlations. To address these challenges, we introduce the
benchmark The Curse of Multi-Modalities (CMM), which comprehensively evaluates
hallucinations in LMMs, providing a detailed analysis of their underlying
issues. Our findings highlight key vulnerabilities, including imbalances in
modality integration and biases from training data, underscoring the need for
balanced cross-modal learning and enhanced hallucination mitigation strategies.
Based on our observations and findings, we suggest potential research
directions that could enhance the reliability of LMMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: cmm-damovl.site</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage
  Gaussian Splats 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12781v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12781v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Ziwen, Hao Tan, Kai Zhang, Sai Bi, Fujun Luan, Yicong Hong, Li Fuxin, Zexiang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Long-LRM, a generalizable 3D Gaussian reconstruction model that is
capable of reconstructing a large scene from a long sequence of input images.
Specifically, our model can process 32 source images at 960x540 resolution
within only 1.3 seconds on a single A100 80G GPU. Our architecture features a
mixture of the recent Mamba2 blocks and the classical transformer blocks which
allowed many more tokens to be processed than prior work, enhanced by efficient
token merging and Gaussian pruning steps that balance between quality and
efficiency. Unlike previous feed-forward models that are limited to processing
1~4 input images and can only reconstruct a small portion of a large scene,
Long-LRM reconstructs the entire scene in a single feed-forward step. On
large-scale scene datasets such as DL3DV-140 and Tanks and Temples, our method
achieves performance comparable to optimization-based approaches while being
two orders of magnitude more efficient. Project page:
https://arthurhero.github.io/projects/llrm
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned
  Concepts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12777v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12777v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid progress of diffusion-based content generation, significant
efforts are being made to unlearn harmful or copyrighted concepts from
pretrained diffusion models (DMs) to prevent potential model misuse. However,
it is observed that even when DMs are properly unlearned before release,
malicious finetuning can compromise this process, causing DMs to relearn the
unlearned concepts. This occurs partly because certain benign concepts (e.g.,
"skin") retained in DMs are related to the unlearned ones (e.g., "nudity"),
facilitating their relearning via finetuning. To address this, we propose
meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an
unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes
malicious finetuning on unlearned concepts, the related benign concepts
retained within it will be triggered to self-destruct, hindering the relearning
of unlearned concepts. Our meta-unlearning framework is compatible with most
existing unlearning methods, requiring only the addition of an
easy-to-implement meta objective. We validate our approach through empirical
experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4
and SDXL), supported by extensive ablation studies. Our code is available at
https://github.com/sail-sg/Meta-Unlearning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Zero-Shot Camera Trap Image Categorization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12769v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12769v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiří Vyskočil, Lukas Picek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes the search for an alternative approach to the automatic
categorization of camera trap images. First, we benchmark state-of-the-art
classifiers using a single model for all images. Next, we evaluate methods
combining MegaDetector with one or more classifiers and Segment Anything to
assess their impact on reducing location-specific overfitting. Last, we propose
and test two approaches using large language and foundational models, such as
DINOv2, BioCLIP, BLIP, and ChatGPT, in a zero-shot scenario. Evaluation carried
out on two publicly available datasets (WCT from New Zealand, CCT20 from the
Southwestern US) and a private dataset (CEF from Central Europe) revealed that
combining MegaDetector with two separate classifiers achieves the highest
accuracy. This approach reduced the relative error of a single BEiTV2
classifier by approximately 42\% on CCT20, 48\% on CEF, and 75\% on WCT.
Besides, as the background is removed, the error in terms of accuracy in new
locations is reduced to half. The proposed zero-shot pipeline based on DINOv2
and FAISS achieved competitive results (1.0\% and 4.7\% smaller on CCT20, and
CEF, respectively), which highlights the potential of zero-shot approaches for
camera trap image categorization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Gravity-aligned Rotation Averaging with Circular Regression <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12763v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12763v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linfei Pan, Marc Pollefeys, Dániel Baráth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reconstructing a 3D scene from unordered images is pivotal in computer vision
and robotics, with applications spanning crowd-sourced mapping and beyond.
While global Structure-from-Motion (SfM) techniques are scalable and fast, they
often compromise on accuracy. To address this, we introduce a principled
approach that integrates gravity direction into the rotation averaging phase of
global pipelines, enhancing camera orientation accuracy and reducing the
degrees of freedom. This additional information is commonly available in recent
consumer devices, such as smartphones, mixed-reality devices and drones, making
the proposed method readily accessible. Rooted in circular regression, our
algorithm has similar convergence guarantees as linear regression. It also
supports scenarios where only a subset of cameras have known gravity.
Additionally, we propose a mechanism to refine error-prone gravity. We achieve
state-of-the-art accuracy on four large-scale datasets. Particularly, the
proposed method improves upon the SfM baseline by 13 AUC@$1^\circ$ points, on
average, while running eight times faster. It also outperforms the standard
planar pose graph optimization technique by 23 AUC@$1^\circ$ points. The code
is at https://github.com/colmap/glomap.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted at ECCV2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And
  Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in diffusion models have significantly enhanced their ability
to generate high-quality images and videos, but they have also increased the
risk of producing unsafe content. Existing unlearning/editing-based methods for
safe generation remove harmful concepts from models but face several
challenges: (1) They cannot instantly remove harmful concepts without training.
(2) Their safe generation capabilities depend on collected training data. (3)
They alter model weights, risking degradation in quality for content unrelated
to toxic concepts. To address these, we propose SAFREE, a novel, training-free
approach for safe T2I and T2V, that does not alter the model's weights.
Specifically, we detect a subspace corresponding to a set of toxic concepts in
the text embedding space and steer prompt embeddings away from this subspace,
thereby filtering out harmful content while preserving intended semantics. To
balance the trade-off between filtering toxicity and preserving safe concepts,
SAFREE incorporates a novel self-validating filtering mechanism that
dynamically adjusts the denoising steps when applying the filtered embeddings.
Additionally, we incorporate adaptive re-attention mechanisms within the
diffusion latent space to selectively diminish the influence of features
related to toxic concepts at the pixel level. In the end, SAFREE ensures
coherent safety checking, preserving the fidelity, quality, and safety of the
output. SAFREE achieves SOTA performance in suppressing unsafe content in T2I
generation compared to training-free baselines and effectively filters targeted
concepts while maintaining high-quality images. It also shows competitive
results against training-based methods. We extend SAFREE to various T2I
backbones and T2V tasks, showcasing its flexibility and generalization. SAFREE
provides a robust and adaptable safeguard for ensuring safe visual generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally; Project page:
  https://safree-safe-t2i-t2v.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PND-Net: Plant Nutrition Deficiency and Disease Classification using
  Graph Convolutional Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12742v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12742v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asish Bera, Debotosh Bhattacharjee, Ondrej Krejcar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Crop yield production could be enhanced for agricultural growth if various
plant nutrition deficiencies, and diseases are identified and detected at early
stages. The deep learning methods have proven its superior performances in the
automated detection of plant diseases and nutrition deficiencies from visual
symptoms in leaves. This article proposes a new deep learning method for plant
nutrition deficiencies and disease classification using a graph convolutional
network (GNN), added upon a base convolutional neural network (CNN). Sometimes,
a global feature descriptor might fail to capture the vital region of a
diseased leaf, which causes inaccurate classification of disease. To address
this issue, regional feature learning is crucial for a holistic feature
aggregation. In this work, region-based feature summarization at multi-scales
is explored using spatial pyramidal pooling for discriminative feature
representation. A GCN is developed to capacitate learning of finer details for
classifying plant diseases and insufficiency of nutrients. The proposed method,
called Plant Nutrition Deficiency and Disease Network (PND-Net), is evaluated
on two public datasets for nutrition deficiency, and two for disease
classification using four CNNs. The best classification performances are: (a)
90.00% Banana and 90.54% Coffee nutrition deficiency; and (b) 96.18% Potato
diseases and 84.30% on PlantDoc datasets using Xception backbone. Furthermore,
additional experiments have been carried out for generalization, and the
proposed method has achieved state-of-the-art performances on two public
datasets, namely the Breast Cancer Histopathology Image Classification
(BreakHis 40X: 95.50%, and BreakHis 100X: 96.79% accuracy) and Single cells in
Pap smear images for cervical cancer classification (SIPaKMeD: 99.18%
accuracy). Also, PND-Net achieves improved performances using five-fold cross
validation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing 3D Geometry Reconstruction from Implicit Neural
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shen Fan, Przemyslaw Musialski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit neural representations have emerged as a powerful tool in learning
3D geometry, offering unparalleled advantages over conventional representations
like mesh-based methods. A common type of INR implicitly encodes a shape's
boundary as the zero-level set of the learned continuous function and learns a
mapping from a low-dimensional latent space to the space of all possible shapes
represented by its signed distance function. However, most INRs struggle to
retain high-frequency details, which are crucial for accurate geometric
depiction, and they are computationally expensive. To address these
limitations, we present a novel approach that both reduces computational
expenses and enhances the capture of fine details. Our method integrates
periodic activation functions, positional encodings, and normals into the
neural network architecture. This integration significantly enhances the
model's ability to learn the entire space of 3D shapes while preserving
intricate details and sharp features, areas where conventional representations
often fall short.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAFA-Net: Region Attention Network For Food Items And Agricultural
  Stress Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12718v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12718v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Asish Bera, Ondrej Krejcar, Debotosh Bhattacharjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Convolutional Neural Networks (CNNs) have facilitated remarkable success
in recognizing various food items and agricultural stress. A decent performance
boost has been witnessed in solving the agro-food challenges by mining and
analyzing of region-based partial feature descriptors. Also, computationally
expensive ensemble learning schemes using multiple CNNs have been studied in
earlier works. This work proposes a region attention scheme for modelling
long-range dependencies by building a correlation among different regions
within an input image. The attention method enhances feature representation by
learning the usefulness of context information from complementary regions.
Spatial pyramidal pooling and average pooling pair aggregate partial
descriptors into a holistic representation. Both pooling methods establish
spatial and channel-wise relationships without incurring extra parameters. A
context gating scheme is applied to refine the descriptiveness of weighted
attentional features, which is relevant for classification. The proposed Region
Attention network for Food items and Agricultural stress recognition method,
dubbed RAFA-Net, has been experimented on three public food datasets, and has
achieved state-of-the-art performances with distinct margins. The highest top-1
accuracies of RAFA-Net are 91.69%, 91.56%, and 96.97% on the UECFood-100,
UECFood-256, and MAFood-121 datasets, respectively. In addition, better
accuracies have been achieved on two benchmark agricultural stress datasets.
The best top-1 accuracies on the Insect Pest (IP-102) and PlantDoc-27 plant
disease datasets are 92.36%, and 85.54%, respectively; implying RAFA-Net's
generalization capability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WorldCuisines: A Massive-Scale Benchmark for Multilingual and
  Multicultural Visual Question Answering on Global Cuisines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12705v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12705v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Genta Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Nedjma Ousidhoum, Afifa Amriani, Anar Rzayev, Anirban Das, Ashmari Pramodya, Aulia Adila, Bryan Wilie, Candy Olivia Mawalim, Ching Lam Cheng, Daud Abolade, Emmanuele Chersoni, Enrico Santus, Fariz Ikhwantri, Garry Kuwanto, Hanyang Zhao, Haryo Akbarianto Wibowo, Holy Lovenia, Jan Christian Blaise Cruz, Jan Wira Gotama Putra, Junho Myung, Lucky Susanto, Maria Angelica Riera Machin, Marina Zhukova, Michael Anugraha, Muhammad Farid Adilazuarda, Natasha Santosa, Peerat Limkonchotiwat, Raj Dabre, Rio Alexander Audino, Samuel Cahyawijaya, Shi-Xiong Zhang, Stephanie Yulia Salim, Yi Zhou, Yinxuan Gui, David Ifeoluwa Adelani, En-Shiun Annie Lee, Shogo Okada, Ayu Purwarianti, Alham Fikri Aji, Taro Watanabe, Derry Tanti Wijaya, Alice Oh, Chong-Wah Ngo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Language Models (VLMs) often struggle with culture-specific knowledge,
particularly in languages other than English and in underrepresented cultural
contexts. To evaluate their understanding of such knowledge, we introduce
WorldCuisines, a massive-scale benchmark for multilingual and multicultural,
visually grounded language understanding. This benchmark includes a visual
question answering (VQA) dataset with text-image pairs across 30 languages and
dialects, spanning 9 language families and featuring over 1 million data
points, making it the largest multicultural VQA benchmark to date. It includes
tasks for identifying dish names and their origins. We provide evaluation
datasets in two sizes (12k and 60k instances) alongside a training dataset (1
million instances). Our findings show that while VLMs perform better with
correct location context, they struggle with adversarial contexts and
predicting specific regional cuisines and languages. To support future
research, we release a knowledge base with annotated food entries and images
along with the VQA data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via
  Lightweight Value Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12700v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12700v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in diffusion models trained on large-scale data have
enabled the generation of indistinguishable human-level images, yet they often
produce harmful content misaligned with human values, e.g., social bias, and
offensive content. Despite extensive research on Large Language Models (LLMs),
the challenge of Text-to-Image (T2I) model alignment remains largely
unexplored. Addressing this problem, we propose LiVO (Lightweight Value
Optimization), a novel lightweight method for aligning T2I models with human
values. LiVO only optimizes a plug-and-play value encoder to integrate a
specified value principle with the input prompt, allowing the control of
generated images over both semantics and values. Specifically, we design a
diffusion model-tailored preference optimization loss, which theoretically
approximates the Bradley-Terry model used in LLM alignment but provides a more
flexible trade-off between image quality and value conformity. To optimize the
value encoder, we also develop a framework to automatically construct a
text-image preference dataset of 86k (prompt, aligned image, violating image,
value principle) samples. Without updating most model parameters and through
adaptive value selection from the input prompt, LiVO significantly reduces
harmful outputs and achieves faster convergence, surpassing several strong
baselines and taking an initial step towards ethically aligned T2I models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024. The dataset and code can be found at
  https://github.com/achernarwang/LiVO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AdaptiveDrag: Semantic-Driven Dragging on Diffusion-Based Image Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        DuoSheng Chen, Binghui Chen, Yifeng Geng, Liefeng Bo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, several point-based image editing methods (e.g., DragDiffusion,
FreeDrag, DragNoise) have emerged, yielding precise and high-quality results
based on user instructions. However, these methods often make insufficient use
of semantic information, leading to less desirable results. In this paper, we
proposed a novel mask-free point-based image editing method, AdaptiveDrag,
which provides a more flexible editing approach and generates images that
better align with user intent. Specifically, we design an auto mask generation
module using super-pixel division for user-friendliness. Next, we leverage a
pre-trained diffusion model to optimize the latent, enabling the dragging of
features from handle points to target points. To ensure a comprehensive
connection between the input image and the drag process, we have developed a
semantic-driven optimization. We design adaptive steps that are supervised by
the positions of the points and the semantic regions derived from super-pixel
segmentation. This refined optimization process also leads to more realistic
and accurate drag results. Furthermore, to address the limitations in the
generative consistency of the diffusion model, we introduce an innovative
corresponding loss during the sampling process. Building on these effective
designs, our method delivers superior generation results using only the single
input image and the handle-target point pairs. Extensive experiments have been
conducted and demonstrate that the proposed method outperforms others in
handling various drag instructions (e.g., resize, movement, extension) across
different domains (e.g., animals, human face, land space, clothing).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiCamCows2024 -- A Multi-view Image <span class="highlight-title">Dataset</span> for AI-driven
  Holstein-Friesian Cattle Re-Identification on a Working Farm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Phoenix Yu, Tilo Burghardt, Andrew W Dowsey, Neill W Campbell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present MultiCamCows2024, a farm-scale image dataset filmed across
multiple cameras for the biometric identification of individual
Holstein-Friesian cattle exploiting their unique black and white coat-patterns.
Captured by three ceiling-mounted visual sensors covering adjacent barn areas
over seven days on a working dairy farm, the dataset comprises 101, 329 images
of 90 cows, plus the underlying original CCTV footage. The dataset is provided
alongside full computer vision recognition baselines, that is both a supervised
and self-supervised learning framework for individual cow identification
trained on cattle tracklets. We report a performance above 96% single image
identification accuracy from the dataset and demonstrate that combining data
from multiple cameras during learning enhances self-supervised identification.
We show that our framework enables fully automatic cattle identification,
barring only the simple human verification of tracklet integrity during data
collection. Crucially, our study highlights that multi-camera, supervised and
self-supervised components in tandem not only deliver highly accurate
individual cow identification but also achieve this efficiently with no
labelling of cattle identities by humans at all. We argue that this improvement
in efficacy has practical implications for livestock management, behaviour
analysis, and agricultural monitoring. For full reproducibility and practical
ease of use, we publish all key software and code including re-identification
components and the species detector with this paper.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VividMed: Vision Language Model with Versatile Visual Grounding for
  Medicine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12694v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12694v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Vision Language Models (VLMs) have demonstrated
remarkable promise in generating visually grounded responses. However, their
application in the medical domain is hindered by unique challenges. For
instance, most VLMs rely on a single method of visual grounding, whereas
complex medical tasks demand more versatile approaches. Additionally, while
most VLMs process only 2D images, a large portion of medical images are 3D. The
lack of medical data further compounds these obstacles. To address these
challenges, we present VividMed, a vision language model with versatile visual
grounding for medicine. Our model supports generating both semantic
segmentation masks and instance-level bounding boxes, and accommodates various
imaging modalities, including both 2D and 3D data. We design a three-stage
training procedure and an automatic data synthesis pipeline based on open
datasets and models. Besides visual grounding tasks, VividMed also excels in
other common downstream tasks, including Visual Question Answering (VQA) and
report generation. Ablation studies empirically show that the integration of
visual grounding ability leads to improved performance on these tasks. Our code
is publicly available at https://github.com/function2-llx/MMMM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Machine Learning Approach to Brain Tumor Detection and Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alice Oh, Inyoung Noh, Jian Choo, Jihoo Lee, Justin Park, Kate Hwang, Sanghyeon Kim, Soo Min Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Brain tumor detection and classification are critical tasks in medical image
analysis, particularly in early-stage diagnosis, where accurate and timely
detection can significantly improve treatment outcomes. In this study, we apply
various statistical and machine learning models to detect and classify brain
tumors using brain MRI images. We explore a variety of statistical models
including linear, logistic, and Bayesian regressions, and the machine learning
models including decision tree, random forest, single-layer perceptron,
multi-layer perceptron, convolutional neural network (CNN), recurrent neural
network, and long short-term memory. Our findings show that CNN outperforms
other models, achieving the best performance. Additionally, we confirm that the
CNN model can also work for multi-class classification, distinguishing between
four categories of brain MRI images such as normal, glioma, meningioma, and
pituitary tumor images. This study demonstrates that machine learning
approaches are suitable for brain tumor detection and classification,
facilitating real-world medical applications in assisting radiologists with
early and accurate diagnosis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 2 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic Mapping of Anatomical Landmarks from Free-Text Using Large
  Language Models: Insights from Llama-2 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12686v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12686v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anatomical landmarks are vital in medical imaging for navigation and anomaly
detection. Modern large language models (LLMs), like Llama-2, offer promise for
automating the mapping of these landmarks in free-text radiology reports to
corresponding positions in image data. Recent studies propose LLMs may develop
coherent representations of generative processes. Motivated by these insights,
we investigated whether LLMs accurately represent the spatial positions of
anatomical landmarks. Through experiments with Llama-2 models, we found that
they can linearly represent anatomical landmarks in space with considerable
robustness to different prompts. These results underscore the potential of LLMs
to enhance the efficiency and accuracy of medical imaging workflows.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MambaBEV: An efficient 3D detection model with Mamba2 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12673v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12673v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihan You, Hao Wang, Qichao Zhao, Jinxiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A stable 3D object detection model based on BEV paradigm with temporal
information is very important for autonomous driving systems. However, current
temporal fusion model use convolutional layer or deformable self-attention is
not conducive to the exchange of global information of BEV space and has more
computational cost. Recently, a newly proposed based model specialized in
processing sequence called mamba has shown great potential in multiple
downstream task. In this work, we proposed a mamba2-based BEV 3D object
detection model named MambaBEV. We also adapt an end to end self driving
paradigm to test the performance of the model. Our work performs pretty good
results on nucences datasets:Our base version achieves 51.7% NDS. Our code will
be available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dewei Zhou, Ji Xie, Zongxin Yang, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing demand for controllable outputs in text-to-image generation
has spurred advancements in multi-instance generation (MIG), allowing users to
define both instance layouts and attributes. However, unlike image-conditional
generation methods such as ControlNet, MIG techniques have not been widely
adopted in state-of-the-art models like SD2 and SDXL, primarily due to the
challenge of building robust renderers that simultaneously handle instance
positioning and attribute rendering. In this paper, we introduce Depth-Driven
Decoupled Instance Synthesis (3DIS), a novel framework that decouples the MIG
process into two stages: (i) generating a coarse scene depth map for accurate
instance positioning and scene composition, and (ii) rendering fine-grained
attributes using pre-trained ControlNet on any foundational model, without
additional training. Our 3DIS framework integrates a custom adapter into LDM3D
for precise depth-based layouts and employs a finetuning-free method for
enhanced instance-level attribute rendering. Extensive experiments on
COCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantly
outperforms existing methods in both layout precision and attribute rendering.
Notably, 3DIS offers seamless compatibility with diverse foundational models,
providing a robust, adaptable solution for advanced multi-instance generation.
The code is available at: https://github.com/limuloo/3DIS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shicheng Xu, Liang Pang, Yunchang Zhu, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language alignment in Large Vision-Language Models (LVLMs)
successfully enables LLMs to understand visual input. However, we find that
existing vision-language alignment methods fail to transfer the existing safety
mechanism for text in LLMs to vision, which leads to vulnerabilities in toxic
image. To explore the cause of this problem, we give the insightful explanation
of where and how the safety mechanism of LVLMs operates and conduct comparative
analysis between text and vision. We find that the hidden states at the
specific transformer layers play a crucial role in the successful activation of
safety mechanism, while the vision-language alignment at hidden states level in
current methods is insufficient. This results in a semantic shift for input
images compared to text in hidden states, therefore misleads the safety
mechanism. To address this, we propose a novel Text-Guided vision-language
Alignment method (TGA) for LVLMs. TGA retrieves the texts related to input
vision and uses them to guide the projection of vision into the hidden states
space in LLMs. Experiments show that TGA not only successfully transfers the
safety mechanism for text in basic LLMs to vision in vision-language alignment
for LVLMs without any safety fine-tuning on the visual modality but also
maintains the general performance on various vision tasks (Safe and Good).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cascade learning in multi-task encoder-decoder networks for concurrent
  bone segmentation and glenohumeral joint assessment in shoulder CT scans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12641v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12641v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Marsilio, Davide Marzorati, Matteo Rossi, Andrea Moglia, Luca Mainardi, Alfonso Manzotti, Pietro Cerveri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Osteoarthritis is a degenerative condition affecting bones and cartilage,
often leading to osteophyte formation, bone density loss, and joint space
narrowing. Treatment options to restore normal joint function vary depending on
the severity of the condition. This work introduces an innovative deep-learning
framework processing shoulder CT scans. It features the semantic segmentation
of the proximal humerus and scapula, the 3D reconstruction of bone surfaces,
the identification of the glenohumeral (GH) joint region, and the staging of
three common osteoarthritic-related pathologies: osteophyte formation (OS), GH
space reduction (JS), and humeroscapular alignment (HSA). The pipeline
comprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D
Arthro-Net for threefold classification. A retrospective dataset of 571 CT
scans featuring patients with various degrees of GH osteoarthritic-related
pathologies was used to train, validate, and test the pipeline. Root mean
squared error and Hausdorff distance median values for 3D reconstruction were
0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,
outperforming state-of-the-art architectures and making it potentially suitable
for a PSI-based shoulder arthroplasty preoperative plan context. The
classification accuracy for OS, JS, and HSA consistently reached around 90%
across all three categories. The computational time for the inference pipeline
was less than 15s, showcasing the framework's efficiency and compatibility with
orthopedic radiology practice. The outcomes represent a promising advancement
toward the medical translation of artificial intelligence tools. This progress
aims to streamline the preoperative planning pipeline delivering high-quality
bone surfaces and supporting surgeons in selecting the most suitable surgical
approach according to the unique patient joint conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse
  Synthetic Data and Global-to-Local Adaptive Perception 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyuan Zhao, Hengrui Kang, Bin Wang, Conghui He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document Layout Analysis is crucial for real-world document understanding
systems, but it encounters a challenging trade-off between speed and accuracy:
multimodal methods leveraging both text and visual features achieve higher
accuracy but suffer from significant latency, whereas unimodal methods relying
solely on visual features offer faster processing speeds at the expense of
accuracy. To address this dilemma, we introduce DocLayout-YOLO, a novel
approach that enhances accuracy while maintaining speed advantages through
document-specific optimizations in both pre-training and model design. For
robust document pre-training, we introduce the Mesh-candidate BestFit
algorithm, which frames document synthesis as a two-dimensional bin packing
problem, generating the large-scale, diverse DocSynth-300K dataset.
Pre-training on the resulting DocSynth-300K dataset significantly improves
fine-tuning performance across various document types. In terms of model
optimization, we propose a Global-to-Local Controllable Receptive Module that
is capable of better handling multi-scale variations of document elements.
Furthermore, to validate performance across different document types, we
introduce a complex and challenging benchmark named DocStructBench. Extensive
experiments on downstream datasets demonstrate that DocLayout-YOLO excels in
both speed and accuracy. Code, data, and models are available at
https://github.com/opendatalab/DocLayout-YOLO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github Repo: https://github.com/opendatalab/DocLayout-YOLO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Model Kinship for Merging Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yedi Hu, Yunzhi Yao, Ningyu Zhang, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging has become one of the key technologies for enhancing the
capabilities and efficiency of Large Language Models (LLMs). However, our
understanding of the expected performance gains and principles when merging any
two models remains limited. In this work, we introduce model kinship, the
degree of similarity or relatedness between LLMs, analogous to biological
evolution. With comprehensive empirical analysis, we find that there is a
certain relationship between model kinship and the performance gains after
model merging, which can help guide our selection of candidate models. Inspired
by this, we propose a new model merging strategy: Top-k Greedy Merging with
Model Kinship, which can yield better performance on benchmark datasets.
Specifically, we discover that using model kinship as a criterion can assist us
in continuously performing model merging, alleviating the degradation (local
optima) in model evolution, whereas model kinship can serve as a guide to
escape these traps. Code is available at
https://github.com/zjunlp/ModelKinship.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CMAL: A Novel Cross-Modal Associative Learning Framework for
  Vision-Language <span class="highlight-title">Pre-Train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyuan Ma, Jianjun Li, Guohui Li, Kaiyan Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the flourishing of social media platforms, vision-language pre-training
(VLP) recently has received great attention and many remarkable progresses have
been achieved. The success of VLP largely benefits from the information
complementation and enhancement between different modalities. However, most of
recent studies focus on cross-modal contrastive learning (CMCL) to promote
image-text alignment by pulling embeddings of positive sample pairs together
while pushing those of negative pairs apart, which ignores the natural
asymmetry property between different modalities and requires large-scale
image-text corpus to achieve arduous progress. To mitigate this predicament, we
propose CMAL, a Cross-Modal Associative Learning framework with anchor points
detection and cross-modal associative learning for VLP. Specifically, we first
respectively embed visual objects and textual tokens into separate hypersphere
spaces to learn intra-modal hidden features, and then design a cross-modal
associative prompt layer to perform anchor point masking and swap feature
filling for constructing a hybrid cross-modal associative prompt. Afterwards,
we exploit a unified semantic encoder to learn their cross-modal interactive
features for context adaptation. Finally, we design an associative mapping
classification layer to learn potential associative mappings between modalities
at anchor points, within which we develop a fresh self-supervised associative
mapping classification task to boost CMAL's performance. Experimental results
verify the effectiveness of CMAL, showing that it achieves competitive
performance against previous CMCL-based methods on four common downstream
vision-and-language tasks, with significantly fewer corpus. Especially, CMAL
obtains new state-of-the-art results on SNLI-VE and REC (testA).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>vision-language pre-training, contrastive learning, cross-modal,
  associative learning, associative mapping classification</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor
  Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minkyoung Cho, Yulong Cao, Jiachen Sun, Qingzhao Zhang, Marco Pavone, Jeong Joon Park, Heng Yang, Z. Morley Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An important paradigm in 3D object detection is the use of multiple
modalities to enhance accuracy in both normal and challenging conditions,
particularly for long-tail scenarios. To address this, recent studies have
explored two directions of adaptive approaches: MoE-based adaptive fusion,
which struggles with uncertainties arising from distinct object configurations,
and late fusion for output-level adaptive fusion, which relies on separate
detection pipelines and limits comprehensive understanding. In this work, we
introduce Cocoon, an object- and feature-level uncertainty-aware fusion
framework. The key innovation lies in uncertainty quantification for
heterogeneous representations, enabling fair comparison across modalities
through the introduction of a feature aligner and a learnable surrogate ground
truth, termed feature impression. We also define a training objective to ensure
that their relationship provides a valid metric for uncertainty quantification.
Cocoon consistently outperforms existing static and adaptive methods in both
normal and challenging conditions, including those with natural and artificial
corruptions. Furthermore, we show the validity and efficacy of our uncertainty
metric across diverse datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Visual Counterfactual Explanations Through Region Constraint 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12591v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12591v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bartlomiej Sobieski, Jakub Grzywaczewski, Bartlomiej Sadlej, Matthew Tivnan, Przemyslaw Biecek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual counterfactual explanations (VCEs) have recently gained immense
popularity as a tool for clarifying the decision-making process of image
classifiers. This trend is largely motivated by what these explanations promise
to deliver -- indicate semantically meaningful factors that change the
classifier's decision. However, we argue that current state-of-the-art
approaches lack a crucial component -- the region constraint -- whose absence
prevents from drawing explicit conclusions, and may even lead to faulty
reasoning due to phenomenons like confirmation bias. To address the issue of
previous methods, which modify images in a very entangled and widely dispersed
manner, we propose region-constrained VCEs (RVCEs), which assume that only a
predefined image region can be modified to influence the model's prediction. To
effectively sample from this subclass of VCEs, we propose Region-Constrained
Counterfactual Schr\"odinger Bridges (RCSB), an adaptation of a tractable
subclass of Schr\"odinger Bridges to the problem of conditional inpainting,
where the conditioning signal originates from the classifier of interest. In
addition to setting a new state-of-the-art by a large margin, we extend RCSB to
allow for exact counterfactual reasoning, where the predefined region contains
only the factor of interest, and incorporating the user to actively interact
with the RVCE by predefining the regions manually.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Lab to Pocket: A Novel Continual Learning-based Mobile Application
  for Screening COVID-19 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danny Falero, Muhammad Ashad Kabir, Nusrat Homaira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence (AI) has emerged as a promising tool for predicting
COVID-19 from medical images. In this paper, we propose a novel continual
learning-based approach and present the design and implementation of a mobile
application for screening COVID-19. Our approach demonstrates the ability to
adapt to evolving datasets, including data collected from different locations
or hospitals, varying virus strains, and diverse clinical presentations,
without retraining from scratch. We have evaluated state-of-the-art continual
learning methods for detecting COVID-19 from chest X-rays and selected the
best-performing model for our mobile app. We evaluated various deep learning
architectures to select the best-performing one as a foundation model for
continual learning. Both regularization and memory-based methods for continual
learning were tested, using different memory sizes to develop the optimal
continual learning model for our app. DenseNet161 emerged as the best
foundation model with 96.87\% accuracy, and Learning without Forgetting (LwF)
was the top continual learning method with an overall performance of 71.99\%.
The mobile app design considers both patient and doctor perspectives. It
incorporates the continual learning DenseNet161 LwF model on a cloud server,
enabling the model to learn from new instances of chest X-rays and their
classifications as they are submitted. The app is designed, implemented, and
evaluated to ensure it provides an efficient tool for COVID-19 screening. The
app is available to download from
https://github.com/DannyFGitHub/COVID-19PneumoCheckApp.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-DenseMobileNet: A Robust Framework for Lung Nodule Classification
  using Self-ONN and Stacking-based Meta-Classifier 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md. Sohanur Rahman, Muhammad E. H. Chowdhury, Hasib Ryan Rahman, Mosabber Uddin Ahmed, Muhammad Ashad Kabir, Sanjiban Sekhar Roy, Rusab Sarmun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we propose a novel and robust framework, Self-DenseMobileNet,
designed to enhance the classification of nodules and non-nodules in chest
radiographs (CXRs). Our approach integrates advanced image standardization and
enhancement techniques to optimize the input quality, thereby improving
classification accuracy. To enhance predictive accuracy and leverage the
strengths of multiple models, the prediction probabilities from
Self-DenseMobileNet were transformed into tabular data and used to train eight
classical machine learning (ML) models; the top three performers were then
combined via a stacking algorithm, creating a robust meta-classifier that
integrates their collective insights for superior classification performance.
To enhance the interpretability of our results, we employed class activation
mapping (CAM) to visualize the decision-making process of the best-performing
model. Our proposed framework demonstrated remarkable performance on internal
validation data, achieving an accuracy of 99.28\% using a Meta-Random Forest
Classifier. When tested on an external dataset, the framework maintained strong
generalizability with an accuracy of 89.40\%. These results highlight a
significant improvement in the classification of CXRs with lung nodules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with
  Image Insertion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12564v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12564v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiacheng Ruan, Yebin Yang, Zehao Lin, Feiyu Xiong, Zeyun Tang, Zhiyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Benefiting from the revolutionary advances in large language models (LLMs)
and foundational vision models, large vision-language models (LVLMs) have also
made significant progress. However, current benchmarks focus on tasks that
evaluating only a single aspect of LVLM capabilities (e.g., recognition,
detection, understanding). These tasks fail to fully demonstrate LVLMs'
potential in complex application scenarios. To comprehensively assess the
performance of existing LVLMs, we propose a more challenging task called the
Flow Text with Image Insertion task (FTII). This task requires LVLMs to
simultaneously possess outstanding abilities in image comprehension,
instruction understanding, and long-text interpretation. Specifically, given
several text paragraphs and a set of candidate images, as the text paragraphs
accumulate, the LVLMs are required to select the most suitable image from the
candidates to insert after the corresponding paragraph. Constructing a
benchmark for such a task is highly challenging, particularly in determining
the sequence of flowing text and images. To address this challenge, we turn to
professional news reports, which naturally contain a gold standard for
image-text sequences. Based on this, we introduce the Flow Text with Image
Insertion Benchmark (FTII-Bench), which includes 318 high-quality Chinese
image-text news articles and 307 high-quality English image-text news articles,
covering 10 different news domains. Using these 625 high-quality articles, we
construct problems of two different types with multiple levels of difficulty.
Furthermore, we establish two different evaluation pipelines based on the CLIP
model and existing LVLMs. We evaluate 9 open-source and 2 closed-source LVLMs
as well as 2 CLIP-based models. Results indicate that even the most advanced
models (e.g., GPT-4o) face significant challenges when tackling the FTII task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. 9 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive <span class="highlight-title">Prompt</span> Learning with SAM for Few-shot Scanning Probe Microscope
  Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12562v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12562v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao Shen, Ziwei Wei, Chunmeng Liu, Shuming Wei, Qi Zhao, Kaiyang Zeng, Guangyao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Segment Anything Model (SAM) has demonstrated strong performance in image
segmentation of natural scene images. However, its effectiveness diminishes
markedly when applied to specific scientific domains, such as Scanning Probe
Microscope (SPM) images. This decline in accuracy can be attributed to the
distinct data distribution and limited availability of the data inherent in the
scientific images. On the other hand, the acquisition of adequate SPM datasets
is both time-intensive and laborious as well as skill-dependent. To address
these challenges, we propose an Adaptive Prompt Learning with SAM (APL-SAM)
framework tailored for few-shot SPM image segmentation. Our approach
incorporates two key innovations to enhance SAM: 1) An Adaptive Prompt Learning
module leverages few-shot embeddings derived from limited support set to learn
adaptively central representatives, serving as visual prompts. This innovation
eliminates the need for time-consuming online user interactions for providing
prompts, such as exhaustively marking points and bounding boxes slice by slice;
2) A multi-source, multi-level mask decoder specifically designed for few-shot
SPM image segmentation is introduced, which can effectively capture the
correspondence between the support and query images. To facilitate
comprehensive training and evaluation, we introduce a new dataset, SPM-Seg,
curated for SPM image segmentation. Extensive experiments on this dataset
reveal that the proposed APL-SAM framework significantly outperforms the
original SAM, achieving over a 30% improvement in terms of Dice Similarity
Coefficient with only one-shot guidance. Moreover, APL-SAM surpasses
state-of-the-art few-shot segmentation methods and even fully supervised
approaches in performance. Code and dataset used in this study will be made
available upon acceptance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Development of Image Collection Method Using YOLO and Siamese Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chan Young Shin, Ah Hyun Lee, Jun Young Lee, Ji Min Lee, Soo Jin Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As we enter the era of big data, collecting high-quality data is very
important. However, collecting data by humans is not only very time-consuming
but also expensive. Therefore, many scientists have devised various methods to
collect data using computers. Among them, there is a method called web
crawling, but the authors found that the crawling method has a problem in that
unintended data is collected along with the user. The authors found that this
can be filtered using the object recognition model YOLOv10. However, there are
cases where data that is not properly filtered remains. Here, image
reclassification was performed by additionally utilizing the distance output
from the Siamese network, and higher performance was recorded than other
classification models. (average \_f1 score YOLO+MobileNet
0.678->YOLO+SiameseNet 0.772)) The user can specify a distance threshold to
adjust the balance between data deficiency and noise-robustness. The authors
also found that the Siamese network can achieve higher performance with fewer
resources because the cropped images are used for object recognition when
processing images in the Siamese network. (Class 20 mean-based f1 score,
non-crop+Siamese(MobileNetV3-Small) 80.94 -> crop
preprocessing+Siamese(MobileNetV3-Small) 82.31) In this way, the image
retrieval system that utilizes two consecutive models to reduce errors can save
users' time and effort, and build better quality data faster and with fewer
resources than before.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 13 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Step Diffusion via Shortcut Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Frans, Danijar Hafner, Sergey Levine, Pieter Abbeel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models and flow-matching models have enabled generating diverse and
realistic images by learning to transfer noise to data. However, sampling from
these models involves iterative denoising over many neural network passes,
making generation slow and expensive. Previous approaches for speeding up
sampling require complex training regimes, such as multiple training phases,
multiple networks, or fragile scheduling. We introduce shortcut models, a
family of generative models that use a single network and training phase to
produce high-quality samples in a single or multiple sampling steps. Shortcut
models condition the network not only on the current noise level but also on
the desired step size, allowing the model to skip ahead in the generation
process. Across a wide range of sampling step budgets, shortcut models
consistently produce higher quality samples than previous approaches, such as
consistency models and reflow. Compared to distillation, shortcut models reduce
complexity to a single network and training phase and additionally allow
varying step budgets at inference time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Utility of Memory Efficient Medical Image Generation: A Study
  on Lung Nodule Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kathrin Khadra, Utku Türkbey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scarcity of publicly available medical imaging data limits the
development of effective AI models. This work proposes a memory-efficient
patch-wise denoising diffusion probabilistic model (DDPM) for generating
synthetic medical images, focusing on CT scans with lung nodules. Our approach
generates high-utility synthetic images with nodule segmentation while
efficiently managing memory constraints, enabling the creation of training
datasets. We evaluate the method in two scenarios: training a segmentation
model exclusively on synthetic data, and augmenting real-world training data
with synthetic images. In the first case, models trained solely on synthetic
data achieve Dice scores comparable to those trained on real-world data
benchmarks. In the second case, augmenting real-world data with synthetic
images significantly improves segmentation performance. The generated images
demonstrate their potential to enhance medical image datasets in scenarios with
limited real-world data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shaping a Stabilized Video by Mitigating Unintended Changes for
  Concept-Augmented Video Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12526v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12526v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingce Guo, Jingxuan He, Shengeng Tang, Zhangye Wang, Lechao Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-driven video editing utilizing generative diffusion models has garnered
significant attention due to their potential applications. However, existing
approaches are constrained by the limited word embeddings provided in
pre-training, which hinders nuanced editing targeting open concepts with
specific attributes. Directly altering the keywords in target prompts often
results in unintended disruptions to the attention mechanisms. To achieve more
flexible editing easily, this work proposes an improved concept-augmented video
editing approach that generates diverse and stable target videos flexibly by
devising abstract conceptual pairs. Specifically, the framework involves
concept-augmented textual inversion and a dual prior supervision mechanism. The
former enables plug-and-play guidance of stable diffusion for video editing,
effectively capturing target attributes for more stylized results. The dual
prior supervision mechanism significantly enhances video stability and
fidelity. Comprehensive evaluations demonstrate that our approach generates
more stable and lifelike videos, outperforming state-of-the-art methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MambaPainter: Neural Stroke-Based Rendering in a Single Step <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tomoya Sawada, Marie Katsurai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stroke-based rendering aims to reconstruct an input image into an oil
painting style by predicting brush stroke sequences. Conventional methods
perform this prediction stroke-by-stroke or require multiple inference steps
due to the limitations of a predictable number of strokes. This procedure leads
to inefficient translation speed, limiting their practicality. In this study,
we propose MambaPainter, capable of predicting a sequence of over 100 brush
strokes in a single inference step, resulting in rapid translation. We achieve
this sequence prediction by incorporating the selective state-space model.
Additionally, we introduce a simple extension to patch-based rendering, which
we use to translate high-resolution images, improving the visual quality with a
minimal increase in computational cost. Experimental results demonstrate that
MambaPainter can efficiently translate inputs to oil painting-style images
compared to state-of-the-art methods. The codes are available at
https://github.com/STomoya/MambaPainter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SIGGRAPH Asia 2024 posters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QueensCAMP: an RGB-D <span class="highlight-title">dataset</span> for robust Visual SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hudson M. S. Bruno, Esther L. Colombini, Sidney N. Givigi Jr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Simultaneous Localization and Mapping (VSLAM) is a fundamental
technology for robotics applications. While VSLAM research has achieved
significant advancements, its robustness under challenging situations, such as
poor lighting, dynamic environments, motion blur, and sensor failures, remains
a challenging issue. To address these challenges, we introduce a novel RGB-D
dataset designed for evaluating the robustness of VSLAM systems. The dataset
comprises real-world indoor scenes with dynamic objects, motion blur, and
varying illumination, as well as emulated camera failures, including lens dirt,
condensation, underexposure, and overexposure. Additionally, we offer
open-source scripts for injecting camera failures into any images, enabling
further customization by the research community. Our experiments demonstrate
that ORB-SLAM2, a traditional VSLAM algorithm, and TartanVO, a Deep
Learning-based VO algorithm, can experience performance degradation under these
challenging conditions. Therefore, this dataset and the camera failure
open-source tools provide a valuable resource for developing more robust VSLAM
systems capable of handling real-world challenges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning <span class="chip">ICASSP2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12501v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12501v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiabao Wei, Zhiyuan Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Virtual Try-ON (VTON) aims to synthesis specific person images dressed in
given garments, which recently receives numerous attention in online shopping
scenarios. Currently, the core challenges of the VTON task mainly lie in the
fine-grained semantic extraction (i.e.,deep semantics) of the given reference
garments during depth estimation and effective texture preservation when the
garments are synthesized and warped onto human body. To cope with these issues,
we propose DH-VTON, a deep text-driven virtual try-on model featuring a special
hybrid attention learning strategy and deep garment semantic preservation
module. By standing on the shoulder of a well-built pre-trained
paint-by-example (abbr. PBE) approach, we present our DH-VTON pipeline in this
work. Specifically, to extract the deep semantics of the garments, we first
introduce InternViT-6B as fine-grained feature learner, which can be trained to
align with the large-scale intrinsic knowledge with deep text semantics
(e.g.,"neckline" or "girdle") to make up for the deficiency of the commonly
adopted CLIP encoder. Based on this, to enhance the customized dressing
abilities, we further introduce Garment-Feature ControlNet Plus (abbr. GFC+)
module and propose to leverage a fresh hybrid attention strategy for training,
which can adaptively integrate fine-grained characteristics of the garments
into the different layers of the VTON model, so as to achieve multi-scale
features preservation effects. Extensive experiments on several representative
datasets demonstrate that our method outperforms previous diffusion-based and
GAN-based approaches, showing competitive performance in preserving garment
details and generating authentic human images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 6 figures, ICASSP2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stabilize the Latent Space for Image Autoregressive Modeling: A Unified
  Perspective <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongxin Zhu, Bocheng Li, Hang Zhang, Xin Li, Linli Xu, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Latent-based image generative models, such as Latent Diffusion Models (LDMs)
and Mask Image Models (MIMs), have achieved notable success in image generation
tasks. These models typically leverage reconstructive autoencoders like VQGAN
or VAE to encode pixels into a more compact latent space and learn the data
distribution in the latent space instead of directly from pixels. However, this
practice raises a pertinent question: Is it truly the optimal choice? In
response, we begin with an intriguing observation: despite sharing the same
latent space, autoregressive models significantly lag behind LDMs and MIMs in
image generation. This finding contrasts sharply with the field of NLP, where
the autoregressive model GPT has established a commanding presence. To address
this discrepancy, we introduce a unified perspective on the relationship
between latent space and generative models, emphasizing the stability of latent
space in image generative modeling. Furthermore, we propose a simple but
effective discrete image tokenizer to stabilize the latent space for image
generative modeling. Experimental results show that image autoregressive
modeling with our tokenizer (DiGIT) benefits both image understanding and image
generation with the next token prediction principle, which is inherently
straightforward for GPT models but challenging for other generative models.
Remarkably, for the first time, a GPT-style autoregressive model for images
outperforms LDMs, which also exhibits substantial improvement akin to GPT when
scaling up model size. Our findings underscore the potential of an optimized
latent space and the integration of discrete tokenization in advancing the
capabilities of image generative models. The code is available at
\url{https://github.com/DAMO-NLP-SG/DiGIT}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthetic Augmentation for Anatomical Landmark Localization using DDPMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arnela Hadzic, Lea Bogensperger, Simon Johannes Joham, Martin Urschler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning techniques for anatomical landmark localization (ALL) have
shown great success, but their reliance on large annotated datasets remains a
problem due to the tedious and costly nature of medical data acquisition and
annotation. While traditional data augmentation, variational autoencoders
(VAEs), and generative adversarial networks (GANs) have already been used to
synthetically expand medical datasets, diffusion-based generative models have
recently started to gain attention for their ability to generate high-quality
synthetic images. In this study, we explore the use of denoising diffusion
probabilistic models (DDPMs) for generating medical images and their
corresponding heatmaps of landmarks to enhance the training of a supervised
deep learning model for ALL. Our novel approach involves a DDPM with a
2-channel input, incorporating both the original medical image and its heatmap
of annotated landmarks. We also propose a novel way to assess the quality of
the generated images using a Markov Random Field (MRF) model for landmark
matching and a Statistical Shape Model (SSM) to check landmark plausibility,
before we evaluate the DDPM-augmented dataset in the context of an ALL task
involving hand X-Rays.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Gap Between Prototypes and Images in Cross-domain Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongduan Tian, Feng Liu, Zhanke Zhou, Tongliang Liu, Chengqi Zhang, Bo Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In cross-domain few-shot classification (CFC), recent works mainly focus on
adapting a simple transformation head on top of a frozen pre-trained backbone
with few labeled data to project embeddings into a task-specific metric space
where classification can be performed by measuring similarities between image
instance and prototype representations. Technically, an assumption implicitly
adopted in such a framework is that the prototype and image instance embeddings
share the same representation transformation. However, in this paper, we find
that there naturally exists a gap, which resembles the modality gap, between
the prototype and image instance embeddings extracted from the frozen
pre-trained backbone, and simply applying the same transformation during the
adaptation phase constrains exploring the optimal representations and shrinks
the gap between prototype and image representations. To solve this problem, we
propose a simple yet effective method, contrastive prototype-image adaptation
(CoPA), to adapt different transformations respectively for prototypes and
images similarly to CLIP by treating prototypes as text prompts. Extensive
experiments on Meta-Dataset demonstrate that CoPA achieves the state-of-the-art
performance more efficiently. Meanwhile, further analyses also indicate that
CoPA can learn better representation clusters, enlarge the gap, and achieve
minimal validation loss at the enlarged gap.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Primal-dual algorithm for image reconstruction with ICNNs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hok Shing Wong, Matthias J. Ehrhardt, Subhadip Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the optimization problem in a data-driven variational
reconstruction framework, where the regularizer is parameterized by an
input-convex neural network (ICNN). While gradient-based methods are commonly
used to solve such problems, they struggle to effectively handle non-smoothness
which often leads to slow convergence. Moreover, the nested structure of the
neural network complicates the application of standard non-smooth optimization
techniques, such as proximal algorithms. To overcome these challenges, we
reformulate the problem and eliminate the network's nested structure. By
relating this reformulation to epigraphical projections of the activation
functions, we transform the problem into a convex optimization problem that can
be efficiently solved using a primal-dual algorithm. We also prove that this
reformulation is equivalent to the original variational problem. Through
experiments on several imaging tasks, we demonstrate that the proposed approach
outperforms subgradient methods in terms of both speed and stability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention-Guided Perturbation for Consistency Regularization in
  Semi-Supervised Medical Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Cheng, Chenxi Shao, Jie Ma, Guoliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image segmentation is a pivotal step in diagnostic and therapeutic
processes. However, the acquisition of high-quality annotated data is often
constrained by scarcity and cost. Semi-supervised learning offers a promising
approach to enhance model performance by using unlabeled data. While
consistency regularization is a prevalent method in semi-supervised image
segmentation, there is a dearth of research on perturbation strategies tailored
for semi-supervised medical image segmentation tasks. This paper introduces an
attention-guided perturbation strategy for semi-supervised consistency
regularization in the context of medical image segmentation. We add the
perturbation based on the attention from the model in the image and feature
level to achieve consistency regularization. The method is adept at
accommodating the intricate structures and high-dimensional semantics inherent
in medical images, thereby enhancing the performance of semi-supervised
segmentation tasks. Our method achieved state-of-the-art results on benchmark
datasets, including a 90.4\% Dice score on the ACDC dataset in the 7-case
scenario.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Triplet: Triangle Patchlet for Mesh-Based Inverse Rendering and Scene
  Parameters Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12414v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12414v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajie Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Radiance Fields have significantly improved novel-view
synthesis. However, in many real-world applications, the more advanced
challenge lies in inverse rendering, which seeks to derive the physical
properties of a scene, including light, geometry, textures, and materials.
Meshes, as a traditional representation adopted by many simulation pipeline,
however, still show limited influence in radiance field for inverse rendering.
This paper introduces a novel framework called Triangle Patchlet (abbr.
Triplet), a mesh-based representation, to comprehensively approximate these
scene parameters. We begin by assembling Triplets with either randomly
generated points or sparse points obtained from camera calibration where all
faces are treated as an independent element. Next, we simulate the physical
interaction of light and optimize the scene parameters using traditional
graphics rendering techniques like rasterization and ray tracing, accompanying
with density control and propagation. An iterative mesh extracting process is
also suggested, where we continue to optimize on geometry and materials with
graph-based operation. We also introduce several regulation terms to enable
better generalization of materials property. Our framework could precisely
estimate the light, materials and geometry with mesh without prior of light,
materials and geometry in a unified framework. Experiments demonstrate that our
approach can achieve state-of-the-art visual quality while reconstructing
high-quality geometry and accurate material properties.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/RANDO11199/Triplet</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AdaCropFollow: <span class="highlight-title">Self-Supervised</span> Online Adaptation for Visual Under-Canopy
  Navigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arun N. Sivakumar, Federico Magistri, Mateus V. Gasparino, Jens Behley, Cyrill Stachniss, Girish Chowdhary
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Under-canopy agricultural robots can enable various applications like precise
monitoring, spraying, weeding, and plant manipulation tasks throughout the
growing season. Autonomous navigation under the canopy is challenging due to
the degradation in accuracy of RTK-GPS and the large variability in the visual
appearance of the scene over time. In prior work, we developed a supervised
learning-based perception system with semantic keypoint representation and
deployed this in various field conditions. A large number of failures of this
system can be attributed to the inability of the perception model to adapt to
the domain shift encountered during deployment. In this paper, we propose a
self-supervised online adaptation method for adapting the semantic keypoint
representation using a visual foundational model, geometric prior, and pseudo
labeling. Our preliminary experiments show that with minimal data and
fine-tuning of parameters, the keypoint prediction model trained with labels on
the source domain can be adapted in a self-supervised manner to various
challenging target domains onboard the robot computer using our method. This
can enable fully autonomous row-following capability in under-canopy robots
across fields and crops without requiring human intervention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Coarse-Grained Matching in Video-Text Retrieval <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12407v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12407v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aozhu Chen, Hazel Doughty, Xirong Li, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-text retrieval has seen significant advancements, yet the ability of
models to discern subtle differences in captions still requires verification.
In this paper, we introduce a new approach for fine-grained evaluation. Our
approach can be applied to existing datasets by automatically generating hard
negative test captions with subtle single-word variations across nouns, verbs,
adjectives, adverbs, and prepositions. We perform comprehensive experiments
using four state-of-the-art models across two standard benchmarks (MSR-VTT and
VATEX) and two specially curated datasets enriched with detailed descriptions
(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our
analyses show that the current evaluation benchmarks fall short in detecting a
model's ability to perceive subtle single-word differences, 2) our fine-grained
evaluation highlights the difficulty models face in distinguishing such subtle
variations. To enhance fine-grained understanding, we propose a new baseline
that can be easily combined with current methods. Experiments on our
fine-grained evaluations demonstrate that this approach enhances a model's
ability to understand fine-grained differences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ De-Identification of Medical Imaging Data: A Comprehensive Tool for
  Ensuring Patient Privacy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12402v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12402v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moritz Rempe, Lukas Heine, Constantin Seibold, Fabian Hörst, Jens Kleesiek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical data employed in research frequently comprises sensitive patient
health information (PHI), which is subject to rigorous legal frameworks such as
the General Data Protection Regulation (GDPR) or the Health Insurance
Portability and Accountability Act (HIPAA). Consequently, these types of data
must be pseudonymized prior to utilisation, which presents a significant
challenge for many researchers. Given the vast array of medical data, it is
necessary to employ a variety of de-identification techniques. To facilitate
the anonymization process for medical imaging data, we have developed an
open-source tool that can be used to de-identify DICOM magnetic resonance
images, computer tomography images, whole slide images and magnetic resonance
twix raw data. Furthermore, the implementation of a neural network enables the
removal of text within the images. The proposed tool automates an elaborate
anonymization pipeline for multiple types of inputs, reducing the need for
additional tools used for de-identification of imaging data. We make our code
publicly available at
https://github.com/code-lukas/medical_image_deidentification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Feature Augmentation for <span class="highlight-title">Self-supervised</span> Contrastive Learning: A Closer
  Look <span class="chip">IJCNN 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Zhang, Rui Zhu, Shifeng Zhang, Xu Zhou, Shifeng Chen, Xiaofan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised contrastive learning heavily relies on the view variance
brought by data augmentation, so that it can learn a view-invariant pre-trained
representation. Beyond increasing the view variance for contrast, this work
focuses on improving the diversity of training data, to improve the
generalization and robustness of the pre-trained models. To this end, we
propose a unified framework to conduct data augmentation in the feature space,
known as feature augmentation. This strategy is domain-agnostic, which augments
similar features to the original ones and thus improves the data diversity. We
perform a systematic investigation of various feature augmentation
architectures, the gradient-flow skill, and the relationship between feature
augmentation and traditional data augmentation. Our study reveals some
practical principles for feature augmentation in self-contrastive learning. By
integrating feature augmentation on the instance discrimination or the instance
similarity paradigm, we consistently improve the performance of pre-trained
feature learning and gain better generalization over the downstream image
classification and object detection task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IJCNN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Real-time Stereo-based 3D Object Detection for Streaming Perception <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12394v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12394v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changcai Li, Zonghua Gu, Gang Chen, Libo Huang, Wei Zhang, Huihui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to promptly respond to environmental changes is crucial for the
perception system of autonomous driving. Recently, a new task called streaming
perception was proposed. It jointly evaluate the latency and accuracy into a
single metric for video online perception. In this work, we introduce
StreamDSGN, the first real-time stereo-based 3D object detection framework
designed for streaming perception. StreamDSGN is an end-to-end framework that
directly predicts the 3D properties of objects in the next moment by leveraging
historical information, thereby alleviating the accuracy degradation of
streaming perception. Further, StreamDSGN applies three strategies to enhance
the perception accuracy: (1) A feature-flow-based fusion method, which
generates a pseudo-next feature at the current moment to address the
misalignment issue between feature and ground truth. (2) An extra regression
loss for explicit supervision of object motion consistency in consecutive
frames. (3) A large kernel backbone with a large receptive field for
effectively capturing long-range spatial contextual features caused by changes
in object positions. Experiments on the KITTI Tracking dataset show that,
compared with the strong baseline, StreamDSGN significantly improves the
streaming average precision by up to 4.33%. Our code is available at
https://github.com/weiyangdaren/streamDSGN-pytorch.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Streaming Perception, 3D Object Detection, NeurIPS2024 poster</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of
  Large Multimodal Models Through Coding Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengji Zhang, Linquan Wu, Huiyu Bai, Guancheng Lin, Xiao Li, Xiao Yu, Yue Wang, Bei Chen, Jacky Keung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coding tasks have been valuable for evaluating Large Language Models (LLMs),
as they demand the comprehension of high-level instructions, complex reasoning,
and the implementation of functional programs -- core capabilities for
advancing Artificial General Intelligence. Despite the progress in Large
Multimodal Models (LMMs), which extend LLMs with visual perception and
understanding capabilities, there remains a notable lack of coding benchmarks
that rigorously assess these models, particularly in tasks that emphasize
visual reasoning. To address this gap, we introduce HumanEval-V, a novel and
lightweight benchmark specifically designed to evaluate LMMs' visual
understanding and reasoning capabilities through code generation. HumanEval-V
includes 108 carefully crafted, entry-level Python coding tasks derived from
platforms like CodeForces and Stack Overflow. Each task is adapted by modifying
the context and algorithmic patterns of the original problems, with visual
elements redrawn to ensure distinction from the source, preventing potential
data leakage. LMMs are required to complete the code solution based on the
provided visual context and a predefined Python function signature outlining
the task requirements. Every task is equipped with meticulously handcrafted
test cases to ensure a thorough and reliable evaluation of model-generated
solutions. We evaluate 19 state-of-the-art LMMs using HumanEval-V, uncovering
significant challenges. Proprietary models like GPT-4o achieve only 13% pass@1
and 36.4% pass@10, while open-weight models with 70B parameters score below 4%
pass@1. Ablation studies further reveal the limitations of current LMMs in
vision reasoning and coding capabilities. These results underscore key areas
for future research to enhance LMMs' capabilities. We have open-sourced our
code and benchmark at https://github.com/HumanEval-V/HumanEval-V-Benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>homepage https://humaneval-v.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stylistic Multi-Task Analysis of Ukiyo-e Woodblock Prints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12379v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12379v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Selina Khan, Nanne van Noord
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work we present a large-scale dataset of \textit{Ukiyo-e} woodblock
prints. Unlike previous works and datasets in the artistic domain that
primarily focus on western art, this paper explores this pre-modern Japanese
art form with the aim of broadening the scope for stylistic analysis and to
provide a benchmark to evaluate a variety of art focused Computer Vision
approaches. Our dataset consists of over $175.000$ prints with corresponding
metadata (\eg artist, era, and creation date) from the 17th century to present
day. By approaching stylistic analysis as a Multi-Task problem we aim to more
efficiently utilize the available metadata, and learn more general
representations of style. We show results for well-known baselines and
state-of-the-art multi-task learning frameworks to enable future comparison,
and to encourage stylistic analysis on this artistic domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GAN Based Top-Down View Synthesis in Reinforcement Learning Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Usama Younus, Vinoj Jayasundara, Shivam Mishra, Suleyman Aslan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human actions are based on the mental perception of the environment. Even
when all the aspects of an environment are not visible, humans have an internal
mental model that can generalize the partially visible scenes to fully
constructed and connected views. This internal mental model uses learned
abstract representations of spatial and temporal aspects of the environments
encountered in the past.
  Artificial agents in reinforcement learning environments also benefit by
learning a representation of the environment from experience. It provides the
agent with viewpoints that are not directly visible to it, helping it make
better policy decisions. It can also be used to predict the future state of the
environment.
  This project explores learning the top-down view of an RL environment based
on the artificial agent's first-person view observations with a generative
adversarial network(GAN). The top-down view is useful as it provides a complete
overview of the environment by building a map of the entire environment. It
provides information about the objects' dimensions and shapes along with their
relative positions with one another. Initially, when only a partial observation
of the environment is visible to the agent, only a partial top-down view is
generated. As the agent explores the environment through a set of actions, the
generated top-down view becomes complete. This generated top-down view can
assist the agent in deducing better policy decisions. The focus of the project
is to learn the top-down view of an RL environment. It doesn't deal with any
Reinforcement Learning task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-Infused Visual Grounding for Art 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Selina Khan, Nanne van Noord
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many artwork collections contain textual attributes that provide rich and
contextualised descriptions of artworks. Visual grounding offers the potential
for localising subjects within these descriptions on images, however, existing
approaches are trained on natural images and generalise poorly to art. In this
paper, we present CIGAr (Context-Infused GroundingDINO for Art), a visual
grounding approach which utilises the artwork descriptions during training as
context, thereby enabling visual grounding on art. In addition, we present a
new dataset, Ukiyo-eVG, with manually annotated phrase-grounding annotations,
and we set a new state-of-the-art for object detection on two artwork datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Flexible and Efficient Diffusion Low Light Enhancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanzhou Lan, Qianli Ma, Yuqi Yang, Zhigang Wang, Dong Wang, Yuan Yuan, Bin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based Low-Light Image Enhancement (LLIE) has demonstrated
significant success in improving the visibility of low-light images. However,
the substantial computational burden introduced by the iterative sampling
process remains a major concern. Current acceleration methods, whether
training-based or training-free, often lead to significant performance
degradation. As a result, to achieve an efficient student model with
performance comparable to that of existing multi-step teacher model, it is
usually necessary to retrain a more capable teacher model. This approach
introduces inflexibility, as it requires additional training to enhance the
teacher's performance. To address these challenges, we propose
\textbf{Re}flectance-aware \textbf{D}iffusion with \textbf{Di}stilled
\textbf{T}rajectory (\textbf{ReDDiT}), a step distillation framework
specifically designed for LLIE. ReDDiT trains a student model to replicate the
teacher's trajectory in fewer steps while also possessing the ability to
surpass the teacher's performance. Specifically, we first introduce a
trajectory decoder from the teacher model to provide guidance. Subsequently, a
reflectance-aware trajectory refinement module is incorporated into the
distillation process to enable more deterministic guidance from the teacher
model. Our framework achieves comparable performance to previous
diffusion-based methods with redundant steps in just 2 steps while establishing
new state-of-the-art (SOTA) results with 8 or 4 steps. Comprehensive
experimental evaluations on 10 benchmark datasets validate the effectiveness of
our method, consistently outperforming existing SOTA methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistant 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12342v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12342v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guopeng Li, Qiang Wang, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most knowledge distillation (KD) methodologies predominantly focus on
teacher-student pairs with similar architectures, such as both being
convolutional neural networks (CNNs). However, the potential and flexibility of
KD can be greatly improved by expanding it to novel Cross-Architecture KD
(CAKD), where the knowledge of homogeneous and heterogeneous teachers can be
transferred flexibly to a given student. The primary challenge in CAKD lies in
the substantial feature gaps between heterogeneous models, originating from the
distinction of their inherent inductive biases and module functions. To this
end, we introduce an assistant model as a bridge to facilitate smooth feature
knowledge transfer between heterogeneous teachers and students. More
importantly, within our proposed design principle, the assistant model combines
the advantages of cross-architecture inductive biases and module functions by
merging convolution and attention modules derived from both student and teacher
module functions. Furthermore, we observe that heterogeneous features exhibit
diverse spatial distributions in CAKD, hindering the effectiveness of
conventional pixel-wise mean squared error (MSE) loss. Therefore, we leverage a
spatial-agnostic InfoNCE loss to align features after spatial smoothing,
thereby improving the feature alignments in CAKD. Our proposed method is
evaluated across some homogeneous model pairs and arbitrary heterogeneous
combinations of CNNs, ViTs, and MLPs, achieving state-of-the-art performance
for distilled models with a maximum gain of 11.47% on CIFAR-100 and 3.67% on
ImageNet-1K. Our code and models will be released.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 6 figures, and 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ARIC: An Activity Recognition <span class="highlight-title">Dataset</span> in Classroom Surveillance Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linfeng Xu, Fanman Meng, Qingbo Wu, Lili Pan, Heqian Qiu, Lanxiao Wang, Kailong Chen, Kanglei Geng, Yilei Qian, Haojie Wang, Shuchang Zhou, Shimou Ling, Zejia Liu, Nanlin Chen, Yingjie Xu, Shaoxu Cheng, Bowen Tan, Ziyong Xu, Hongliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The application of activity recognition in the ``AI + Education" field is
gaining increasing attention. However, current work mainly focuses on the
recognition of activities in manually captured videos and a limited number of
activity types, with little attention given to recognizing activities in
surveillance images from real classrooms. Activity recognition in classroom
surveillance images faces multiple challenges, such as class imbalance and high
activity similarity. To address this gap, we constructed a novel multimodal
dataset focused on classroom surveillance image activity recognition called
ARIC (Activity Recognition In Classroom). The ARIC dataset has advantages of
multiple perspectives, 32 activity categories, three modalities, and real-world
classroom scenarios. In addition to the general activity recognition tasks, we
also provide settings for continual learning and few-shot continual learning.
We hope that the ARIC dataset can act as a facilitator for future analysis and
research for open teaching scenarios. You can download preliminary data from
https://ivipclab.github.io/publication_ARIC/ARIC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2409.03354</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of
  MLLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12332v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12332v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunqiu Xu, Linchao Zhu, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While multimodal large language models (MLLMs) have demonstrated
extraordinary vision-language understanding capabilities and shown potential to
serve as general-purpose assistants, their abilities to solve instance-level
visual-language problems beyond a single image warrant further exploration. In
order to assess these unproven abilities of MLLMs, this paper proposes a new
visual grounding task called multi-context visual grounding, which aims to
localize instances of interest across multiple images based on open-ended text
prompts. To facilitate this research, we meticulously construct a new dataset
MC-Bench for benchmarking the visual grounding capabilities of MLLMs. MC-Bench
features 2K high-quality and manually annotated samples, consisting of
instance-level labeled image pairs and corresponding text prompts that indicate
the target instances in the images. In total, there are three distinct styles
of text prompts, covering 20 practical skills. We benchmark over 20
state-of-the-art MLLMs and foundation models with potential multi-context
visual grounding capabilities. Our evaluation reveals a non-trivial performance
gap between existing MLLMs and humans across all metrics. We also observe that
existing MLLMs typically outperform foundation models without LLMs only on
image-level metrics, and the specialist MLLMs trained on single images often
struggle to generalize to multi-image scenarios. Moreover, a simple stepwise
baseline integrating advanced MLLM and a detector can significantly surpass
prior end-to-end MLLMs. We hope our MC-Bench and empirical findings can
encourage the research community to further explore and enhance the untapped
potentials of MLLMs in instance-level tasks, particularly in multi-image
contexts. Project page: https://xuyunqiu.github.io/MC-Bench/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improved Anomaly Detection through Conditional Latent Space VAE
  Ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Åström, Alexandros Sopasakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel Conditional Latent space Variational Autoencoder (CL-VAE)
to perform improved pre-processing for anomaly detection on data with known
inlier classes and unknown outlier classes. This proposed variational
autoencoder (VAE) improves latent space separation by conditioning on
information within the data. The method fits a unique prior distribution to
each class in the dataset, effectively expanding the classic prior distribution
for VAEs to include a Gaussian mixture model. An ensemble of these VAEs are
merged in the latent spaces to form a group consensus that greatly improves the
accuracy of anomaly detection across data sets. Our approach is compared
against the capabilities of a typical VAE, a CNN, and a PCA, with regards AUC
for anomaly detection. The proposed model shows increased accuracy in anomaly
detection, achieving an AUC of 97.4% on the MNIST dataset compared to 95.7% for
the second best model. In addition, the CL-VAE shows increased benefits from
ensembling, a more interpretable latent space, and an increased ability to
learn patterns in complex data with limited model sizes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages of main article, 19 pages including references and appendix,
  4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanghao Li, Yu Cao, Qi Chen, Yifan Yang, Jian Pu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In point-line SLAM systems, the utilization of line structural information
and the optimization of lines are two significant problems. The former is
usually addressed through structural regularities, while the latter typically
involves using minimal parameter representations of lines in optimization.
However, separating these two steps leads to the loss of constraint information
to each other. We anchor lines with similar directions to a principal axis and
optimize them with $n+2$ parameters for $n$ lines, solving both problems
together. Our method considers scene structural information, which can be
easily extended to different world hypotheses while significantly reducing the
number of line parameters to be optimized, enabling rapid and accurate mapping
and tracking. To further enhance the system's robustness and avoid mismatch, we
have modeled the line-axis probabilistic data association and provided the
algorithm for axis creation, updating, and optimization. Additionally,
considering that most real-world scenes conform to the Atlanta World
hypothesis, we provide a structural line detection strategy based on vertical
priors and vanishing points. Experimental results and ablation studies on
various indoor and outdoor datasets demonstrate the effectiveness of our
system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FaceChain-FACT: Face Adapter with Decoupled Training for
  Identity-preserved Personalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12312v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12312v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Yu, Haoyu Xie, Lei Shang, Yang Liu, Jun Dan, Baigui Sun, Liefeng Bo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the field of human-centric personalized image generation, the
adapter-based method obtains the ability to customize and generate portraits by
text-to-image training on facial data. This allows for identity-preserved
personalization without additional fine-tuning in inference. Although there are
improvements in efficiency and fidelity, there is often a significant
performance decrease in test following ability, controllability, and diversity
of generated faces compared to the base model. In this paper, we analyze that
the performance degradation is attributed to the failure to decouple identity
features from other attributes during extraction, as well as the failure to
decouple the portrait generation training from the overall generation task. To
address these issues, we propose the Face Adapter with deCoupled Training
(FACT) framework, focusing on both model architecture and training strategy. To
decouple identity features from others, we leverage a transformer-based
face-export encoder and harness fine-grained identity features. To decouple the
portrait generation training, we propose Face Adapting Increment
Regularization~(FAIR), which effectively constrains the effect of face adapters
on the facial region, preserving the generative ability of the base model.
Additionally, we incorporate a face condition drop and shuffle mechanism,
combined with curriculum learning, to enhance facial controllability and
diversity. As a result, FACT solely learns identity preservation from training
data, thereby minimizing the impact on the original text-to-image capabilities
of the base model. Extensive experiments show that FACT has both
controllability and fidelity in both text-to-image generation and inpainting
solutions for portrait generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in
  Frequency Domain 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengpeng Li, Kemou Li, Haiwei Wu, Jinyu Tian, Jiantao Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To protect deep neural networks (DNNs) from adversarial attacks, adversarial
training (AT) is developed by incorporating adversarial examples (AEs) into
model training. Recent studies show that adversarial attacks disproportionately
impact the patterns within the phase of the sample's frequency spectrum --
typically containing crucial semantic information -- more than those in the
amplitude, resulting in the model's erroneous categorization of AEs. We find
that, by mixing the amplitude of training samples' frequency spectrum with
those of distractor images for AT, the model can be guided to focus on phase
patterns unaffected by adversarial perturbations. As a result, the model's
robustness can be improved. Unfortunately, it is still challenging to select
appropriate distractor images, which should mix the amplitude without affecting
the phase patterns. To this end, in this paper, we propose an optimized
Adversarial Amplitude Generator (AAG) to achieve a better tradeoff between
improving the model's robustness and retaining phase patterns. Based on this
generator, together with an efficient AE production procedure, we design a new
Dual Adversarial Training (DAT) strategy. Experiments on various datasets show
that our proposed DAT leads to significantly improved robustness against
diverse adversarial attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Consistency Calibration: Improving Uncertainty Calibration via
  Consistency among Perturbed Neighbors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12295v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12295v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Calibration is crucial in deep learning applications, especially in fields
like healthcare and autonomous driving, where accurate confidence estimates are
vital for decision-making. However, deep neural networks often suffer from
miscalibration, with reliability diagrams and Expected Calibration Error (ECE)
being the only standard perspective for evaluating calibration performance. In
this paper, we introduce the concept of consistency as an alternative
perspective on model calibration, inspired by uncertainty estimation literature
in large language models (LLMs). We highlight its advantages over the
traditional reliability-based view. Building on this concept, we propose a
post-hoc calibration method called Consistency Calibration (CC), which adjusts
confidence based on the model's consistency across perturbed inputs. CC is
particularly effective in locally uncertainty estimation, as it requires no
additional data samples or label information, instead generating input
perturbations directly from the source data. Moreover, we show that performing
perturbations at the logit level significantly improves computational
efficiency. We validate the effectiveness of CC through extensive comparisons
with various post-hoc and training-time calibration methods, demonstrating
state-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100,
and ImageNet, as well as on long-tailed datasets like ImageNet-LT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical
  Decision-Support Setting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxime Kayser, Bayar Menzat, Cornelius Emde, Bogdan Bercean, Alex Novak, Abdala Espinosa, Bartlomiej W. Papiez, Susanne Gaube, Thomas Lukasiewicz, Oana-Maria Camburu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing capabilities of AI models are leading to their wider use,
including in safety-critical domains. Explainable AI (XAI) aims to make these
models safer to use by making their inference process more transparent.
However, current explainability methods are seldom evaluated in the way they
are intended to be used: by real-world end users. To address this, we conducted
a large-scale user study with 85 healthcare practitioners in the context of
human-AI collaborative chest X-ray analysis. We evaluated three types of
explanations: visual explanations (saliency maps), natural language
explanations, and a combination of both modalities. We specifically examined
how different explanation types influence users depending on whether the AI
advice and explanations are factually correct. We find that text-based
explanations lead to significant over-reliance, which is alleviated by
combining them with saliency maps. We also observe that the quality of
explanations, that is, how much factually correct information they entail, and
how much this aligns with AI correctness, significantly impacts the usefulness
of the different explanation types.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Controlled Automatic Task-Specific Synthetic Data Generation for
  Hallucination Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Xie, Karan Aggarwal, Aitzaz Ahmad, Stephen Lau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to automatically generate non-trivial
task-specific synthetic datasets for hallucination detection. Our approach
features a two-step generation-selection pipeline, using hallucination pattern
guidance and a language style alignment during generation. Hallucination
pattern guidance leverages the most important task-specific hallucination
patterns while language style alignment aligns the style of the synthetic
dataset with benchmark text. To obtain robust supervised detectors from
synthetic datasets, we also adopt a data mixture strategy to improve
performance robustness and generalization. Our results on three datasets show
that our generated hallucination text is more closely aligned with
non-hallucinated text versus baselines, to train hallucination detectors with
better generalization. Our hallucination detectors trained on synthetic
datasets outperform in-context-learning (ICL)-based detectors by a large margin
of 32%. Our extensive experiments confirm the benefits of our approach with
cross-task and cross-generator generalization. Our data-mixture-based training
further improves the generalization and robustness of hallucination detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fusion from Decomposition: A <span class="highlight-title">Self-Supervised</span> Approach for Image Fusion
  and Beyond 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12274v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12274v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengwei Liang, Junjun Jiang, Qing Ma, Xianming Liu, Jiayi Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image fusion is famous as an alternative solution to generate one
high-quality image from multiple images in addition to image restoration from a
single degraded image. The essence of image fusion is to integrate
complementary information from source images. Existing fusion methods struggle
with generalization across various tasks and often require labor-intensive
designs, in which it is difficult to identify and extract useful information
from source images due to the diverse requirements of each fusion task.
Additionally, these methods develop highly specialized features for different
downstream applications, hindering the adaptation to new and diverse downstream
tasks. To address these limitations, we introduce DeFusion++, a novel framework
that leverages self-supervised learning (SSL) to enhance the versatility of
feature representation for different image fusion tasks. DeFusion++ captures
the image fusion task-friendly representations from large-scale data in a
self-supervised way, overcoming the constraints of limited fusion datasets.
Specifically, we introduce two innovative pretext tasks: common and unique
decomposition (CUD) and masked feature modeling (MFM). CUD decomposes source
images into abstract common and unique components, while MFM refines these
components into robust fused features. Jointly training of these tasks enables
DeFusion++ to produce adaptable representations that can effectively extract
useful information from various source images, regardless of the fusion task.
The resulting fused representations are also highly adaptable for a wide range
of downstream tasks, including image segmentation and object detection.
DeFusion++ stands out by producing versatile fused representations that can
enhance both the quality of image fusion and the effectiveness of downstream
high-level vision tasks, simplifying the process with the elegant fusion
framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18page</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haobo Zuo, Changhong Fu, Guangze Zheng, Liangliang Yao, Kunhan Lu, Jia Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain adaptation is an inspiring solution to the misalignment issue of
day/night image features for nighttime UAV tracking. However, the one-step
adaptation paradigm is inadequate in addressing the prevalent difficulties
posed by low-resolution (LR) objects when viewed from the UAVs at night, owing
to the blurry edge contour and limited detail information. Moreover, these
approaches struggle to perceive LR objects disturbed by nighttime noise. To
address these challenges, this work proposes a novel progressive alignment
paradigm, named domain-aware diffusion model (DaDiff), aligning nighttime LR
object features to the daytime by virtue of progressive and stable generations.
The proposed DaDiff includes an alignment encoder to enhance the detail
information of nighttime LR objects, a tracking-oriented layer designed to
achieve close collaboration with tracking tasks, and a successive distribution
discriminator presented to distinguish different feature distributions at each
diffusion timestep successively. Furthermore, an elaborate nighttime UAV
tracking benchmark is constructed for LR objects, namely NUT-LR, consisting of
100 annotated sequences. Exhaustive experiments have demonstrated the
robustness and feature alignment ability of the proposed DaDiff. The source
code and video demo are available at https://github.com/vision4robotics/DaDiff.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural
  Wireframe Alignment <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juelin Zhu, Shen Yan, Long Wang, Shengyue Zhang, Yu Liu, Maojun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a new method named LoD-Loc for visual localization in the air.
Unlike existing localization algorithms, LoD-Loc does not rely on complex 3D
representations and can estimate the pose of an Unmanned Aerial Vehicle (UAV)
using a Level-of-Detail (LoD) 3D map. LoD-Loc mainly achieves this goal by
aligning the wireframe derived from the LoD projected model with that predicted
by the neural network. Specifically, given a coarse pose provided by the UAV
sensor, LoD-Loc hierarchically builds a cost volume for uniformly sampled pose
hypotheses to describe pose probability distribution and select a pose with
maximum probability. Each cost within this volume measures the degree of line
alignment between projected and predicted wireframes. LoD-Loc also devises a
6-DoF pose optimization algorithm to refine the previous result with a
differentiable Gaussian-Newton method. As no public dataset exists for the
studied problem, we collect two datasets with map levels of LoD3.0 and LoD2.0,
along with real RGB queries and ground-truth pose annotations. We benchmark our
method and demonstrate that LoD-Loc achieves excellent performance, even
surpassing current state-of-the-art methods that use textured 3D models for
localization. The code and dataset are available at
https://victorzoo.github.io/LoD-Loc.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024; for Project page, see
  https://victorzoo.github.io/LoD-Loc.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing YOLOv5s Object Detection through Knowledge Distillation
  algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12259v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12259v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanming Huang, Aoran Shen, Yuxiang Hu, Junliang Du, Jiacheng Hu, Yingbin Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the application of knowledge distillation technology in
target detection tasks, especially the impact of different distillation
temperatures on the performance of student models. By using YOLOv5l as the
teacher network and a smaller YOLOv5s as the student network, we found that
with the increase of distillation temperature, the student's detection accuracy
gradually improved, and finally achieved mAP50 and mAP50-95 indicators that
were better than the original YOLOv5s model at a specific temperature.
Experimental results show that appropriate knowledge distillation strategies
can not only improve the accuracy of the model but also help improve the
reliability and stability of the model in practical applications. This paper
also records in detail the accuracy curve and loss function descent curve
during the model training process and shows that the model converges to a
stable state after 150 training cycles. These findings provide a theoretical
basis and technical reference for further optimizing target detection
algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Healthcare: Innovative ML Approaches for Improved Medical
  Imaging in Data-Constrained Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Al Amin, Kamrul Hasan, Saleh Zein-Sabatto, Liang Hong, Sachin Shetty, Imtiaz Ahmed, Tariqul Islam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Healthcare industries face challenges when experiencing rare diseases due to
limited samples. Artificial Intelligence (AI) communities overcome this
situation to create synthetic data which is an ethical and privacy issue in the
medical domain. This research introduces the CAT-U-Net framework as a new
approach to overcome these limitations, which enhances feature extraction from
medical images without the need for large datasets. The proposed framework adds
an extra concatenation layer with downsampling parts, thereby improving its
ability to learn from limited data while maintaining patient privacy. To
validate, the proposed framework's robustness, different medical conditioning
datasets were utilized including COVID-19, brain tumors, and wrist fractures.
The framework achieved nearly 98% reconstruction accuracy, with a Dice
coefficient close to 0.946. The proposed CAT-U-Net has the potential to make a
big difference in medical image diagnostics in settings with limited data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EG-HumanNeRF: Efficient Generalizable Human NeRF Utilizing Human Prior
  for Sparse View 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12242v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12242v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaorong Wang, Yoshihiro Kanamori, Yuki Endo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalizable neural radiance field (NeRF) enables neural-based digital human
rendering without per-scene retraining. When combined with human prior
knowledge, high-quality human rendering can be achieved even with sparse input
views. However, the inference of these methods is still slow, as a large number
of neural network queries on each ray are required to ensure the rendering
quality. Moreover, occluded regions often suffer from artifacts, especially
when the input views are sparse. To address these issues, we propose a
generalizable human NeRF framework that achieves high-quality and real-time
rendering with sparse input views by extensively leveraging human prior
knowledge. We accelerate the rendering with a two-stage sampling reduction
strategy: first constructing boundary meshes around the human geometry to
reduce the number of ray samples for sampling guidance regression, and then
volume rendering using fewer guided samples. To improve rendering quality,
especially in occluded regions, we propose an occlusion-aware attention
mechanism to extract occlusion information from the human priors, followed by
an image space refinement network to improve rendering quality. Furthermore,
for volume rendering, we adopt a signed ray distance function (SRDF)
formulation, which allows us to propose an SRDF loss at every sample position
to improve the rendering quality further. Our experiments demonstrate that our
method outperforms the state-of-the-art methods in rendering quality and has a
competitive rendering speed compared with speed-prioritized novel view
synthesis methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>project page: https://github.com/LarsPh/EG-HumanNeRF</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Spatial Attention and Edge Context for Optimized Feature
  Selection in Visual Localization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nanda Febri Istighfarin, HyungGi Jo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual localization determines an agent's precise position and orientation
within an environment using visual data. It has become a critical task in the
field of robotics, particularly in applications such as autonomous navigation.
This is due to the ability to determine an agent's pose using cost-effective
sensors such as RGB cameras. Recent methods in visual localization employ scene
coordinate regression to determine the agent's pose. However, these methods
face challenges as they attempt to regress 2D-3D correspondences across the
entire image region, despite not all regions providing useful information. To
address this issue, we introduce an attention network that selectively targets
informative regions of the image. Using this network, we identify the
highest-scoring features to improve the feature selection process and combine
the result with edge detection. This integration ensures that the features
chosen for the training buffer are located within robust regions, thereby
improving 2D-3D correspondence and overall localization performance. Our
approach was tested on the outdoor benchmark dataset, demonstrating superior
results compared to previous methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Cascaded Methods of Vision-Language Models for Zero-Shot
  Detection and Association of Hardhats for Increased Construction Safety 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12225v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12225v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Choi, Ross Greer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper evaluates the use of vision-language models (VLMs) for zero-shot
detection and association of hardhats to enhance construction safety. Given the
significant risk of head injuries in construction, proper enforcement of
hardhat use is critical. We investigate the applicability of foundation models,
specifically OWLv2, for detecting hardhats in real-world construction site
images. Our contributions include the creation of a new benchmark dataset,
Hardhat Safety Detection Dataset, by filtering and combining existing datasets
and the development of a cascaded detection approach. Experimental results on
5,210 images demonstrate that the OWLv2 model achieves an average precision of
0.6493 for hardhat detection. We further analyze the limitations and potential
improvements for real-world applications, highlighting the strengths and
weaknesses of current foundation models in safety perception domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Order-Aware Interactive Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Wang, Anwesa Choudhuri, Meng Zheng, Zhongpai Gao, Benjamin Planche, Andong Deng, Qin Liu, Terrence Chen, Ulas Bagci, Ziyan Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interactive segmentation aims to accurately segment target objects with
minimal user interactions. However, current methods often fail to accurately
separate target objects from the background, due to a limited understanding of
order, the relative depth between objects in a scene. To address this issue, we
propose OIS: order-aware interactive segmentation, where we explicitly encode
the relative depth between objects into order maps. We introduce a novel
order-aware attention, where the order maps seamlessly guide the user
interactions (in the form of clicks) to attend to the image features. We
further present an object-aware attention module to incorporate a strong
object-level understanding to better differentiate objects with similar order.
Our approach allows both dense and sparse integration of user clicks, enhancing
both accuracy and efficiency as compared to prior works. Experimental results
demonstrate that OIS achieves state-of-the-art performance, improving mIoU
after one click by 7.61 on the HQSeg44K dataset and 1.32 on the DAVIS dataset
as compared to the previous state-of-the-art SegNext, while also doubling
inference speed compared to current leading methods. The project page is
https://ukaukaaaa.github.io/projects/OIS/index.html
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Interactive demo can be found in project page:
  https://ukaukaaaa.github.io/projects/OIS/index.html</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse Prototype Network for Explainable Pedestrian Behavior Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12195v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12195v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Feng, Alexander Carballo, Kazuya Takeda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting pedestrian behavior is challenging yet crucial for applications
such as autonomous driving and smart city. Recent deep learning models have
achieved remarkable performance in making accurate predictions, but they fail
to provide explanations of their inner workings. One reason for this problem is
the multi-modal inputs. To bridge this gap, we present Sparse Prototype Network
(SPN), an explainable method designed to simultaneously predict a pedestrian's
future action, trajectory, and pose. SPN leverages an intermediate prototype
bottleneck layer to provide sample-based explanations for its predictions. The
prototypes are modality-independent, meaning that they can correspond to any
modality from the input. Therefore, SPN can extend to arbitrary combinations of
modalities. Regularized by mono-semanticity and clustering constraints, the
prototypes learn consistent and human-understandable features and achieve
state-of-the-art performance on action, trajectory and pose prediction on TITAN
and PIE. Finally, we propose a metric named Top-K Mono-semanticity Scale to
quantitatively evaluate the explainability. Qualitative results show the
positive correlation between sparsity and explainability. Code available at
https://github.com/Equinoxxxxx/SPN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Test-time adaptation for image compression with distribution
  regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kecheng Chen, Pingping Zhang, Tiexin Qin, Shiqi Wang, Hong Yan, Haoliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current test- or compression-time adaptation image compression (TTA-IC)
approaches, which leverage both latent and decoder refinements as a two-step
adaptation scheme, have potentially enhanced the rate-distortion (R-D)
performance of learned image compression models on cross-domain compression
tasks, \textit{e.g.,} from natural to screen content images. However, compared
with the emergence of various decoder refinement variants, the latent
refinement, as an inseparable ingredient, is barely tailored to cross-domain
scenarios. To this end, we aim to develop an advanced latent refinement method
by extending the effective hybrid latent refinement (HLR) method, which is
designed for \textit{in-domain} inference improvement but shows noticeable
degradation of the rate cost in \textit{cross-domain} tasks. Specifically, we
first provide theoretical analyses, in a cue of marginalization approximation
from in- to cross-domain scenarios, to uncover that the vanilla HLR suffers
from an underlying mismatch between refined Gaussian conditional and hyperprior
distributions, leading to deteriorated joint probability approximation of
marginal distribution with increased rate consumption. To remedy this issue, we
introduce a simple Bayesian approximation-endowed \textit{distribution
regularization} to encourage learning a better joint probability approximation
in a plug-and-play manner. Extensive experiments on six in- and cross-domain
datasets demonstrate that our proposed method not only improves the R-D
performance compared with other latent refinement counterparts, but also can be
flexibly integrated into existing TTA-IC methods with incremental benefits.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TransAgent: Transfer Vision-Language Foundation Models with
  Heterogeneous Agent Collaboration <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwei Guo, Shaobin Zhuang, Kunchang Li, Yu Qiao, Yali Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language foundation models (such as CLIP) have recently shown their
power in transfer learning, owing to large-scale image-text pre-training.
However, target domain data in the downstream tasks can be highly different
from the pre-training phase, which makes it hard for such a single model to
generalize well. Alternatively, there exists a wide range of expert models that
contain diversified vision and/or language knowledge pre-trained on different
modalities, tasks, networks, and datasets. Unfortunately, these models are
"isolated agents" with heterogeneous structures, and how to integrate their
knowledge for generalizing CLIP-like models has not been fully explored. To
bridge this gap, we propose a general and concise TransAgent framework, which
transports the knowledge of the isolated agents in a unified manner, and
effectively guides CLIP to generalize with multi-source knowledge distillation.
With such a distinct framework, we flexibly collaborate with 11 heterogeneous
agents to empower vision-language foundation models, without further cost in
the inference phase. Finally, our TransAgent achieves state-of-the-art
performance on 11 visual recognition datasets. Under the same low-shot setting,
it outperforms the popular CoOp with around 10% on average, and 20% on EuroSAT
which contains large domain shifts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual-Model Distillation for Efficient Action Classification with Hybrid
  Edge-Cloud Solution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Timothy Wei, Hsien Xin Peng, Elaine Xu, Bryan Zhao, Lei Ding, Diji Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Artificial Intelligence models, such as Large Video-Language models
(VLMs), grow in size, their deployment in real-world applications becomes
increasingly challenging due to hardware limitations and computational costs.
To address this, we design a hybrid edge-cloud solution that leverages the
efficiency of smaller models for local processing while deferring to larger,
more accurate cloud-based models when necessary. Specifically, we propose a
novel unsupervised data generation method, Dual-Model Distillation (DMD), to
train a lightweight switcher model that can predict when the edge model's
output is uncertain and selectively offload inference to the large model in the
cloud. Experimental results on the action classification task show that our
framework not only requires less computational overhead, but also improves
accuracy compared to using a large model alone. Our framework provides a
scalable and adaptable solution for action classification in
resource-constrained environments, with potential applications beyond
healthcare. Noteworthy, while DMD-generated data is used for optimizing
performance and resource usage in our pipeline, we expect the concept of DMD to
further support future research on knowledge alignment across multiple models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAM-Guided Masked Token Prediction for 3D Scene Understanding <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12158v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12158v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhimin Chen, Liang Yang, Yingwei Li, Longlong Jing, Bing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models have significantly enhanced 2D task performance, and recent
works like Bridge3D have successfully applied these models to improve 3D scene
understanding through knowledge distillation, marking considerable
advancements. Nonetheless, challenges such as the misalignment between 2D and
3D representations and the persistent long-tail distribution in 3D datasets
still restrict the effectiveness of knowledge distillation from 2D to 3D using
foundation models. To tackle these issues, we introduce a novel SAM-guided
tokenization method that seamlessly aligns 3D transformer structures with
region-level knowledge distillation, replacing the traditional KNN-based
tokenization techniques. Additionally, we implement a group-balanced
re-weighting strategy to effectively address the long-tail problem in knowledge
distillation. Furthermore, inspired by the recent success of masked feature
prediction, our framework incorporates a two-stage masked token prediction
process in which the student model predicts both the global embeddings and the
token-wise local embeddings derived from the teacher models trained in the
first stage. Our methodology has been validated across multiple datasets,
including SUN RGB-D, ScanNet, and S3DIS, for tasks like 3D object detection and
semantic segmentation. The results demonstrate significant improvements over
current State-of-the-art self-supervised methods, establishing new benchmarks
in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling the Limits of Alignment: Multi-modal Dynamic Local Fusion
  Network and A Benchmark for Unaligned RGBT Video Object Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12143v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12143v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qishun Wang, Zhengzheng Tu, Kunpeng Wang, Le Gu, Chuanwang Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current RGB-Thermal Video Object Detection (RGBT VOD) methods still depend on
manually aligning data at the image level, which hampers its practical
application in real-world scenarios since image pairs captured by multispectral
sensors often differ in both fields of view and resolution. To address this
limitation, we propose a Multi-modal Dynamic Local fusion Network (MDLNet)
designed to handle unaligned RGBT image pairs. Specifically, our proposed
Multi-modal Dynamic Local Fusion (MDLF) module includes a set of predefined
boxes, each enhanced with random Gaussian noise to generate a dynamic box. Each
box selects a local region from the original high-resolution RGB image. This
region is then fused with the corresponding information from another modality
and reinserted into the RGB. This method adapts to various data alignment
scenarios by interacting with local features across different ranges.
Simultaneously, we introduce a Cascaded Temporal Scrambler (CTS) within an
end-to-end architecture. This module leverages consistent spatiotemporal
information from consecutive frames to enhance the representation capability of
the current frame while maintaining network efficiency. We have curated an open
dataset called UVT-VOD2024 for unaligned RGBT VOD. It consists of 30,494 pairs
of unaligned RGBT images captured directly from a multispectral camera. We
conduct a comprehensive evaluation and comparison with MDLNet and
state-of-the-art (SOTA) models, demonstrating the superior effectiveness of
MDLNet. We will release our code and UVT-VOD2024 to the public for further
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preserving Cardiac Integrity: A Topology-Infused Approach to Whole Heart
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10551v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10551v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyu Zhang, Wenxue Guan, Xiaodan Xing, Guang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whole heart segmentation (WHS) supports cardiovascular disease (CVD)
diagnosis, disease monitoring, treatment planning, and prognosis. Deep learning
has become the most widely used method for WHS applications in recent years.
However, segmentation of whole-heart structures faces numerous challenges
including heart shape variability during the cardiac cycle, clinical artifacts
like motion and poor contrast-to-noise ratio, domain shifts in multi-center
data, and the distinct modalities of CT and MRI. To address these limitations
and improve segmentation quality, this paper introduces a new
topology-preserving module that is integrated into deep neural networks. The
implementation achieves anatomically plausible segmentation by using learned
topology-preserving fields, which are based entirely on 3D convolution and are
therefore very effective for 3D voxel data. We incorporate natural constraints
between structures into the end-to-end training and enrich the feature
representation of the neural network. The effectiveness of the proposed method
is validated on an open-source medical heart dataset, specifically using the
WHS++ data. The results demonstrate that the architecture performs
exceptionally well, achieving a Dice coefficient of 0.939 during testing. This
indicates full topology preservation for individual structures and
significantly outperforms other baselines in preserving the overall scene
topology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing
  Pipelines <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.02181v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.02181v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renjith Prasad, Chathurangi Shyalika, Ramtin Zand, Fadi El Kalach, Revathy Venkataramanan, Ramy Harik, Amit Sheth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection in manufacturing pipelines remains a critical challenge,
intensified by the complexity and variability of industrial environments. This
paper introduces AssemAI, an interpretable image-based anomaly detection system
tailored for smart manufacturing pipelines. Utilizing a curated image dataset
from an industry-focused rocket assembly pipeline, we address the challenge of
imbalanced image data and demonstrate the importance of image-based methods in
anomaly detection. Our primary contributions include deriving an image dataset,
fine-tuning an object detection model YOLO-FF, and implementing a custom
anomaly detection model for assembly pipelines. The proposed approach leverages
domain knowledge in data preparation, model development and reasoning. We
implement several anomaly detection models on the derived image dataset,
including a Convolutional Neural Network, Vision Transformer (ViT), and
pre-trained versions of these models. Additionally, we incorporate
explainability techniques at both user and model levels, utilizing ontology for
user-level explanations and SCORE-CAM for in-depth feature and model analysis.
Finally, the best-performing anomaly detection model and YOLO-FF are deployed
in a real-time setting. Our results include ablation studies on the baselines
and a comprehensive evaluation of the proposed system. This work highlights the
broader impact of advanced image-based anomaly detection in enhancing the
reliability and efficiency of smart manufacturing processes. The image dataset,
codes to reproduce the results and additional experiments are available at
https://github.com/renjithk4/AssemAI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 Pages, 6 Figures, 4 Tables, Predictive Models in Engineering
  Applications special session (MLPMEA )at International Conference on Machine
  Learning and Applications (ICMLA) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding Figurative Meaning through Explainable Visual Entailment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01474v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01474v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arkadiy Saakyan, Shreyas Kulkarni, Tuhin Chakrabarty, Smaranda Muresan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (VLMs) have demonstrated strong capabilities in
tasks requiring a fine-grained understanding of literal meaning in images and
text, such as visual question-answering or visual entailment. However, there
has been little exploration of these models' capabilities when presented with
images and captions containing figurative meaning, such as metaphors or humor.
To close this gap, we propose a new task framing the figurative meaning
understanding problem as an explainable visual entailment task, where the model
has to predict whether the image (premise) entails a caption (hypothesis) and
justify the predicted label with a textual explanation. The figurative
phenomena can be present either in the image, the caption, or both. Utilizing a
human-AI collaboration approach, we build the accompanying expert-verified
dataset V-FLUTE, containing 6,027 {image, caption, label, explanation}
instances spanning five diverse figurative phenomena: metaphors, similes,
idioms, sarcasm, and humor. Through automatic evaluation, we find that VLMs
struggle to generalize from literal to figurative meaning, particularly when it
is present in images. Further, we identify common types of errors in VLM
reasoning via human evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Inversion with Timestep-aware Sampling for Training-free
  Non-rigid Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08601v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08601v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunji Jung, Seokju Lee, Tair Djanibekov, Hyunjung Shim, Jong Chul Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-guided non-rigid editing involves complex edits for input images, such
as changing motion or compositions within their surroundings. Since it requires
manipulating the input structure, existing methods often struggle with
preserving object identity and background, particularly when combined with
Stable Diffusion. In this work, we propose a training-free approach for
non-rigid editing with Stable Diffusion, aimed at improving the identity
preservation quality without compromising editability. Our approach comprises
three stages: text optimization, latent inversion, and timestep-aware text
injection sampling. Inspired by the success of Imagic, we employ their text
optimization for smooth editing. Then, we introduce latent inversion to
preserve the input image's identity without additional model fine-tuning. To
fully utilize the input reconstruction ability of latent inversion, we suggest
timestep-aware text injection sampling. This effectively retains the structure
of the input image by injecting the source text prompt in early sampling steps
and then transitioning to the target prompt in subsequent sampling steps. This
strategic approach seamlessly harmonizes with text optimization, facilitating
complex non-rigid edits to the input without losing the original identity. We
demonstrate the effectiveness of our method in terms of identity preservation,
editability, and aesthetic quality through extensive experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This manuscript has been submitted to Pattern Recognition Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Self-supervised</span> Learning of LiDAR 3D Point Clouds via 2D-3D Neural
  Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12452v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12452v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Zhang, Siyu Ren, Junhui Hou, Jinjian Wu, Yixuan Yuan, Guangming Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel self-supervised learning framework for
enhancing 3D perception in autonomous driving scenes. Specifically, our
approach, namely NCLR, focuses on 2D-3D neural calibration, a novel pretext
task that estimates the rigid pose aligning camera and LiDAR coordinate
systems. First, we propose the learnable transformation alignment to bridge the
domain gap between image and point cloud data, converting features into a
unified representation space for effective comparison and matching. Second, we
identify the overlapping area between the image and point cloud with the fused
features. Third, we establish dense 2D-3D correspondences to estimate the rigid
pose. The framework not only learns fine-grained matching from points to pixels
but also achieves alignment of the image and point cloud at a holistic level,
understanding their relative pose. We demonstrate the efficacy of NCLR by
applying the pre-trained backbone to downstream tasks, such as LiDAR-based 3D
semantic segmentation, object detection, and panoptic segmentation.
Comprehensive experiments on various datasets illustrate the superiority of
NCLR over existing self-supervised methods. The results confirm that joint
learning from different modalities significantly enhances the network's
understanding abilities and effectiveness of learned representation. The code
is publicly available at https://github.com/Eaphan/NCLR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Tuning Towards Parameter and Inference Efficiency for ViT
  Adaptation <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wangbo Zhao, Jiasheng Tang, Yizeng Han, Yibing Song, Kai Wang, Gao Huang, Fan Wang, Yang You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing parameter-efficient fine-tuning (PEFT) methods have achieved
significant success on vision transformers (ViTs) adaptation by improving
parameter efficiency. However, the exploration of enhancing inference
efficiency during adaptation remains underexplored. This limits the broader
application of pre-trained ViT models, especially when the model is
computationally extensive. In this paper, we propose Dynamic Tuning (DyT), a
novel approach to improve both parameter and inference efficiency for ViT
adaptation. Specifically, besides using the lightweight adapter modules, we
propose a token dispatcher to distinguish informative tokens from less
important ones, allowing the latter to dynamically skip the original block,
thereby reducing the redundant computation during inference. Additionally, we
explore multiple design variants to find the best practice of DyT. Finally,
inspired by the mixture-of-experts (MoE) mechanism, we introduce an enhanced
adapter to further boost the adaptation performance. We validate DyT across
various tasks, including image/video recognition and semantic segmentation. For
instance, DyT achieves superior performance compared to existing PEFT methods
while evoking only 71% of their FLOPs on the VTAB-1K benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ScaleFlow++: Robust and Accurate Estimation of 3D Motion from Video 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09797v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09797v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Ling, Quansen Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Perceiving and understanding 3D motion is a core technology in fields such as
autonomous driving, robots, and motion prediction. This paper proposes a 3D
motion perception method called ScaleFlow++ that is easy to generalize. With
just a pair of RGB images, ScaleFlow++ can robustly estimate optical flow and
motion-in-depth (MID). Most existing methods directly regress MID from two RGB
frames or optical flow, resulting in inaccurate and unstable results. Our key
insight is cross-scale matching, which extracts deep motion clues by matching
objects in pairs of images at different scales. Unlike previous methods,
ScaleFlow++ integrates optical flow and MID estimation into a unified
architecture, estimating optical flow and MID end-to-end based on feature
matching. Moreover, we also proposed modules such as global initialization
network, global iterative optimizer, and hybrid training pipeline to integrate
global motion information, reduce the number of iterations, and prevent
overfitting during training. On KITTI, ScaleFlow++ achieved the best monocular
scene flow estimation performance, reducing SF-all from 6.21 to 5.79. The
evaluation of MID even surpasses RGBD-based methods. In addition, ScaleFlow++
has achieved stunning zero-shot generalization performance in both rigid and
nonrigid scenes. Code is available at
\url{https://github.com/HanLingsgjk/CSCV}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages; Previously this version appeared as arXiv:2409.12202 which
  was submitted as a new work by accident</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Token Reweighting for Interpretable and Controllable Text
  Embeddings in CLIP <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eunji Kim, Kyuhong Shim, Simyung Chang, Sungroh Yoon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A text encoder within Vision-Language Models (VLMs) like CLIP plays a crucial
role in translating textual input into an embedding space shared with images,
thereby facilitating the interpretative analysis of vision tasks through
natural language. Despite the varying significance of different textual
elements within a sentence depending on the context, efforts to account for
variation of importance in constructing text embeddings have been lacking. We
propose a framework of Semantic Token Reweighting to build Interpretable text
embeddings (SToRI), which incorporates controllability as well. SToRI refines
the text encoding process in CLIP by differentially weighting semantic elements
based on contextual importance, enabling finer control over emphasis responsive
to data-driven insights and user preferences. The efficacy of SToRI is
demonstrated through comprehensive experiments on few-shot image classification
and image retrieval tailored to user preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient and Effective Universal Adversarial Attack against
  Vision-Language <span class="highlight-title">Pre-train</span>ing Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11639v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11639v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Yang, Yihao Huang, Kailong Wang, Ling Shi, Geguang Pu, Yang Liu, Haoyu Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language pre-training (VLP) models, trained on large-scale image-text
pairs, have become widely used across a variety of downstream
vision-and-language (V+L) tasks. This widespread adoption raises concerns about
their vulnerability to adversarial attacks. Non-universal adversarial attacks,
while effective, are often impractical for real-time online applications due to
their high computational demands per data instance. Recently, universal
adversarial perturbations (UAPs) have been introduced as a solution, but
existing generator-based UAP methods are significantly time-consuming. To
overcome the limitation, we propose a direct optimization-based UAP approach,
termed DO-UAP, which significantly reduces resource consumption while
maintaining high attack performance. Specifically, we explore the necessity of
multimodal loss design and introduce a useful data augmentation strategy.
Extensive experiments conducted on three benchmark VLP datasets, six popular
VLP models, and three classical downstream tasks demonstrate the efficiency and
effectiveness of DO-UAP. Specifically, our approach drastically decreases the
time consumption by 23-fold while achieving a better attack performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive Convolutional Neural Network for Image Super-resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15704v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15704v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunwei Tian, Xuanyu Zhang, Tao Wang, Yongjun Zhang, Qi Zhu, Chia-Wen Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional neural networks can automatically learn features via deep
network architectures and given input samples. However, the robustness of
obtained models may face challenges in varying scenes. Bigger differences in
network architecture are beneficial to extract more diversified structural
information to strengthen the robustness of an obtained super-resolution model.
In this paper, we proposed a adaptive convolutional neural network for image
super-resolution (ADSRNet). To capture more information, ADSRNet is implemented
by a heterogeneous parallel network. The upper network can enhance relation of
context information, salient information relation of a kernel mapping and
relations of shallow and deep layers to improve performance of image
super-resolution. That can strengthen adaptability of an obtained
super-resolution model for different scenes. The lower network utilizes a
symmetric architecture to enhance relations of different layers to mine more
structural information, which is complementary with a upper network for image
super-resolution. The relevant experimental results show that the proposed
ADSRNet is effective to deal with image resolving. Codes are obtained at
https://github.com/hellloxiaotian/ADSRNet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Diffusion Models: A Comprehensive <span class="highlight-title">Survey</span> from Principles to
  Practices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11795v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11795v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyuan Ma, Yuzhu Zhang, Guoli Jia, Liangliang Zhao, Yichao Ma, Mingjie Ma, Gaofeng Liu, Kaiyan Zhang, Jianjun Li, Bowen Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As one of the most popular and sought-after generative models in the recent
years, diffusion models have sparked the interests of many researchers and
steadily shown excellent advantage in various generative tasks such as image
synthesis, video generation, molecule design, 3D scene rendering and multimodal
generation, relying on their dense theoretical principles and reliable
application practices. The remarkable success of these recent efforts on
diffusion models comes largely from progressive design principles and efficient
architecture, training, inference, and deployment methodologies. However, there
has not been a comprehensive and in-depth review to summarize these principles
and practices to help the rapid understanding and application of diffusion
models. In this survey, we provide a new efficiency-oriented perspective on
these existing efforts, which mainly focuses on the profound principles and
efficient practices in architecture designs, model training, fast inference and
reliable deployment, to guide further theoretical research, algorithm migration
and model application for new scenarios in a reader-friendly way.
\url{https://github.com/ponyzym/Efficient-DMs-Survey}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Developing Generalist Foundation Models from a Multimodal <span class="highlight-title">Dataset</span> for 3D
  Computed Tomography 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17834v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17834v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ibrahim Ethem Hamamci, Sezgin Er, Furkan Almas, Ayse Gulnihan Simsek, Sevval Nil Esirgun, Irem Dogan, Muhammed Furkan Dasdelen, Omer Faruk Durugol, Bastian Wittmann, Tamaz Amiranashvili, Enis Simsar, Mehmet Simsar, Emine Bensu Erdemir, Abdullah Alanbay, Anjany Sekuboyina, Berkan Lafci, Christian Bluethgen, Mehmet Kemal Ozdemir, Bjoern Menze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While computer vision has achieved tremendous success with multimodal
encoding and direct textual interaction with images via chat-based large
language models, similar advancements in medical imaging AI, particularly in 3D
imaging, have been limited due to the scarcity of comprehensive datasets. To
address this critical gap, we introduce CT-RATE, the first dataset that pairs
3D medical images with corresponding textual reports. CT-RATE comprises 25,692
non-contrast 3D chest CT scans from 21,304 unique patients. Through various
reconstructions, these scans are expanded to 50,188 volumes, totaling over 14.3
million 2D slices. Each scan is accompanied by its corresponding radiology
report. Leveraging CT-RATE, we develop CT-CLIP, a CT-focused contrastive
language-image pretraining framework designed for broad applications without
the need for task-specific training. We demonstrate how CT-CLIP can be used in
two tasks: multi-abnormality detection and case retrieval. Remarkably, in
multi-abnormality detection, CT-CLIP outperforms state-of-the-art fully
supervised models across all key metrics, effectively eliminating the need for
manual annotation. In case retrieval, it efficiently retrieves relevant cases
using either image or textual queries, thereby enhancing knowledge
dissemination. By combining CT-CLIP's vision encoder with a pretrained large
language model, we create CT-CHAT, a vision-language foundational chat model
for 3D chest CT volumes. Finetuned on over 2.7 million question-answer pairs
derived from the CT-RATE dataset, CT-CHAT surpasses other multimodal AI
assistants, underscoring the necessity for specialized methods in 3D medical
imaging. Collectively, the open-source release of CT-RATE, CT-CLIP, and CT-CHAT
not only addresses critical challenges in 3D medical imaging but also lays the
groundwork for future innovations in medical AI and improved patient care.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixture of Experts Made Personalized: Federated <span class="highlight-title">Prompt</span> Learning for
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Luo, Chen Chen, Shandong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning for pre-trained Vision-Language Models (VLMs) like CLIP has
demonstrated potent applicability across diverse downstream tasks. This
lightweight approach has quickly gained traction from federated learning (FL)
researchers who seek to efficiently adapt VLMs to heterogeneous scenarios.
However, current federated prompt learning methods are habitually restricted to
the traditional FL paradigm, where the participating clients are generally only
allowed to download a single globally aggregated model from the server. While
justifiable for training full-sized models under federated settings, in this
work, we argue that this paradigm is ill-suited for lightweight prompts. By
facilitating the clients to download multiple pre-aggregated prompts as fixed
non-local experts, we propose Personalized Federated Mixture of Adaptive
Prompts (pFedMoAP), a novel FL framework that personalizes the prompt learning
process through the lens of Mixture of Experts (MoE). pFedMoAP implements a
local attention-based gating network that learns to generate enhanced text
features for better alignment with local image data on the client, benefiting
from both local and downloaded non-local adaptive prompt experts. The non-local
experts are sparsely selected from a server-maintained pool, fostering
collaborative learning across clients. To evaluate the proposed algorithm, we
conduct extensive experiments across 9 datasets under various heterogeneous
federated settings. The results show that pFedMoAP consistently outperforms the
state-of-the-art alternatives, underscoring its efficacy in personalizing
prompt learning for CLIP within the federated learning paradigm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Interpret Your Decision: Logical Reasoning Regularization for
  Generalization in Visual Classification <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04492v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04492v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaorui Tan, Xi Yang, Qiufeng Wang, Anh Nguyen, Kaizhu Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision models excel in image classification but struggle to generalize to
unseen data, such as classifying images from unseen domains or discovering
novel categories. In this paper, we explore the relationship between logical
reasoning and deep learning generalization in visual classification. A logical
regularization termed L-Reg is derived which bridges a logical analysis
framework to image classification. Our work reveals that L-Reg reduces the
complexity of the model in terms of the feature distribution and classifier
weights. Specifically, we unveil the interpretability brought by L-Reg, as it
enables the model to extract the salient features, such as faces to persons,
for classification. Theoretical analysis and experiments demonstrate that L-Reg
enhances generalization across various scenarios, including multi-domain
generalization and generalized category discovery. In complex real-world
scenarios where images span unknown classes and unseen domains, L-Reg
consistently improves generalization, highlighting its practical efficacy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS2024 as Spotlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A3D: Does Diffusion Dream about 3D Alignment? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15020v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15020v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Savva Ignatyev, Nina Konovalova, Daniil Selikhanovych, Oleg Voynov, Nikolay Patakin, Ilya Olkov, Dmitry Senushkin, Alexey Artemov, Anton Konushin, Alexander Filippov, Peter Wonka, Evgeny Burnaev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We tackle the problem of text-driven 3D generation from a geometry alignment
perspective. Given a set of text prompts, we aim to generate a collection of
objects with semantically corresponding parts aligned across them. Recent
methods based on Score Distillation have succeeded in distilling the knowledge
from 2D diffusion models to high-quality representations of the 3D objects.
These methods handle multiple text queries separately, and therefore the
resulting objects have a high variability in object pose and structure.
However, in some applications, such as 3D asset design, it may be desirable to
obtain a set of objects aligned with each other. In order to achieve the
alignment of the corresponding parts of the generated objects, we propose to
embed these objects into a common latent space and optimize the continuous
transitions between these objects. We enforce two kinds of properties of these
transitions: smoothness of the transition and plausibility of the intermediate
objects along the transition. We demonstrate that both of these properties are
essential for good alignment. We provide several practical scenarios that
benefit from alignment between the objects, including 3D editing and object
hybridization, and experimentally demonstrate the effectiveness of our method.
https://voyleg.github.io/a3d/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gaussian Primitives for Deformable Image Registration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03394v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03394v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihe Li, Xiang Liu, Fabian Zhang, Xia Li, Xixin Cao, Ye Zhang, Joachim Buhmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deformable Image Registration (DIR) is essential for aligning medical images
that exhibit anatomical variations, facilitating applications such as disease
tracking and radiotherapy planning. While classical iterative methods and deep
learning approaches have achieved success in DIR, they are often hindered by
computational inefficiency or poor generalization. In this paper, we introduce
GaussianDIR, a novel, case-specific optimization DIR method inspired by 3D
Gaussian splatting. In general, GaussianDIR represents image deformations using
a sparse set of mobile and flexible Gaussian primitives, each defined by a
center position, covariance, and local rigid transformation. This compact and
explicit representation reduces noise and computational overhead while
improving interpretability. Furthermore, the movement of individual voxel is
derived via blending the local rigid transformation of the neighboring Gaussian
primitives. By this, GaussianDIR captures both global smoothness and local
rigidity as well as reduces the computational burden. To address varying levels
of deformation complexity, GaussianDIR also integrates an adaptive density
control mechanism that dynamically adjusts the density of Gaussian primitives.
Additionally, we employ multi-scale Gaussian primitives to capture both coarse
and fine deformations, reducing optimization to local minima. Experimental
results on brain MRI, lung CT, and cardiac MRI datasets demonstrate that
GaussianDIR outperforms existing DIR methods in both accuracy and efficiency,
highlighting its potential for clinical applications. Finally, as a
training-free approach, it challenges the stereotype that iterative methods are
inherently slow and transcend the limitations of poor generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BroadWay: Boost Your Text-to-Video Generation Model in a Training-free
  Way 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06241v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06241v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiazi Bu, Pengyang Ling, Pan Zhang, Tong Wu, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The text-to-video (T2V) generation models, offering convenient visual
creation, have recently garnered increasing attention. Despite their
substantial potential, the generated videos may present artifacts, including
structural implausibility, temporal inconsistency, and a lack of motion, often
resulting in near-static video. In this work, we have identified a correlation
between the disparity of temporal attention maps across different blocks and
the occurrence of temporal inconsistencies. Additionally, we have observed that
the energy contained within the temporal attention maps is directly related to
the magnitude of motion amplitude in the generated videos. Based on these
observations, we present BroadWay, a training-free method to improve the
quality of text-to-video generation without introducing additional parameters,
augmenting memory or sampling time. Specifically, BroadWay is composed of two
principal components: 1) Temporal Self-Guidance improves the structural
plausibility and temporal consistency of generated videos by reducing the
disparity between the temporal attention maps across various decoder blocks. 2)
Fourier-based Motion Enhancement enhances the magnitude and richness of motion
by amplifying the energy of the map. Extensive experiments demonstrate that
BroadWay significantly improves the quality of text-to-video generation with
negligible additional cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VrdONE: One-stage Video Visual Relation Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinjie Jiang, Chenxi Zheng, Xuemiao Xu, Bangzhen Liu, Weiying Zheng, Huaidong Zhang, Shengfeng He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Visual Relation Detection (VidVRD) focuses on understanding how
entities interact over time and space in videos, a key step for gaining deeper
insights into video scenes beyond basic visual tasks. Traditional methods for
VidVRD, challenged by its complexity, typically split the task into two parts:
one for identifying what relation categories are present and another for
determining their temporal boundaries. This split overlooks the inherent
connection between these elements. Addressing the need to recognize entity
pairs' spatiotemporal interactions across a range of durations, we propose
VrdONE, a streamlined yet efficacious one-stage model. VrdONE combines the
features of subjects and objects, turning predicate detection into 1D instance
segmentation on their combined representations. This setup allows for both
relation category identification and binary mask generation in one go,
eliminating the need for extra steps like proposal generation or
post-processing. VrdONE facilitates the interaction of features across various
frames, adeptly capturing both short-lived and enduring relations.
Additionally, we introduce the Subject-Object Synergy (SOS) module, enhancing
how subjects and objects perceive each other before combining. VrdONE achieves
state-of-the-art performances on the VidOR benchmark and ImageNet-VidVRD,
showcasing its superior capability in discerning relations across different
temporal scales. The code is available at https://github.com/lucaspk512/vrdone.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures, accepted by ACM Multimedia 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mini-Omni2: Towards Open-source <span class="highlight-title">GPT</span>-4o with Vision, Speech and Duplex
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11190v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11190v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhifei Xie, Changqiao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  GPT-4o, an all-encompassing model, represents a milestone in the development
of large multi-modal language models. It can understand visual, auditory, and
textual modalities, directly output audio, and support flexible duplex
interaction. Models from the open-source community often achieve some
functionalities of GPT-4o, such as visual understanding and voice chat.
Nevertheless, training a unified model that incorporates all modalities is
challenging due to the complexities of multi-modal data, intricate model
architectures, and training processes. In this paper, we introduce Mini-Omni2,
a visual-audio assistant capable of providing real-time, end-to-end voice
responses to visoin and audio queries. By integrating pretrained visual and
auditory encoders, Mini-Omni2 maintains performance in individual modalities.
We propose a three-stage training process to align modalities, allowing the
language model to handle multi-modal inputs and outputs after training on a
limited dataset. For interaction, we introduce a command-based interruption
mechanism, enabling more flexible interaction with users. To the best of our
knowledge, Mini-Omni2 is one of the closest reproductions of GPT-4o, which have
similar form of functionality, and we hope it can offer valuable insights for
subsequent research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved
  Denoising Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00355v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00355v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Xie, Qian Qiao, Jun Gao, Tianxiang Wu, Jiaqing Fan, Yue Zhang, Jielei Zhang, Huyang Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  More and more end-to-end text spotting methods based on Transformer
architecture have demonstrated superior performance. These methods utilize a
bipartite graph matching algorithm to perform one-to-one optimal matching
between predicted objects and actual objects. However, the instability of
bipartite graph matching can lead to inconsistent optimization targets, thereby
affecting the training performance of the model. Existing literature applies
denoising training to solve the problem of bipartite graph matching instability
in object detection tasks. Unfortunately, this denoising training method cannot
be directly applied to text spotting tasks, as these tasks need to perform
irregular shape detection tasks and more complex text recognition tasks than
classification. To address this issue, we propose a novel denoising training
method (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we
decompose the queries of the denoising part into noised positional queries and
noised content queries. We use the four Bezier control points of the Bezier
center curve to generate the noised positional queries. For the noised content
queries, considering that the output of the text in a fixed positional order is
not conducive to aligning position with content, we employ a masked character
sliding method to initialize noised content queries, thereby assisting in the
alignment of text content and position. To improve the model's perception of
the background, we further utilize an additional loss function for background
characters classification in the denoising training part.Although DNTextSpotter
is conceptually simple, it outperforms the state-of-the-art methods on four
benchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially
yielding an improvement of 11.3% against the best approach in Inverse-Text
dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM'MM2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Large Uni- and Multi-modal Models for Unsupervised Classification of
  Social Media Images: Nature's Contribution to People as a case study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00275v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00275v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohaifa Khaldi, Domingo Alcaraz-Segura, Ignacio Sánchez-Herrera, Javier Martinez-Lopez, Carlos Javier Navarro, Siham Tabik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media images have proven to be a valuable source of information for
understanding human interactions with important subjects such as cultural
heritage, biodiversity, and nature, among others. The task of grouping such
images into a number of semantically meaningful clusters without labels is
challenging due to the high diversity and complex nature of the visual content
in addition to their large volume. On the other hand, recent advances in Large
Visual Models (LVMs), Large Language Models (LLMs), and Large Visual Language
Models (LVLMs) provide an important opportunity to explore new productive and
scalable solutions. This work proposes, analyzes, and compares various
approaches based on one or more state-of-the-art LVM, LLM, and LVLM, for
mapping social media images into a number of predefined classes. As a case
study, we consider the problem of understanding the interactions between humans
and nature, also known as Nature's Contribution to People or Cultural Ecosystem
Services (CES). Our experiments show that the highest-performing approaches,
with accuracy above 95%, still require the creation of a small labeled dataset.
These include the fine-tuned LVM DINOv2 and the LVLM LLaVA-1.5 combined with a
fine-tuned LLM. The top fully unsupervised approaches, achieving accuracy above
84%, are the LVLMs, specifically the proprietary GPT-4 model and the public
LLaVA-1.5 model. Additionally, the LVM DINOv2, when applied in a 10-shot
learning setup, delivered competitive results with an accuracy of 83.99%,
closely matching the performance of the LVLM LLaVA-1.5.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Topological reconstruction of sampled surfaces via Morse theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Franco Coltraro, Jaume Amorós, Maria Alberich-Carramiñana, Carme Torras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we study the perception problem for sampled surfaces (possibly
with boundary) using tools from computational topology, specifically, how to
identify their underlying topology starting from point-cloud samples in space,
such as those obtained with 3D scanners. We present a reconstruction algorithm
based on a careful topological study of the point sample that allows us to
obtain a cellular decomposition of it using a Morse function. No triangulation
or local implicit equations are used as intermediate steps, avoiding in this
way reconstruction-induced artifices. The algorithm can be run without any
prior knowledge of the surface topology, density or regularity of the
point-sample. The results consist of a piece-wise decomposition of the given
surface as a union of Morse cells (i.e. topological disks), suitable for tasks
such as mesh-independent reparametrization or noise-filtering, and a small-rank
cellular complex determining the topology of the surface. The algorithm, which
we test with several real and synthetic surfaces, can be applied to smooth
surfaces with or without boundary, embedded in an ambient space of any
dimension.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages, 17 figures, 1 table, 1 algorithm, 1 appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MFC-Bench: Benchmarking Multimodal Fact-Checking with Large
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11288v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11288v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengkang Wang, Hongzhan Lin, Ziyang Luo, Zhen Ye, Guang Chen, Jing Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) have significantly improved multimodal
reasoning tasks, such as visual question answering and image captioning. These
models embed multimodal facts within their parameters, rather than relying on
external knowledge bases to store factual information explicitly. However, the
content discerned by LVLMs may deviate from actual facts due to inherent bias
or incorrect inference. To address this issue, we introduce MFC-Bench, a
rigorous and comprehensive benchmark designed to evaluate the factual accuracy
of LVLMs across three stages of verdict prediction for MFC: Manipulation,
Out-of-Context, and Veracity Classification. Through our evaluation on
MFC-Bench, we benchmarked a dozen diverse and representative LVLMs, uncovering
that current models still fall short in multimodal fact-checking and
demonstrate insensitivity to various forms of manipulated content. We hope that
MFC-Bench could raise attention to the trustworthy AI potentially assisted by
LVLMs in the future. The MFC-Bench and accompanying resources are publicly
accessible at https://github.com/wskbest/MFC-Bench, contributing to ongoing
research in the multimodal fact-checking field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Free Video-LLM: <span class="highlight-title">Prompt</span>-guided Visual Perception for Efficient
  Training-free Video LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Han, Jianyuan Guo, Yehui Tang, Wei He, Enhua Wu, Yunhe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language large models have achieved remarkable success in various
multi-modal tasks, yet applying them to video understanding remains challenging
due to the inherent complexity and computational demands of video data. While
training-based video-LLMs deliver high performance, they often require
substantial resources for training and inference. Conversely, training-free
approaches offer a more efficient alternative by adapting pre-trained
image-LLMs models for video tasks without additional training, but they face
inference efficiency bottlenecks due to the large number of visual tokens
generated from video frames. In this work, we present a novel prompt-guided
visual perception framework (abbreviated as Free Video-LLM) for efficient
inference of training-free video LLMs. The proposed framework decouples
spatial-temporal dimension and performs temporal frame sampling and spatial RoI
cropping respectively based on task-specific prompts. Our method effectively
reduces the number of visual tokens while maintaining high performance across
multiple video question-answering benchmarks. Extensive experiments demonstrate
that our approach achieves competitive results with significantly fewer tokens,
offering an optimal trade-off between accuracy and computational efficiency
compared to state-of-the-art video LLMs. The code will be available at
https://github.com/contrastive/FreeVideoLLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tech report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Robustness of Vision-Language Models through Orthogonality
  Learning and Self-Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08374v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08374v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinlong Li, Dong Zhao, Zequn Jie, Elisa Ricci, Lin Ma, Nicu Sebe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient fine-tuning of vision-language models (VLMs) like CLIP for specific
downstream tasks is gaining significant attention. Previous works primarily
focus on prompt learning to adapt the CLIP into a variety of downstream tasks,
however, suffering from task overfitting when fine-tuned on a small data set.
In this paper, we introduce an orthogonal fine-tuning method for efficiently
fine-tuning pretrained weights and enabling enhanced robustness and
generalization, while a self-regularization strategy is further exploited to
maintain the stability in terms of zero-shot generalization of VLMs, dubbed
OrthSR. Specifically, trainable orthogonal matrices are injected seamlessly
into the transformer architecture and enforced with orthogonality constraint
during the training, benefiting from the norm-preserving property and thus
leading to stable and faster convergence, while keeping the pre-trained weights
frozen. To alleviate deviation from fine-tuning, a self-regularization strategy
is further employed to retain the generalization of the model during the
training within a bypass manner. In addition, to enrich the sample diversity
for downstream tasks under the small dataset scenario, we first explore
attentive CutOut data augmentation to boost the efficient fine-tuning, leading
to better model fitting capacity for specific downstream task. Then we support
the theoretical analysis on how our approach improves the specific downstream
performance and maintains the generalizability. For the first time, we revisit
the CLIP and CoOp with our method to effectively improve the model on few-shot
image classficiation scenario on par with the elaborated prompt learning
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reverse Stable Diffusion: What <span class="highlight-title">prompt</span> was used to generate this image? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.01472v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.01472v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image diffusion models have recently attracted the interest of many
researchers, and inverting the diffusion process can play an important role in
better understanding the generative process and how to engineer prompts in
order to obtain the desired images. To this end, we study the task of
predicting the prompt embedding given an image generated by a generative
diffusion model. We consider a series of white-box and black-box models (with
and without access to the weights of the diffusion network) to deal with the
proposed task. We propose a novel learning framework comprising a joint prompt
regression and multi-label vocabulary classification objective that generates
improved prompts. To further improve our method, we employ a curriculum
learning procedure that promotes the learning of image-prompt pairs with lower
labeling noise (i.e. that are better aligned). We conduct experiments on the
DiffusionDB data set, predicting text prompts from images generated by Stable
Diffusion. In addition, we make an interesting discovery: training a diffusion
model on the prompt generation task can make the model generate images that are
much better aligned with the input prompts, when the model is directly reused
for text-to-image generation. Our code is publicly available for download at
https://github.com/CroitoruAlin/Reverse-Stable-Diffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in Computer Vision and Image Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Instruction-Guided Visual Masking <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19783v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19783v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinliang Zheng, Jianxiong Li, Sijie Cheng, Yinan Zheng, Jiaming Li, Jihao Liu, Yu Liu, Jingjing Liu, Xianyuan Zhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction following is crucial in contemporary LLM. However, when extended
to multimodal setting, it often suffers from misalignment between specific
textual instruction and targeted local region of an image. To achieve more
accurate and nuanced multimodal instruction following, we introduce
Instruction-guided Visual Masking (IVM), a new versatile visual grounding model
that is compatible with diverse multimodal models, such as LMM and robot model.
By constructing visual masks for instruction-irrelevant regions, IVM-enhanced
multimodal models can effectively focus on task-relevant image regions to
better align with complex instructions. Specifically, we design a visual
masking data generation pipeline and create an IVM-Mix-1M dataset with 1
million image-instruction pairs. We further introduce a new learning technique,
Discriminator Weighted Supervised Learning (DWSL) for preferential IVM training
that prioritizes high-quality data samples. Experimental results on generic
multimodal tasks such as VQA and embodied robotic control demonstrate the
versatility of IVM, which as a plug-and-play tool, significantly boosts the
performance of diverse multimodal models, yielding new state-of-the-art results
across challenging multimodal benchmarks. Code, model and data are available at
https://github.com/2toinf/IVM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ InterACT: Inter-dependency Aware Action Chunking with Hierarchical
  Attention <span class="highlight-title">Transformer</span>s for Bimanual Manipulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07914v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07914v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Lee, Ian Chuang, Ling-Yuan Chen, Iman Soltani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bimanual manipulation presents unique challenges compared to unimanual tasks
due to the complexity of coordinating two robotic arms. In this paper, we
introduce InterACT: Inter-dependency aware Action Chunking with Hierarchical
Attention Transformers, a novel imitation learning framework designed
specifically for bimanual manipulation. InterACT leverages hierarchical
attention mechanisms to effectively capture inter-dependencies between dual-arm
joint states and visual inputs. The framework comprises a Hierarchical
Attention Encoder, which processes multi-modal inputs through segment-wise and
cross-segment attention mechanisms, and a Multi-arm Decoder that generates each
arm's action predictions in parallel, while sharing information between the
arms through synchronization blocks by providing the other arm's intermediate
output as context. Our experiments, conducted on various simulated and
real-world bimanual manipulation tasks, demonstrate that InterACT outperforms
existing methods. Detailed ablation studies further validate the significance
of key components, including the impact of CLS tokens, cross-segment encoders,
and synchronization blocks on task performance. We provide supplementary
materials and videos on our project page.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Conference on Robot Learning (CoRL) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ No Bells, Just Whistles: Sports Field Registration by Leveraging
  Geometric Properties <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08401v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08401v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marc Gutiérrez-Pérez, Antonio Agudo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Broadcast sports field registration is traditionally addressed as a
homography estimation task, mapping the visible image area to a planar field
model, predominantly focusing on the main camera shot. Addressing the
shortcomings of previous approaches, we propose a novel calibration pipeline
enabling camera calibration using a 3D soccer field model and extending the
process to assess the multiple-view nature of broadcast videos. Our approach
begins with a keypoint generation pipeline derived from SoccerNet dataset
annotations, leveraging the geometric properties of the court. Subsequently, we
execute classical camera calibration through DLT algorithm in a minimalist
fashion, without further refinement. Through extensive experimentation on
real-world soccer broadcast datasets such as SoccerNet-Calibration, WorldCup
2014 and TS- WorldCup, our method demonstrates superior performance in both
multiple- and single-view 3D camera calibration while maintaining competitive
results in homography estimation compared to state-of-the-art techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in CVPRW 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Active Fake: DeepFake Camouflage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03200v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03200v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pu Sun, Honggang Qi, Yuezun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  DeepFake technology has gained significant attention due to its ability to
manipulate facial attributes with high realism, raising serious societal
concerns. Face-Swap DeepFake is the most harmful among these techniques, which
fabricates behaviors by swapping original faces with synthesized ones. Existing
forensic methods, primarily based on Deep Neural Networks (DNNs), effectively
expose these manipulations and have become important authenticity indicators.
However, these methods mainly concentrate on capturing the blending
inconsistency in DeepFake faces, raising a new security issue, termed Active
Fake, emerges when individuals intentionally create blending inconsistency in
their authentic videos to evade responsibility. This tactic is called DeepFake
Camouflage. To achieve this, we introduce a new framework for creating DeepFake
camouflage that generates blending inconsistencies while ensuring
imperceptibility, effectiveness, and transferability. This framework, optimized
via an adversarial learning strategy, crafts imperceptible yet effective
inconsistencies to mislead forensic detectors. Extensive experiments
demonstrate the effectiveness and robustness of our method, highlighting the
need for further research in active fake detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic
  Manipulation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10394v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10394v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaidong Zhang, Pengzhen Ren, Bingqian Lin, Junfan Lin, Shikui Ma, Hang Xu, Xiaodan Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language-guided robotic manipulation is a challenging task that requires an
embodied agent to follow abstract user instructions to accomplish various
complex manipulation tasks. Previous work trivially fitting the data without
revealing the relation between instruction and low-level executable actions,
these models are prone to memorizing the surficial pattern of the data instead
of acquiring the transferable knowledge, and thus are fragile to dynamic
environment changes. To address this issue, we propose a PrIrmitive-driVen
waypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses
solely on the prediction of task-relevant waypoints. Specifically, PIVOT-R
consists of a Waypoint-aware World Model (WAWM) and a lightweight action
prediction module. The former performs primitive action parsing and
primitive-driven waypoint prediction, while the latter focuses on decoding
low-level actions. Additionally, we also design an asynchronous hierarchical
executor (AHE), which can use different execution frequencies for different
modules of the model, thereby helping the model reduce computational redundancy
and improve model execution efficiency. Our PIVOT-R outperforms
state-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving
an average relative improvement of 19.45% across four levels of instruction
tasks. Moreover, compared to the synchronously executed PIVOT-R, the execution
efficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop
in performance. These results provide compelling evidence that our PIVOT-R can
significantly improve both the performance and efficiency of robotic
manipulation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Progressive Retinal Image Registration via Global and Local Deformable
  Transformations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01068v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01068v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yepeng Liu, Baosheng Yu, Tian Chen, Yuliang Gu, Bo Du, Yongchao Xu, Jun Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retinal image registration plays an important role in the ophthalmological
diagnosis process. Since there exist variances in viewing angles and anatomical
structures across different retinal images, keypoint-based approaches become
the mainstream methods for retinal image registration thanks to their
robustness and low latency. These methods typically assume the retinal surfaces
are planar, and adopt feature matching to obtain the homography matrix that
represents the global transformation between images. Yet, such a planar
hypothesis inevitably introduces registration errors since retinal surface is
approximately curved. This limitation is more prominent when registering image
pairs with significant differences in viewing angles. To address this problem,
we propose a hybrid registration framework called HybridRetina, which
progressively registers retinal images with global and local deformable
transformations. For that, we use a keypoint detector and a deformation network
called GAMorph to estimate the global transformation and local deformable
transformation, respectively. Specifically, we integrate multi-level pixel
relation knowledge to guide the training of GAMorph. Additionally, we utilize
an edge attention module that includes the geometric priors of the images,
ensuring the deformation field focuses more on the vascular regions of clinical
interest. Experiments on two widely-used datasets, FIRE and FLoRI21, show that
our proposed HybridRetina significantly outperforms some state-of-the-art
methods. The code is available at
https://github.com/lyp-deeplearning/awesome-retinal-registration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at BIBM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deciphering Cross-Modal Alignment in Large Vision-Language Models with
  Modality Integration Rate 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qidong Huang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Dahua Lin, Weiming Zhang, Nenghai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Modality Integration Rate (MIR), an effective, robust, and
generalized metric to indicate the multi-modal pre-training quality of Large
Vision Language Models (LVLMs). Large-scale pre-training plays a critical role
in building capable LVLMs, while evaluating its training quality without the
costly supervised fine-tuning stage is under-explored. Loss, perplexity, and
in-context evaluation results are commonly used pre-training metrics for Large
Language Models (LLMs), while we observed that these metrics are less
indicative when aligning a well-trained LLM with a new modality. Due to the
lack of proper metrics, the research of LVLMs in the critical pre-training
stage is hindered greatly, including the training data choice, efficient module
design, etc. In this paper, we propose evaluating the pre-training quality from
the inter-modal distribution distance perspective and present MIR, the Modality
Integration Rate, which is 1) \textbf{Effective} to represent the pre-training
quality and show a positive relation with the benchmark performance after
supervised fine-tuning. 2) \textbf{Robust} toward different training/evaluation
data. 3) \textbf{Generalize} across training configurations and architecture
choices. We conduct a series of pre-training experiments to explore the
effectiveness of MIR and observe satisfactory results that MIR is indicative
about training data selection, training strategy schedule, and model
architecture design to get better pre-training results. We hope MIR could be a
helpful metric for building capable LVLMs and inspire the following research
about modality alignment in different areas. Our code is at:
https://github.com/shikiw/Modality-Integration-Rate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://github.com/shikiw/Modality-Integration-Rate</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.04804v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.04804v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Feng, Jiangang Huang, Shaoyi Du, Shihui Ying, Jun-Hai Yong, Yipeng Li, Guiguang Ding, Rongrong Ji, Yue Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Hyper-YOLO, a new object detection method that integrates
hypergraph computations to capture the complex high-order correlations among
visual features. Traditional YOLO models, while powerful, have limitations in
their neck designs that restrict the integration of cross-level features and
the exploitation of high-order feature interrelationships. To address these
challenges, we propose the Hypergraph Computation Empowered Semantic Collecting
and Scattering (HGC-SCS) framework, which transposes visual feature maps into a
semantic space and constructs a hypergraph for high-order message propagation.
This enables the model to acquire both semantic and structural information,
advancing beyond conventional feature-focused learning. Hyper-YOLO incorporates
the proposed Mixed Aggregation Network (MANet) in its backbone for enhanced
feature extraction and introduces the Hypergraph-Based Cross-Level and
Cross-Position Representation Network (HyperC2Net) in its neck. HyperC2Net
operates across five scales and breaks free from traditional grid structures,
allowing for sophisticated high-order interactions across levels and positions.
This synergy of components positions Hyper-YOLO as a state-of-the-art
architecture in various scale models, as evidenced by its superior performance
on the COCO dataset. Specifically, Hyper-YOLO-N significantly outperforms the
advanced YOLOv8-N and YOLOv9-T with 12\% $\text{AP}^{val}$ and 9\%
$\text{AP}^{val}$ improvements. The source codes are at
ttps://github.com/iMoonLab/Hyper-YOLO.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Depth Estimation From Monocular Images With Enhanced Encoder-Decoder
  Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11610v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11610v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dabbrata Das, Argho Deb Das, Farhan Sadaf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating depth from a single 2D image is a challenging task because of the
need for stereo or multi-view data, which normally provides depth information.
This paper deals with this challenge by introducing a novel deep learning-based
approach using an encoder-decoder architecture, where the Inception-ResNet-v2
model is utilized as the encoder. According to the available literature, this
is the first instance of using Inception-ResNet-v2 as an encoder for monocular
depth estimation, illustrating better performance than previous models. The use
of Inception-ResNet-v2 enables our model to capture complex objects and
fine-grained details effectively that are generally difficult to predict.
Besides, our model incorporates multi-scale feature extraction to enhance depth
prediction accuracy across different kinds of object sizes and distances. We
propose a composite loss function consisting of depth loss, gradient edge loss,
and SSIM loss, where the weights are fine-tuned to optimize the weighted sum,
ensuring better balance across different aspects of depth estimation.
Experimental results on the NYU Depth V2 dataset show that our model achieves
state-of-the-art performance, with an ARE of 0.064, RMSE of 0.228, and accuracy
($\delta$ $<1.25$) of 89.3%. These metrics demonstrate that our model
effectively predicts depth, even in challenging circumstances, providing a
scalable solution for real-world applications in robotics, 3D reconstruction,
and augmented reality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Models: What Do They Know? Do They Know Things? Let's Find
  Out! 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17137v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17137v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodan Du, Nicholas Kolkin, Greg Shakhnarovich, Anand Bhattad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models excel at mimicking real scenes, suggesting they might
inherently encode important intrinsic scene properties. In this paper, we aim
to explore the following key questions: (1) What intrinsic knowledge do
generative models like GANs, Autoregressive models, and Diffusion models
encode? (2) Can we establish a general framework to recover intrinsic
representations from these models, regardless of their architecture or model
type? (3) How minimal can the required learnable parameters and labeled data be
to successfully recover this knowledge? (4) Is there a direct link between the
quality of a generative model and the accuracy of the recovered scene
intrinsics?
  Our findings indicate that a small Low-Rank Adaptators (LoRA) can recover
intrinsic images-depth, normals, albedo and shading-across different generators
(Autoregressive, GANs and Diffusion) while using the same decoder head that
generates the image. As LoRA is lightweight, we introduce very few learnable
parameters (as few as 0.04% of Stable Diffusion model weights for a rank of 2),
and we find that as few as 250 labeled images are enough to generate intrinsic
images with these LoRA modules. Finally, we also show a positive correlation
between the generative model's quality and the accuracy of the recovered
intrinsics through control experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://intrinsic-lora.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mini-Splatting: Representing Scenes with a Constrained Number of
  Gaussians 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14166v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14166v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangchi Fang, Bing Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we explore the challenge of efficiently representing scenes
with a constrained number of Gaussians. Our analysis shifts from traditional
graphics and 2D computer vision to the perspective of point clouds,
highlighting the inefficient spatial distribution of Gaussian representation as
a key limitation in model performance. To address this, we introduce strategies
for densification including blur split and depth reinitialization, and
simplification through intersection preserving and sampling. These techniques
reorganize the spatial positions of the Gaussians, resulting in significant
improvements across various datasets and benchmarks in terms of rendering
quality, resource consumption, and storage compression. Our Mini-Splatting
integrates seamlessly with the original rasterization pipeline, providing a
strong baseline for future research in Gaussian-Splatting-based works.
\href{https://github.com/fatPeter/mini-splatting}{Code is available}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ See Where You Read with Eye Gaze Tracking and Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19454v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19454v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sikai Yang, Gang Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Losing track of reading progress during line switching can be frustrating.
Eye gaze tracking technology offers a potential solution by highlighting read
paragraphs, aiding users in avoiding wrong line switches. However, the gap
between gaze tracking accuracy (2-3 cm) and text line spacing (3-5 mm) makes
direct application impractical. Existing methods leverage the linear reading
pattern but fail during jump reading. This paper presents a reading tracking
and highlighting system that supports both linear and jump reading. Based on
experimental insights from the gaze nature study of 16 users, two gaze error
models are designed to enable both jump reading detection and relocation. The
system further leverages the large language model's contextual perception
capability in aiding reading tracking. A reading tracking domain-specific
line-gaze alignment opportunity is also exploited to enable dynamic and
frequent calibration of the gaze results. Controlled experiments demonstrate
reliable linear reading tracking, as well as 84% accuracy in tracking jump
reading. Furthermore, real field tests with 18 volunteers demonstrated the
system's effectiveness in tracking and highlighting read paragraphs, improving
reading efficiency, and enhancing user experience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic
  Manipulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11548v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11548v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuyan Xiong, Chengyu Shen, Xiaoqi Li, Kaichen Zhou, Jiaming Liu, Ruiping Wang, Hao Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to reflect on and correct failures is crucial for robotic systems
to interact stably with real-life objects. Observing the generalization and
reasoning capabilities of Multimodal Large Language Models (MLLMs), previous
approaches have aimed to utilize these models to enhance robotic systems
accordingly. However, these methods typically focus on high-level planning
corrections using an additional MLLM, with limited utilization of failed
samples to correct low-level contact poses which is particularly prone to occur
during articulated object manipulation. To address this gap, we propose an
Autonomous Interactive Correction (AIC) MLLM, which makes use of previous
low-level interaction experiences to correct SE(3) pose predictions for
articulated object. Specifically, AIC MLLM is initially fine-tuned to acquire
both pose prediction and feedback prompt comprehension abilities. We design two
types of prompt instructions for interactions with objects: 1) visual masks to
highlight unmovable parts for position correction, and 2) textual descriptions
to indicate potential directions for rotation correction. During inference, a
Feedback Information Extraction module is introduced to recognize the failure
cause, allowing AIC MLLM to adaptively correct the pose prediction using the
corresponding prompts. To further enhance manipulation stability, we devise a
Test Time Adaptation strategy that enables AIC MLLM to better adapt to the
current scene configuration. Finally, extensive experiments are conducted in
both simulated and real-world environments to evaluate the proposed method. The
results demonstrate that our AIC MLLM can efficiently correct failure samples
by leveraging interaction experience prompts. Our project website is
https://sites.google.com/view/aic-mllm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Key-Grid: Unsupervised 3D Keypoints Detection using Grid Heatmap
  Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02237v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02237v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengkai Hou, Zhengrong Xue, Bingyang Zhou, Jinghan Ke, Lin Shao, Huazhe Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting 3D keypoints with semantic consistency is widely used in many
scenarios such as pose estimation, shape registration and robotics. Currently,
most unsupervised 3D keypoint detection methods focus on the rigid-body
objects. However, when faced with deformable objects, the keypoints they
identify do not preserve semantic consistency well. In this paper, we introduce
an innovative unsupervised keypoint detector Key-Grid for both the rigid-body
and deformable objects, which is an autoencoder framework. The encoder predicts
keypoints and the decoder utilizes the generated keypoints to reconstruct the
objects. Unlike previous work, we leverage the identified keypoint in formation
to form a 3D grid feature heatmap called grid heatmap, which is used in the
decoder section. Grid heatmap is a novel concept that represents the latent
variables for grid points sampled uniformly in the 3D cubic space, where these
variables are the shortest distance between the grid points and the skeleton
connected by keypoint pairs. Meanwhile, we incorporate the information from
each layer of the encoder into the decoder section. We conduct an extensive
evaluation of Key-Grid on a list of benchmark datasets. Key-Grid achieves the
state-of-the-art performance on the semantic consistency and position accuracy
of keypoints. Moreover, we demonstrate the robustness of Key-Grid to noise and
downsampling. In addition, we achieve SE-(3) invariance of keypoints though
generalizing Key-Grid to a SE(3)-invariant backbone.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MERLIN: Multimodal Embedding Refinement via LLM-based Iterative
  Navigation for Text-Video Retrieval-Rerank Pipeline <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12508v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12508v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid expansion of multimedia content has made accurately retrieving
relevant videos from large collections increasingly challenging. Recent
advancements in text-video retrieval have focused on cross-modal interactions,
large-scale foundation model training, and probabilistic modeling, yet often
neglect the crucial user perspective, leading to discrepancies between user
queries and the content retrieved. To address this, we introduce MERLIN
(Multimodal Embedding Refinement via LLM-based Iterative Navigation), a novel,
training-free pipeline that leverages Large Language Models (LLMs) for
iterative feedback learning. MERLIN refines query embeddings from a user
perspective, enhancing alignment between queries and video content through a
dynamic question answering process. Experimental results on datasets like
MSR-VTT, MSVD, and ActivityNet demonstrate that MERLIN substantially improves
Recall@1, outperforming existing systems and confirming the benefits of
integrating LLMs into multimodal retrieval systems for more responsive and
context-aware multimedia retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Industry Track Accepted (Camera-Ready Version)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tri-Cam: Practical Eye Gaze Tracking via Camera Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19554v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19554v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sikai Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As human eyes serve as conduits of rich information, unveiling emotions,
intentions, and even aspects of an individual's health and overall well-being,
gaze tracking also enables various human-computer interaction applications, as
well as insights in psychological and medical research. However, existing gaze
tracking solutions fall short at handling free user movement, and also require
laborious user effort in system calibration. We introduce Tri-Cam, a practical
deep learning-based gaze tracking system using three affordable RGB webcams. It
features a split network structure for efficient training, as well as
designated network designs to handle the separated gaze tracking tasks. Tri-Cam
is also equipped with an implicit calibration module, which makes use of mouse
click opportunities to reduce calibration overhead on the user's end. We
evaluate Tri-Cam against Tobii, the state-of-the-art commercial eye tracker,
achieving comparable accuracy, while supporting a wider free movement area. In
conclusion, Tri-Cam provides a user-friendly, affordable, and robust gaze
tracking solution that could practically enable various applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ViLReF: An Expert Knowledge Enabled Vision-Language Retinal Foundation
  Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10894v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10894v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengzhu Yang, Jiawei Du, Jia Guo, Weihang Zhang, Hanruo Liu, Huiqi Li, Ningli Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Subtle semantic differences in retinal image and text data present great
challenges for pre-training visual-language models. Moreover, false negative
samples, i.e., image-text pairs having the same semantics but incorrectly
regarded as negatives, disrupt the visual-language pre-training process and
affect the model's learning ability. This work aims to develop a retinal
foundation model, called ViLReF, by pre-training on a paired dataset comprising
451,956 retinal images and corresponding diagnostic text reports. In our
vision-language pre-training strategy, we leverage expert knowledge to
facilitate the extraction of labels and propose a novel constraint, the
Weighted Similarity Coupling Loss, to adjust the speed of pushing sample pairs
further apart dynamically within the feature space. Furthermore, we employ a
batch expansion module with dynamic memory queues, maintained by momentum
encoders, to supply extra samples and compensate for the vacancies caused by
eliminating false negatives. Extensive experiments are conducted on multiple
datasets for downstream classification and segmentation tasks. The experimental
results demonstrate the powerful zero-shot and transfer learning capabilities
of ViLReF, verifying the effectiveness of our pre-training strategy. Our ViLReF
model is available at: https://github.com/T6Yang/ViLReF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Up Personalized Image Aesthetic Assessment via Task Vector
  Customization <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07176v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07176v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jooyeol Yun, Jaegul Choo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of personalized image aesthetic assessment seeks to tailor aesthetic
score prediction models to match individual preferences with just a few
user-provided inputs. However, the scalability and generalization capabilities
of current approaches are considerably restricted by their reliance on an
expensive curated database. To overcome this long-standing scalability
challenge, we present a unique approach that leverages readily available
databases for general image aesthetic assessment and image quality assessment.
Specifically, we view each database as a distinct image score regression task
that exhibits varying degrees of personalization potential. By determining
optimal combinations of task vectors, known to represent specific traits of
each database, we successfully create personalized models for individuals. This
approach of integrating multiple models allows us to harness a substantial
amount of data. Our extensive experiments demonstrate the effectiveness of our
approach in generalizing to previously unseen domains-a challenge previous
approaches have struggled to achieve-making it highly applicable to real-world
scenarios. Our novel approach significantly advances the field by offering
scalable solutions for personalized aesthetic assessment and establishing high
standards for future research.
https://yeolj00.github.io/personal-projects/personalized-aesthetics/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnimateLCM: Computation-Efficient Personalized Style Video Generation
  without Personalized Video Data <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00769v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00769v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fu-Yun Wang, Zhaoyang Huang, Weikang Bian, Xiaoyu Shi, Keqiang Sun, Guanglu Song, Yu Liu, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces an effective method for computation-efficient
personalized style video generation without requiring access to any
personalized video data. It reduces the necessary generation time of similarly
sized video diffusion models from 25 seconds to around 1 second while
maintaining the same level of performance. The method's effectiveness lies in
its dual-level decoupling learning approach: 1) separating the learning of
video style from video generation acceleration, which allows for personalized
style video generation without any personalized style video data, and 2)
separating the acceleration of image generation from the acceleration of video
motion generation, enhancing training efficiency and mitigating the negative
effects of low-quality video data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a Short Paper by SIGGRAPH ASIA 2024 Technical
  Communications. This is a short version of the original work. Project Page:
  https://animatelcm.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Vision-Based Adaptive Robotics for Autonomous Surface Crack Repair 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.16874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.16874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Genova, Eric Cabrera, Vedhus Hoskere
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surface cracks in infrastructure can lead to significant deterioration and
costly maintenance if not efficiently repaired. Manual repair methods are
labor-intensive, time-consuming, and imprecise and thus difficult to scale to
large areas. While advancements in robotic perception and manipulation have
progressed autonomous crack repair, existing methods still face three key
challenges: accurate localization of cracks within the robot's coordinate
frame, (ii) adaptability to varying crack depths and widths, and (iii)
validation of the repair process under realistic conditions. This paper
presents an adaptive, autonomous system for surface crack detection and repair
using robotics with advanced sensing technologies to enhance precision and
safety for humans. The system uses an RGB-D camera for crack detection, a laser
scanner for precise measurement, and an extruder and pump for material
deposition. To address one of the key challenges, the laser scanner is used to
enhance the crack coordinates for accurate localization. Furthermore, our
approach demonstrates that an adaptive crack-filling method is more efficient
and effective than a fixed-speed approach, with experimental results confirming
both precision and consistency. In addition, to ensure real-world applicability
and testing repeatability, we introduce a novel validation procedure using
3D-printed crack specimens that accurately simulate real-world conditions. This
research contributes to the evolving field of human-robot interaction in
construction by demonstrating how adaptive robotic systems can reduce the need
for manual labor, improve safety, and enhance the efficiency of maintenance
operations, ultimately paving the way for more sophisticated and integrated
construction robotics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 14 figures, submitted to Advanced Engineering Informatics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sample what you cant compress 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02529v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02529v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vighnesh Birodkar, Gabriel Barcik, James Lyon, Sergey Ioffe, David Minnen, Joshua V. Dillon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For learned image representations, basic autoencoders often produce blurry
results. Reconstruction quality can be improved by incorporating additional
penalties such as adversarial (GAN) and perceptual losses. Arguably, these
approaches lack a principled interpretation. Concurrently, in generative
settings diffusion has demonstrated a remarkable ability to create crisp, high
quality results and has solid theoretical underpinnings (from variational
inference to direct study as the Fisher Divergence). Our work combines
autoencoder representation learning with diffusion and is, to our knowledge,
the first to demonstrate the efficacy of jointly learning a continuous encoder
and decoder under a diffusion-based loss. We demonstrate that this approach
yields better reconstruction quality as compared to GAN-based autoencoders
while being easier to tune. We also show that the resulting representation is
easier to model with a latent diffusion model as compared to the representation
obtained from a state-of-the-art GAN-based loss. Since our decoder is
stochastic, it can generate details not encoded in the otherwise deterministic
latent representation; we therefore name our approach "Sample what you can't
compress", or SWYCC for short.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MuseTalk: Real-Time High Quality Lip Synchronization with Latent Space
  Inpainting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10122v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10122v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yue Zhang, Minhao Liu, Zhaokang Chen, Bin Wu, Yubin Zeng, Chao Zhan, Yingjie He, Junxin Huang, Wenjiang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving high-resolution, identity consistency, and accurate lip-speech
synchronization in face visual dubbing presents significant challenges,
particularly for real-time applications like live video streaming. We propose
MuseTalk, which generates lip-sync targets in a latent space encoded by a
Variational Autoencoder, enabling high-fidelity talking face video generation
with efficient inference. Specifically, we project the occluded lower half of
the face image and itself as an reference into a low-dimensional latent space
and use a multi-scale U-Net to fuse audio and visual features at various
levels. We further propose a novel sampling strategy during training, which
selects reference images with head poses closely matching the target, allowing
the model to focus on precise lip movement by filtering out redundant
information. Additionally, we analyze the mechanism of lip-sync loss and reveal
its relationship with input information volume. Extensive experiments show that
MuseTalk consistently outperforms recent state-of-the-art methods in visual
fidelity and achieves comparable lip-sync accuracy. As MuseTalk supports the
online generation of face at 256x256 at more than 30 FPS with negligible
starting latency, it paves the way for real-time applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Delta-ICM: Entropy Modeling with Delta Function for Learned Image
  Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07669v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07669v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takahiro Shindo, Taiju Watanabe, Yui Tatsumi, Hiroshi Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image Coding for Machines (ICM) is becoming more important as research in
computer vision progresses. ICM is a vital research field that pursues the use
of images for image recognition models, facilitating efficient image
transmission and storage. The demand for recognition models is growing rapidly
among the general public, and their performance continues to improve. To meet
these needs, exchanging image data between consumer devices and cloud AI using
ICM technology could be one possible solution. In ICM, various image
compression methods have adopted Learned Image Compression (LIC). LIC includes
an entropy model for estimating the bitrate of latent features, and the design
of this model significantly affects its performance. Typically, LIC methods
assume that the distribution of latent features follows a normal distribution.
This assumption is effective for compressing images intended for human vision.
However, employing an entropy model based on normal distribution is inefficient
in ICM due to the limitation of image parts that require precise decoding. To
address this, we propose Delta-ICM, which uses a probability distribution based
on a delta function. Assuming the delta distribution as a distribution of
latent features reduces the entropy of image portions unnecessary for machines.
We compress the remaining portions using an entropy model based on normal
distribution, similar to existing methods. Delta-ICM selects between the
entropy model based on the delta distribution and the one based on the normal
distribution for each latent feature. Our method outperforms existing ICM
methods in image compression performance aimed at machines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video-to-Audio Generation with Hidden Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07464v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07464v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manjie Xu, Chenxing Li, Xinyi Tu, Yong Ren, Rilin Chen, Yu Gu, Wei Liang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating semantically and temporally aligned audio content in accordance
with video input has become a focal point for researchers, particularly
following the remarkable breakthrough in text-to-video generation. In this
work, we aim to offer insights into the video-to-audio generation paradigm,
focusing on three crucial aspects: vision encoders, auxiliary embeddings, and
data augmentation techniques. Beginning with a foundational model built on a
simple yet surprisingly effective intuition, we explore various vision encoders
and auxiliary embeddings through ablation studies. Employing a comprehensive
evaluation pipeline that emphasizes generation quality and video-audio
synchronization alignment, we demonstrate that our model exhibits
state-of-the-art video-to-audio generation capabilities. Furthermore, we
provide critical insights into the impact of different data augmentation
methods on enhancing the generation framework's overall capacity. We showcase
possibilities to advance the challenge of generating synchronized audio from
semantic and temporal perspectives. We hope these insights will serve as a
stepping stone toward developing more realistic and accurate audio-visual
generation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://sites.google.com/view/vta-ldm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge Circuits in <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>s <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024, 32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranav Gupta, Rishabh Rengarajan, Viren Bankapur, Vedansh Mannem, Lakshit Ahuja, Surya Vijay, Kevin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Combining LiDAR and Camera-view data has become a common approach for 3D
Object Detection. However, previous approaches combine the two input streams at
a point-level, throwing away semantic information derived from camera features.
In this paper we propose Cross-View Center Point-Fusion, a state-of-the-art
model to perform 3D object detection by combining camera and LiDAR-derived
features in the BEV space to preserve semantic density from the camera stream
while incorporating spacial data from the LiDAR stream. Our architecture
utilizes aspects from previously established algorithms, Cross-View
Transformers and CenterPoint, and runs their backbones in parallel, allowing
efficient computation for real-time processing and application. In this paper
we find that while an implicitly calculated depth-estimate may be sufficiently
accurate in a 2D map-view representation, explicitly calculated geometric and
spacial information is needed for precise bounding box prediction in the 3D
world-view space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:2205.02833 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReLayout: Towards Real-World Document Understanding via Layout-enhanced
  <span class="highlight-title">Pre-train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10471v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10471v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhouqiang Jiang, Bowen Wang, Junhao Chen, Yuta Nakashima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent approaches for visually-rich document understanding (VrDU) uses
manually annotated semantic groups, where a semantic group encompasses all
semantically relevant but not obviously grouped words. As OCR tools are unable
to automatically identify such grouping, we argue that current VrDU approaches
are unrealistic. We thus introduce a new variant of the VrDU task, real-world
visually-rich document understanding (ReVrDU), that does not allow for using
manually annotated semantic groups. We also propose a new method, ReLayout,
compliant with the ReVrDU scenario, which learns to capture semantic grouping
through arranging words and bringing the representations of words that belong
to the potential same semantic group closer together. Our experimental results
demonstrate the performance of existing methods is deteriorated with the ReVrDU
task, while ReLayout shows superiour performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ultra-High-Definition Image Restoration: New Benchmarks and A Dual
  Interaction Prior-Driven Solution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13607v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13607v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyan Wang, Cong Wang, Jinshan Pan, Xiaofeng Liu, Weixiang Zhou, Xiaoran Sun, Wei Wang, Zhixun Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ultra-High-Definition (UHD) image restoration has acquired remarkable
attention due to its practical demand. In this paper, we construct UHD snow and
rain benchmarks, named UHD-Snow and UHD-Rain, to remedy the deficiency in this
field. The UHD-Snow/UHD-Rain is established by simulating the physics process
of rain/snow into consideration and each benchmark contains 3200 degraded/clear
image pairs of 4K resolution. Furthermore, we propose an effective UHD image
restoration solution by considering gradient and normal priors in model design
thanks to these priors' spatial and detail contributions. Specifically, our
method contains two branches: (a) feature fusion and reconstruction branch in
high-resolution space and (b) prior feature interaction branch in
low-resolution space. The former learns high-resolution features and fuses
prior-guided low-resolution features to reconstruct clear images, while the
latter utilizes normal and gradient priors to mine useful spatial features and
detail features to guide high-resolution recovery better. To better utilize
these priors, we introduce single prior feature interaction and dual prior
feature interaction, where the former respectively fuses normal and gradient
priors with high-resolution features to enhance prior ones, while the latter
calculates the similarity between enhanced prior ones and further exploits dual
guided filtering to boost the feature interaction of dual priors. We conduct
experiments on both new and existing public datasets and demonstrate the
state-of-the-art performance of our method on UHD image low-light enhancement,
dehazing, deblurring, desonwing, and deraining. The source codes and benchmarks
are available at \url{https://github.com/wlydlut/UHDDIP}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AdaMSS: Adaptive Multi-Modality Segmentation-to-Survival Learning for
  Survival Outcome Prediction from PET/CT Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.09946v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.09946v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingyuan Meng, Bingxin Gu, Michael Fulham, Shaoli Song, Dagan Feng, Lei Bi, Jinman Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Survival prediction is a major concern for cancer management. Deep survival
models based on deep learning have been widely adopted to perform end-to-end
survival prediction from medical images. Recent deep survival models achieved
promising performance by jointly performing tumor segmentation with survival
prediction, where the models were guided to extract tumor-related information
through Multi-Task Learning (MTL). However, these deep survival models have
difficulties in exploring out-of-tumor prognostic information. In addition,
existing deep survival models are unable to effectively leverage multi-modality
images. Empirically-designed fusion strategies were commonly adopted to fuse
multi-modality information via task-specific manually-designed networks, thus
limiting the adaptability to different scenarios. In this study, we propose an
Adaptive Multi-modality Segmentation-to-Survival model (AdaMSS) for survival
prediction from PET/CT images. Instead of adopting MTL, we propose a novel
Segmentation-to-Survival Learning (SSL) strategy, where our AdaMSS is trained
for tumor segmentation and survival prediction sequentially in two stages. This
strategy enables the AdaMSS to focus on tumor regions in the first stage and
gradually expand its focus to include other prognosis-related regions in the
second stage. We also propose a data-driven strategy to fuse multi-modality
information, which realizes adaptive optimization of fusion strategies based on
training data during training. With the SSL and data-driven fusion strategies,
our AdaMSS is designed as an adaptive model that can self-adapt its focus
regions and fusion strategy for different training stages. Extensive
experiments with two large clinical datasets show that our AdaMSS outperforms
state-of-the-art survival prediction methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The extended version of this paper has been published at npj
  Precision Oncology as "Adaptive segmentation-to-survival learning for
  survival prediction from multi-modality medical images"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-shot Generalizable Incremental Learning for Vision-Language Object
  Detection <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.01680v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.01680v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jieren Deng, Haojian Zhang, Kun Ding, Jianhua Hu, Xingxuan Zhang, Yunkuan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents Incremental Vision-Language Object Detection (IVLOD), a
novel learning task designed to incrementally adapt pre-trained Vision-Language
Object Detection Models (VLODMs) to various specialized domains, while
simultaneously preserving their zero-shot generalization capabilities for the
generalized domain. To address this new challenge, we present the
Zero-interference Reparameterizable Adaptation (ZiRa), a novel method that
introduces Zero-interference Loss and reparameterization techniques to tackle
IVLOD without incurring additional inference costs or a significant increase in
memory usage. Comprehensive experiments on COCO and ODinW-13 datasets
demonstrate that ZiRa effectively safeguards the zero-shot generalization
ability of VLODMs while continuously adapting to new tasks. Specifically, after
training on ODinW-13 datasets, ZiRa exhibits superior performance compared to
CL-DETR and iDETR, boosting zero-shot generalizability by substantial 13.91 and
8.74 AP, respectively.Our code is available at
https://github.com/JarintotionDin/ZiRaGroundingDINO.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ In the Eye of <span class="highlight-title">Transformer</span>: Global-Local Correlation for Egocentric Gaze
  Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2208.04464v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2208.04464v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bolin Lai, Miao Liu, Fiona Ryan, James M. Rehg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present the first transformer-based model to address the
challenging problem of egocentric gaze estimation. We observe that the
connection between the global scene context and local visual information is
vital for localizing the gaze fixation from egocentric video frames. To this
end, we design the transformer encoder to embed the global context as one
additional visual token and further propose a novel Global-Local Correlation
(GLC) module to explicitly model the correlation of the global token and each
local token. We validate our model on two egocentric video datasets - EGTEA
Gaze+ and Ego4D. Our detailed ablation studies demonstrate the benefits of our
method. In addition, our approach exceeds previous state-of-the-arts by a large
margin. We also provide additional visualizations to support our claim that
global-local correlation serves a key representation for predicting gaze
fixation from egocentric videos. More details can be found in our website
(https://bolinlai.github.io/GLC-EgoGazeEst).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lotus: Diffusion-based Visual Foundation Model for High-quality Dense
  Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18124v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18124v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing He, Haodong Li, Wei Yin, Yixun Liang, Leheng Li, Kaiqiang Zhou, Hongbo Zhang, Bingbing Liu, Ying-Cong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging the visual priors of pre-trained text-to-image diffusion models
offers a promising solution to enhance zero-shot generalization in dense
prediction tasks. However, existing methods often uncritically use the original
diffusion formulation, which may not be optimal due to the fundamental
differences between dense prediction and image generation. In this paper, we
provide a systemic analysis of the diffusion formulation for the dense
prediction, focusing on both quality and efficiency. And we find that the
original parameterization type for image generation, which learns to predict
noise, is harmful for dense prediction; the multi-step noising/denoising
diffusion process is also unnecessary and challenging to optimize. Based on
these insights, we introduce Lotus, a diffusion-based visual foundation model
with a simple yet effective adaptation protocol for dense prediction.
Specifically, Lotus is trained to directly predict annotations instead of
noise, thereby avoiding harmful variance. We also reformulate the diffusion
process into a single-step procedure, simplifying optimization and
significantly boosting inference speed. Additionally, we introduce a novel
tuning strategy called detail preserver, which achieves more accurate and
fine-grained predictions. Without scaling up the training data or model
capacity, Lotus achieves SoTA performance in zero-shot depth and normal
estimation across various datasets. It also enhances efficiency, being
significantly faster than most existing diffusion-based methods. Lotus'
superior quality and efficiency also enable a wide range of practical
applications, such as joint estimation, single/multi-view 3D reconstruction,
etc. Project page: https://lotus3d.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally. Project page:
  https://lotus3d.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly
  Mixed Classifiers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02263v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02263v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yatong Bai, Mo Zhou, Vishal M. Patel, Somayeh Sojoudi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial robustness often comes at the cost of degraded accuracy, impeding
real-life applications of robust classification models. Training-based
solutions for better trade-offs are limited by incompatibilities with
already-trained high-performance large models, necessitating the exploration of
training-free ensemble approaches. Observing that robust models are more
confident in correct predictions than in incorrect ones on clean and
adversarial data alike, we speculate amplifying this "benign confidence
property" can reconcile accuracy and robustness in an ensemble setting. To
achieve so, we propose "MixedNUTS", a training-free method where the output
logits of a robust classifier and a standard non-robust classifier are
processed by nonlinear transformations with only three parameters, which are
optimized through an efficient algorithm. MixedNUTS then converts the
transformed logits into probabilities and mixes them as the overall output. On
CIFAR-10, CIFAR-100, and ImageNet datasets, experimental results with custom
strong adaptive attacks demonstrate MixedNUTS's vastly improved accuracy and
near-SOTA robustness -- it boosts CIFAR-100 clean accuracy by 7.86 points,
sacrificing merely 0.87 points in robust accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RosePO: Aligning LLM-based Recommenders with Human Values 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12519v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12519v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Liao, Xiangnan He, Ruobing Xie, Jiancan Wu, Yancheng Yuan, Xingwu Sun, Zhanhui Kang, Xiang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, there has been a growing interest in leveraging Large Language
Models (LLMs) for recommendation systems, which usually adapt a pre-trained LLM
to the recommendation scenario through supervised fine-tuning (SFT). However,
both the pre-training and SFT stages fail to explicitly model the comparative
relationships of a user's preferences on different items. To construct a
"helpful and harmless" LLM-based recommender, we propose a general framework --
Recommendation with smoothing personalized Preference Optimization (RosePO),
which better aligns with customized human values during the post-training
stage. Specifically, in addition to the input and chosen response that
naturally align with SFT data, we design a rejected sampling strategy tailored
for enhancing helpfulness, along with two strategies aimed at mitigating biases
to promote harmlessness. To ensure robustness against uncertain labels present
in automatically constructed preference data, we introduce a personalized
smoothing factor predicted by a preference oracle into the optimization
objective. Evaluation on three real-world datasets demonstrates the
effectiveness of our method, showcasing not only improved recommendation
performance but also mitigation of semantic hallucination and popularity bias.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unifying Economic and Language Models for Enhanced Sentiment Analysis of
  the Oil Market 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12473v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12473v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Himmet Kaplan, Ralf-Peter Mundani, Heiko Rölke, Albert Weichselbraun, Martin Tschudy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Crude oil, a critical component of the global economy, has its prices
influenced by various factors such as economic trends, political events, and
natural disasters. Traditional prediction methods based on historical data have
their limits in forecasting, but recent advancements in natural language
processing bring new possibilities for event-based analysis. In particular,
Language Models (LM) and their advancement, the Generative Pre-trained
Transformer (GPT), have shown potential in classifying vast amounts of natural
language. However, these LMs often have difficulty with domain-specific
terminology, limiting their effectiveness in the crude oil sector. Addressing
this gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude
oil market. The results indicate that CrudeBERT's sentiment scores align more
closely with the WTI Futures curve and significantly enhance price predictions,
underscoring the crucial role of integrating economic principles into LMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Dual Latent Confounding Biases in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12451v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12451v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianfeng Deng, Qingfeng Chen, Debo Cheng, Jiuyong Li, Lin Liu, Xiaojing Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems are extensively utilised across various areas to predict
user preferences for personalised experiences and enhanced user engagement and
satisfaction. Traditional recommender systems, however, are complicated by
confounding bias, particularly in the presence of latent confounders that
affect both item exposure and user feedback. Existing debiasing methods often
fail to capture the complex interactions caused by latent confounders in
interaction data, especially when dual latent confounders affect both the user
and item sides. To address this, we propose a novel debiasing method that
jointly integrates the Instrumental Variables (IV) approach and identifiable
Variational Auto-Encoder (iVAE) for Debiased representation learning in
Recommendation systems, referred to as IViDR. Specifically, IViDR leverages the
embeddings of user features as IVs to address confounding bias caused by latent
confounders between items and user feedback, and reconstructs the embedding of
items to obtain debiased interaction data. Moreover, IViDR employs an
Identifiable Variational Auto-Encoder (iVAE) to infer identifiable
representations of latent confounders between item exposure and user feedback
from both the original and debiased interaction data. Additionally, we provide
theoretical analyses of the soundness of using IV and the identifiability of
the latent representations. Extensive experiments on both synthetic and
real-world datasets demonstrate that IViDR outperforms state-of-the-art models
in reducing bias and providing reliable recommendations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QUIDS: Query Intent Generation via Dual Space Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12400v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12400v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yumeng Wang, Xiuying Chen, Suzan Verberne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query understanding is a crucial component of Information Retrieval (IR),
aimed at identifying the underlying search intent of textual queries. However,
most existing approaches oversimplify this task into query classification or
clustering, which fails to fully capture the nuanced intent behind the query.
In this paper, we address the task of query intent generation: to automatically
generate detailed and precise intent descriptions for search queries using
relevant and irrelevant documents given a query. These intent descriptions can
help users understand why the search engine considered the top-ranked documents
relevant, and provide more transparency to the retrieval process. We propose a
dual-space model that uses semantic relevance and irrelevance information in
the returned documents to explain the understanding of the query intent.
Specifically, in the encoding process, we project, separate, and distinguish
relevant and irrelevant documents in the representation space. Then, we
introduce a semantic decoupling model in the novel disentangling space, where
the semantics of irrelevant information are removed from the relevant space,
ensuring that only the essential and relevant intent is captured. This process
refines the understanding of the query and provides more accurate explanations
for the search results. Experiments on benchmark data demonstrate that our
methods produce high-quality query intent descriptions, outperforming existing
methods for this task, as well as state-of-the-art query-based summarization
methods. A token-level visualization of attention scores reveals that our model
effectively reduces the focus on irrelevant intent topics. Our findings open up
promising research and application directions for query intent generation,
particularly in exploratory search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Cause Deconfounding for Recommender Systems with Latent
  Confounders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12366v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12366v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhirong Huang, Shichao Zhang, Debo Cheng, Jiuyong Li, Lin Liu, Guixian Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommender systems, various latent confounding factors (e.g., user social
environment and item public attractiveness) can affect user behavior, item
exposure, and feedback in distinct ways. These factors may directly or
indirectly impact user feedback and are often shared across items or users,
making them multi-cause latent confounders. However, existing methods typically
fail to account for latent confounders between users and their feedback, as
well as those between items and user feedback simultaneously. To address the
problem of multi-cause latent confounders, we propose a multi-cause
deconfounding method for recommender systems with latent confounders (MCDCF).
MCDCF leverages multi-cause causal effect estimation to learn substitutes for
latent confounders associated with both users and items, using user behaviour
data. Specifically, MCDCF treats the multiple items that users interact with
and the multiple users that interact with items as treatment variables,
enabling it to learn substitutes for the latent confounders that influence the
estimation of causality between users and their feedback, as well as between
items and user feedback. Additionally, we theoretically demonstrate the
soundness of our MCDCF method. Extensive experiments on three real-world
datasets demonstrate that our MCDCF method effectively recovers latent
confounders related to users and items, reducing bias and thereby improving
recommendation accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comprehending Knowledge Graphs with Large Language Models for
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12229v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12229v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with
  Large Language Models for Multi-Behavior Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12228v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12228v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>DSI: <span class="highlight-title">Prompt</span>-based Rehearsal-free Instance-wise Incremental
  Learning for Document Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan-Luc Huynh, Thuy-Trang Vu, Weiqing Wang, Yinwei Wei, Trung Le, Dragan Gasevic, Yuan-Fang Li, Thanh-Toan Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSI needs full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
prompt-based rehearsal-free approach for instance-wise incremental learning
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that BERT-based PromptDSI matches IncDSI
in managing forgetting while improving new corpora performance by more than 4%
Hits@10 on NQ320k and upto 3% MRR@10 on MS MARCO 300k.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DIRAS: Efficient LLM Annotation of Document Relevance in Retrieval
  Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingwei Ni, Tobias Schimanski, Meihong Lin, Mrinmaya Sachan, Elliott Ash, Markus Leippold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval Augmented Generation (RAG) is widely employed to ground responses
to queries on domain-specific documents. But do RAG implementations leave out
important information when answering queries that need an integrated analysis
of information (e.g., Tell me good news in the stock market today.)? To address
these concerns, RAG developers need to annotate information retrieval (IR) data
for their domain of interest, which is challenging because (1) domain-specific
queries usually need nuanced definitions of relevance beyond shallow semantic
relevance; and (2) human or GPT-4 annotation is costly and cannot cover all
(query, document) pairs (i.e., annotation selection bias), thus harming the
effectiveness in evaluating IR recall. To address these challenges, we propose
DIRAS (Domain-specific Information Retrieval Annotation with Scalability), a
manual-annotation-free schema that fine-tunes open-sourced LLMs to consider
nuanced relevance definition and annotate (partial) relevance labels with
calibrated relevance scores. Extensive evaluation shows that DIRAS enables
smaller (8B) LLMs to achieve GPT-4-level performance on annotating and ranking
unseen (query, document) pairs, and is helpful for real-world RAG development.
All code, LLM generations, and human annotations can be found in
\url{https://github.com/EdisonNi-hku/DIRAS}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL systems have become crucial for translating natural language into
SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, the Execution Accuracy
(EX), the most prevalent evaluation metric, still shows many false positives
and negatives. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our metric improves
agreement with human experts (from 62 to 87.04 in Cohen's kappa) with
comprehensive context and sophisticated criteria. Our extensive experiments
yield several key insights: (1) Models' performance increases by over 2.6
points on average, substantially affecting rankings on Spider and BIRD
benchmarks; (2) The underestimation of models in EX primarily stems from
annotation quality issues; and (3) Model performance on particularly
challenging questions tends to be overestimated. This work contributes to a
more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Practice-Friendly LLM-Enhanced Paradigm with Preference Parsing for
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00333v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00333v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dugang Liu, Shenxian Xian, Xiaolin Lin, Xiaolian Zhang, Hong Zhu, Yuan Fang, Zhen Chen, Zhong Ming
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training paradigm integrating large language models (LLM) is gradually
reshaping sequential recommender systems (SRS) and has shown promising results.
However, most existing LLM-enhanced methods rely on rich textual information on
the item side and instance-level supervised fine-tuning (SFT) to inject
collaborative information into LLM, which is inefficient and limited in many
applications. To alleviate these problems, this paper proposes a
practice-friendly LLM-enhanced paradigm with preference parsing (P2Rec) for
SRS. Specifically, in the information reconstruction stage, we design a new
user-level SFT task for collaborative information injection with the assistance
of a pre-trained SRS model, which is more efficient and compatible with limited
text information. Our goal is to let LLM learn to reconstruct a corresponding
prior preference distribution from each user's interaction sequence, where LLM
needs to effectively parse the latent category of each item and the
relationship between different items to accomplish this task. In the
information augmentation stage, we feed each item into LLM to obtain a set of
enhanced embeddings that combine collaborative information and LLM inference
capabilities. These embeddings can then be used to help train various future
SRS models. Finally, we verify the effectiveness and efficiency of our TSLRec
on three SRS benchmark datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge Circuits in <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>s <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024, 32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $\textit{lucie}$: An Improved Python Package for Loading <span class="highlight-title">Dataset</span>s from
  the UCI Machine Learning Repository 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenneth Ge, Phuc Nguyen, Ramy Arnaout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The University of California--Irvine (UCI) Machine Learning (ML) Repository
(UCIMLR) is consistently cited as one of the most popular dataset repositories,
hosting hundreds of high-impact datasets. However, a significant portion,
including 28.4% of the top 250, cannot be imported via the $\textit{ucimlrepo}$
package that is provided and recommended by the UCIMLR website. Instead, they
are hosted as .zip files, containing nonstandard formats that are difficult to
import without additional ad hoc processing. To address this issue, here we
present $\textit{lucie}$ -- $\underline{l}oad$ $\underline{U}niversity$
$\underline{C}alifornia$ $\underline{I}rvine$ $\underline{e}xamples$ -- a
utility that automatically determines the data format and imports many of these
previously non-importable datasets, while preserving as much of a tabular data
structure as possible. $\textit{lucie}$ was designed using the top 100 most
popular datasets and benchmarked on the next 130, where it resulted in a
success rate of 95.4% vs. 73.1% for $\textit{ucimlrepo}$. $\textit{lucie}$ is
available as a Python package on PyPI with 98% code coverage.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Inter-Item Relations: Dynamic Adaption for Enhancing LLM-Based
  Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07427v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07427v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        CanYi Liu, Wei Li,  Youchen,  Zhang, Hui Li, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems (SRS) predict the next items that users may
prefer based on user historical interaction sequences. Inspired by the rise of
large language models (LLMs) in various AI applications, there is a surge of
work on LLM-based SRS. Despite their attractive performance, existing LLM-based
SRS still exhibit some limitations, including neglecting intra-item relations,
ignoring long-term collaborative knowledge and using inflexible architecture
designs for adaption. To alleviate these issues, we propose an LLM-based
sequential recommendation model named DARec. Built on top of coarse-grained
adaption for capturing inter-item relations, DARec is further enhanced with (1)
context masking that models intra-item relations to help LLM better understand
token and item semantics in the context of SRS, (2) collaborative knowledge
injection that helps LLM incorporate long-term collaborative knowledge, and (3)
a dynamic adaption mechanism that uses Bayesian optimization to flexibly choose
layer-wise adapter architectures in order to better incorporate different
sequential information. Extensive experiments demonstrate that DARec can
effectively handle sequential recommendation in a dynamic and adaptive manner.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual Prototype Evolving for Test-Time Generalization of Vision-Language
  Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12790v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12790v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ce Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test-time adaptation, which enables models to generalize to diverse data with
unlabeled test samples, holds significant value in real-world scenarios.
Recently, researchers have applied this setting to advanced pre-trained
vision-language models (VLMs), developing approaches such as test-time prompt
tuning to further extend their practical applicability. However, these methods
typically focus solely on adapting VLMs from a single modality and fail to
accumulate task-specific knowledge as more samples are processed. To address
this, we introduce Dual Prototype Evolving (DPE), a novel test-time adaptation
approach for VLMs that effectively accumulates task-specific knowledge from
multi-modalities. Specifically, we create and evolve two sets of
prototypes--textual and visual--to progressively capture more accurate
multi-modal representations for target classes during test time. Moreover, to
promote consistent multi-modal representations, we introduce and optimize
learnable residuals for each test sample to align the prototypes from both
modalities. Extensive experimental results on 15 benchmark datasets demonstrate
that our proposed DPE consistently outperforms previous state-of-the-art
methods while also exhibiting competitive computational efficiency. Code is
available at https://github.com/zhangce01/DPE-CLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024. Project page:
  https://zhangce01.github.io/DPE-CLIP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Metal Price Spike Prediction via a Neurosymbolic Ensemble Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12785v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12785v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathaniel Lee, Noel Ngu, Harshdeep Singh Sahdev, Pramod Motaganahall, Al Mehdi Saadat Chowdhury, Bowen Xi, Paulo Shakarian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting price spikes in critical metals such as Cobalt, Copper, Magnesium,
and Nickel is crucial for mitigating economic risks associated with global
trends like the energy transition and reshoring of manufacturing. While
traditional models have focused on regression-based approaches, our work
introduces a neurosymbolic ensemble framework that integrates multiple neural
models with symbolic error detection and correction rules. This framework is
designed to enhance predictive accuracy by correcting individual model errors
and offering interpretability through rule-based explanations. We show that our
method provides up to 6.42% improvement in precision, 29.41% increase in recall
at 13.24% increase in F1 over the best performing neural models. Further, our
method, as it is based on logical rules, has the benefit of affording an
explanation as to which combination of neural models directly contribute to a
given prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ JudgeBench: A Benchmark for Evaluating LLM-based Judges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sijun Tan, Siyuan Zhuang, Kyle Montgomery, William Y. Tang, Alejandro Cuadron, Chenguang Wang, Raluca Ada Popa, Ion Stoica
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based judges have emerged as a scalable alternative to human evaluation
and are increasingly used to assess, compare, and improve models. However, the
reliability of LLM-based judges themselves is rarely scrutinized. As LLMs
become more advanced, their responses grow more sophisticated, requiring
stronger judges to evaluate them. Existing benchmarks primarily focus on a
judge's alignment with human preferences, but often fail to account for more
challenging tasks where crowdsourced human preference is a poor indicator of
factual and logical correctness. To address this, we propose a novel evaluation
framework to objectively evaluate LLM-based judges. Based on this framework, we
propose JudgeBench, a benchmark for evaluating LLM-based judges on challenging
response pairs spanning knowledge, reasoning, math, and coding. JudgeBench
leverages a novel pipeline for converting existing difficult datasets into
challenging response pairs with preference labels reflecting objective
correctness. Our comprehensive evaluation on a collection of prompted judges,
fine-tuned judges, multi-agent judges, and reward models shows that JudgeBench
poses a significantly greater challenge than previous benchmarks, with many
strong models (e.g., GPT-4o) performing just slightly better than random
guessing. Overall, JudgeBench offers a reliable platform for assessing
increasingly advanced LLM-based judges. Data and code are available at
https://github.com/ScalerLab/JudgeBench .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-Scaling versus Task-Scaling in In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12783v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12783v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhesam Abedsoltan, Adityanarayanan Radhakrishnan, Jingfeng Wu, Mikhail Belkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers exhibit In-Context Learning (ICL), where these models solve new
tasks by using examples in the prompt without additional training. In our work,
we identify and analyze two key components of ICL: (1) context-scaling, where
model performance improves as the number of in-context examples increases and
(2) task-scaling, where model performance improves as the number of
pre-training tasks increases. While transformers are capable of both
context-scaling and task-scaling, we empirically show that standard Multi-Layer
Perceptrons (MLPs) with vectorized input are only capable of task-scaling. To
understand how transformers are capable of context-scaling, we first propose a
significantly simplified transformer architecture without key, query, value
weights. We show that it performs ICL comparably to the original GPT-2 model in
various statistical learning tasks including linear regression, teacher-student
settings. Furthermore, a single block of our simplified transformer can be
viewed as data dependent feature map followed by an MLP. This feature map on
its own is a powerful predictor that is capable of context-scaling but is not
capable of task-scaling. We show empirically that concatenating the output of
this feature map with vectorized data as an input to MLPs enables both
context-scaling and task-scaling. This finding provides a simple setting to
study context and task-scaling for ICL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometry-Aware Generative Autoencoders for Warped Riemannian Metric
  Learning and Generative Modeling on Data Manifolds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingzhi Sun, Danqi Liao, Kincaid MacDonald, Yanlei Zhang, Chen Liu, Guillaume Huguet, Guy Wolf, Ian Adelstein, Tim G. J. Rudner, Smita Krishnaswamy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rapid growth of high-dimensional datasets in fields such as single-cell RNA
sequencing and spatial genomics has led to unprecedented opportunities for
scientific discovery, but it also presents unique computational and statistical
challenges. Traditional methods struggle with geometry-aware data generation,
interpolation along meaningful trajectories, and transporting populations via
feasible paths. To address these issues, we introduce Geometry-Aware Generative
Autoencoder (GAGA), a novel framework that combines extensible manifold
learning with generative modeling. GAGA constructs a neural network embedding
space that respects the intrinsic geometries discovered by manifold learning
and learns a novel warped Riemannian metric on the data space. This warped
metric is derived from both the points on the data manifold and negative
samples off the manifold, allowing it to characterize a meaningful geometry
across the entire latent space. Using this metric, GAGA can uniformly sample
points on the manifold, generate points along geodesics, and interpolate
between populations across the learned manifold. GAGA shows competitive
performance in simulated and real world datasets, including a 30% improvement
over the state-of-the-art methods in single-cell population-level trajectory
inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned
  Concepts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12777v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12777v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid progress of diffusion-based content generation, significant
efforts are being made to unlearn harmful or copyrighted concepts from
pretrained diffusion models (DMs) to prevent potential model misuse. However,
it is observed that even when DMs are properly unlearned before release,
malicious finetuning can compromise this process, causing DMs to relearn the
unlearned concepts. This occurs partly because certain benign concepts (e.g.,
"skin") retained in DMs are related to the unlearned ones (e.g., "nudity"),
facilitating their relearning via finetuning. To address this, we propose
meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an
unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes
malicious finetuning on unlearned concepts, the related benign concepts
retained within it will be triggered to self-destruct, hindering the relearning
of unlearned concepts. Our meta-unlearning framework is compatible with most
existing unlearning methods, requiring only the addition of an
easy-to-implement meta objective. We validate our approach through empirical
experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4
and SDXL), supported by extensive ablation studies. Our code is available at
https://github.com/sail-sg/Meta-Unlearning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Non-Local Model Merging Problem: Permutation Symmetries and Variance
  Collapse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12766v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12766v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ekansh Sharma, Daniel M. Roy, Gintare Karolina Dziugaite
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging aims to efficiently combine the weights of multiple expert
models, each trained on a specific task, into a single multi-task model, with
strong performance across all tasks. When applied to all but the last layer of
weights, existing methods -- such as Task Arithmetic, TIES-merging, and TALL
mask merging -- work well to combine expert models obtained by fine-tuning a
common foundation model, operating within a "local" neighborhood of the
foundation model. This work explores the more challenging scenario of
"non-local" merging, which we find arises when an expert model changes
significantly during pretraining or where the expert models do not even share a
common foundation model.
  We observe that standard merging techniques often fail to generalize
effectively in this non-local setting, even when accounting for permutation
symmetries using standard techniques. We identify that this failure is, in
part, due to "variance collapse", a phenomenon identified also in the setting
of linear mode connectivity by Jordan et al. (2023). To address this, we
propose a multi-task technique to re-scale and shift the output activations of
the merged model for each task, aligning its output statistics with those of
the corresponding task-specific expert models. Our experiments demonstrate that
this correction significantly improves the performance of various model merging
approaches in non-local settings, providing a strong baseline for future
research on this problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And
  Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in diffusion models have significantly enhanced their ability
to generate high-quality images and videos, but they have also increased the
risk of producing unsafe content. Existing unlearning/editing-based methods for
safe generation remove harmful concepts from models but face several
challenges: (1) They cannot instantly remove harmful concepts without training.
(2) Their safe generation capabilities depend on collected training data. (3)
They alter model weights, risking degradation in quality for content unrelated
to toxic concepts. To address these, we propose SAFREE, a novel, training-free
approach for safe T2I and T2V, that does not alter the model's weights.
Specifically, we detect a subspace corresponding to a set of toxic concepts in
the text embedding space and steer prompt embeddings away from this subspace,
thereby filtering out harmful content while preserving intended semantics. To
balance the trade-off between filtering toxicity and preserving safe concepts,
SAFREE incorporates a novel self-validating filtering mechanism that
dynamically adjusts the denoising steps when applying the filtered embeddings.
Additionally, we incorporate adaptive re-attention mechanisms within the
diffusion latent space to selectively diminish the influence of features
related to toxic concepts at the pixel level. In the end, SAFREE ensures
coherent safety checking, preserving the fidelity, quality, and safety of the
output. SAFREE achieves SOTA performance in suppressing unsafe content in T2I
generation compared to training-free baselines and effectively filters targeted
concepts while maintaining high-quality images. It also shows competitive
results against training-based methods. We extend SAFREE to various T2I
backbones and T2V tasks, showcasing its flexibility and generalization. SAFREE
provides a robust and adaptable safeguard for ensuring safe visual generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first two authors contributed equally; Project page:
  https://safree-safe-t2i-t2v.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ StyleDistance: Stronger Content-Independent Style Embeddings with
  Synthetic Parallel Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12757v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12757v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, Chris Callison-Burch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Style representations aim to embed texts with similar writing styles closely
and texts with different styles far apart, regardless of content. However, the
contrastive triplets often used for training these representations may vary in
both style and content, leading to potential content leakage in the
representations. We introduce StyleDistance, a novel approach to training
stronger content-independent style embeddings. We use a large language model to
create a synthetic dataset of near-exact paraphrases with controlled style
variations, and produce positive and negative examples across 40 distinct style
features for precise contrastive learning. We assess the quality of our
synthetic data and embeddings through human and automatic evaluations.
StyleDistance enhances the content-independence of style embeddings, which
generalize to real-world benchmarks and outperform leading style
representations in downstream applications. Our model can be found at
https://huggingface.co/StyleDistance/styledistance .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Initialization Method for Factorization Machine Based on Low-Rank
  Approximation for Constructing a Corrected Approximate Ising Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12747v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12747v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuya Seki, Hyakka Nakada, Shu Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an initialization method that can approximate a given
approximate Ising model with a high degree of accuracy using the Factorization
Machine (FM), a machine learning model. The construction of Ising models using
FM is applied to the combinatorial optimization problem using the factorization
machine with quantum annealing. It is anticipated that the optimization
performance of FMQA will be enhanced through the implementation of the
warm-start method. Nevertheless, the optimal initialization method for
leveraging the warm-start approach in FMQA remains undetermined. Consequently,
the present study compares a number of initialization methods and identifies
the most appropriate for use with a warm-start in FMQA through numerical
experimentation. Furthermore, the properties of the proposed FM initialization
method are analyzed using random matrix theory, demonstrating that the
approximation accuracy of the proposed method is not significantly influenced
by the specific Ising model under consideration. The findings of this study
will facilitate the advancement of combinatorial optimization problem-solving
through the use of Ising machines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CREAM: Consistency Regularized Self-Rewarding Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12735v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12735v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent self-rewarding large language models (LLM) have successfully applied
LLM-as-a-Judge to iteratively improve the alignment performance without the
need of human annotations for preference data. These methods commonly utilize
the same LLM to act as both the policy model (which generates responses) and
the reward model (which scores and ranks those responses). The ranked responses
are then used as preference pairs to train the LLM via direct alignment
technologies (e.g. DPO). However, it is noteworthy that throughout this
process, there is no guarantee of accuracy in the rewarding and ranking, which
is critical for ensuring accurate rewards and high-quality preference data.
Empirical results from relatively small LLMs (e.g., 7B parameters) also
indicate that improvements from self-rewarding may diminish after several
iterations in certain situations, which we hypothesize is due to accumulated
bias in the reward system. This bias can lead to unreliable preference data for
training the LLM. To address this issue, we first formulate and analyze the
generalized iterative preference fine-tuning framework for self-rewarding
language model. We then introduce the regularization to this generalized
framework to mitigate the overconfident preference labeling in the
self-rewarding process. Based on this theoretical insight, we propose a
Consistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages
the rewarding consistency across different iterations to regularize the
self-rewarding training, helping the model to learn from more reliable
preference data. With this explicit regularization, our empirical results
demonstrate the superiority of CREAM in improving both reward consistency and
alignment performance. The code is publicly available at
https://github.com/Raibows/CREAM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Counterfactual Generative Modeling with Variational Causal Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12730v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12730v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulun Wu, Louie McConnell, Claudia Iriondo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating an individual's potential outcomes under counterfactual treatments
is a challenging task for traditional causal inference and supervised learning
approaches when the outcome is high-dimensional (e.g. gene expressions, facial
images) and covariates are relatively limited. In this case, to predict one's
outcomes under counterfactual treatments, it is crucial to leverage individual
information contained in its high-dimensional observed outcome in addition to
the covariates. Prior works using variational inference in counterfactual
generative modeling have been focusing on neural adaptations and model variants
within the conditional variational autoencoder formulation, which we argue is
fundamentally ill-suited to the notion of counterfactual in causal inference.
In this work, we present a novel variational Bayesian causal inference
framework and its theoretical backings to properly handle counterfactual
generative modeling tasks, through which we are able to conduct counterfactual
supervision end-to-end during training without any counterfactual samples, and
encourage latent disentanglement that aids the correct identification of causal
effect in counterfactual generations. In experiments, we demonstrate the
advantage of our framework compared to state-of-the-art models in
counterfactual generative modeling on multiple benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Transformer</span> based super-resolution downscaling for regional reanalysis:
  Full domain vs tiling approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12728v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12728v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Pérez, Mario Santa Cruz, Daniel San Martín, José Manuel Gutiérrez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Super-resolution (SR) is a promising cost-effective downscaling methodology
for producing high-resolution climate information from coarser counterparts. A
particular application is downscaling regional reanalysis outputs (predictand)
from the driving global counterparts (predictor). This study conducts an
intercomparison of various SR downscaling methods focusing on temperature and
using the CERRA reanalysis (5.5 km resolution, produced with a regional
atmospheric model driven by ERA5) as example. The method proposed in this work
is the Swin transformer and two alternative methods are used as benchmark
(fully convolutional U-Net and convolutional and dense DeepESD) as well as the
simple bicubic interpolation. We compare two approaches, the standard one using
the full domain as input and a more scalable tiling approach, dividing the full
domain into tiles that are used as input. The methods are trained to downscale
CERRA surface temperature, based on temperature information from the driving
ERA5; in addition, the tiling approach includes static orographic information.
We show that the tiling approach, which requires spatial transferability, comes
at the cost of a lower performance (although it outperforms some full-domain
benchmarks), but provides an efficient scalable solution that allows SR
reduction on a pan-European scale and is valuable for real-time applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing 3D Geometry Reconstruction from Implicit Neural
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shen Fan, Przemyslaw Musialski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit neural representations have emerged as a powerful tool in learning
3D geometry, offering unparalleled advantages over conventional representations
like mesh-based methods. A common type of INR implicitly encodes a shape's
boundary as the zero-level set of the learned continuous function and learns a
mapping from a low-dimensional latent space to the space of all possible shapes
represented by its signed distance function. However, most INRs struggle to
retain high-frequency details, which are crucial for accurate geometric
depiction, and they are computationally expensive. To address these
limitations, we present a novel approach that both reduces computational
expenses and enhances the capture of fine details. Our method integrates
periodic activation functions, positional encodings, and normals into the
neural network architecture. This integration significantly enhances the
model's ability to learn the entire space of 3D shapes while preserving
intricate details and sharp features, areas where conventional representations
often fall short.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Does Variance Shape the Regret in Contextual Bandits? <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Jia, Jian Qian, Alexander Rakhlin, Chen-Yu Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider realizable contextual bandits with general function
approximation, investigating how small reward variance can lead to
better-than-minimax regret bounds. Unlike in minimax bounds, we show that the
eluder dimension $d_\text{elu}$$-$a complexity measure of the function
class$-$plays a crucial role in variance-dependent bounds. We consider two
types of adversary:
  (1) Weak adversary: The adversary sets the reward variance before observing
the learner's action. In this setting, we prove that a regret of
$\Omega(\sqrt{\min\{A,d_\text{elu}\}\Lambda}+d_\text{elu})$ is unavoidable when
$d_{\text{elu}}\leq\sqrt{AT}$, where $A$ is the number of actions, $T$ is the
total number of rounds, and $\Lambda$ is the total variance over $T$ rounds.
For the $A\leq d_\text{elu}$ regime, we derive a nearly matching upper bound
$\tilde{O}(\sqrt{A\Lambda}+d_\text{elu})$ for the special case where the
variance is revealed at the beginning of each round.
  (2) Strong adversary: The adversary sets the reward variance after observing
the learner's action. We show that a regret of
$\Omega(\sqrt{d_\text{elu}\Lambda}+d_\text{elu})$ is unavoidable when
$\sqrt{d_\text{elu}\Lambda}+d_\text{elu}\leq\sqrt{AT}$. In this setting, we
provide an upper bound of order
$\tilde{O}(d_\text{elu}\sqrt{\Lambda}+d_\text{elu})$.
  Furthermore, we examine the setting where the function class additionally
provides distributional information of the reward, as studied by Wang et al.
(2024). We demonstrate that the regret bound
$\tilde{O}(\sqrt{d_\text{elu}\Lambda}+d_\text{elu})$ established in their work
is unimprovable when $\sqrt{d_{\text{elu}}\Lambda}+d_\text{elu}\leq\sqrt{AT}$.
However, with a slightly different definition of the total variance and with
the assumption that the reward follows a Gaussian distribution, one can achieve
a regret of $\tilde{O}(\sqrt{A\Lambda}+d_\text{elu})$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the sample complexity of purity and inner product estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiyuan Gong, Jonas Haferkamp, Qi Ye, Zhihan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the sample complexity of the prototypical tasks quantum purity
estimation and quantum inner product estimation. In purity estimation, we are
to estimate $tr(\rho^2)$ of an unknown quantum state $\rho$ to additive error
$\epsilon$. Meanwhile, for quantum inner product estimation, Alice and Bob are
to estimate $tr(\rho\sigma)$ to additive error $\epsilon$ given copies of
unknown quantum state $\rho$ and $\sigma$ using classical communication and
restricted quantum communication.
  In this paper, we show a strong connection between the sample complexity of
purity estimation with bounded quantum memory and inner product estimation with
bounded quantum communication and unentangled measurements. We propose a
protocol that solves quantum inner product estimation with $k$-qubit one-way
quantum communication and unentangled local measurements using
$O(median\{1/\epsilon^2,2^{n/2}/\epsilon,2^{n-k}/\epsilon^2\})$ copies of
$\rho$ and $\sigma$. Our protocol can be modified to estimate the purity of an
unknown quantum state $\rho$ using $k$-qubit quantum memory with the same
complexity. We prove that arbitrary protocols with $k$-qubit quantum memory
that estimate purity to error $\epsilon$ require
$\Omega(median\{1/\epsilon^2,2^{n/2}/\sqrt{\epsilon},2^{n-k}/\epsilon^2\})$
copies of $\rho$. This indicates the same lower bound for quantum inner product
estimation with one-way $k$-qubit quantum communication and classical
communication, and unentangled local measurements. For purity estimation, we
further improve the lower bound to
$\Omega(\max\{1/\epsilon^2,2^{n/2}/\epsilon\})$ for any protocols using an
identical single-copy projection-valued measurement.
  Additionally, we investigate a decisional variant of quantum distributed
inner product estimation without quantum communication for mixed state and
provide a lower bound on the sample complexity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs
  with Adaptive Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sarcasm Detection in a Less-Resourced Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lazar Đoković, Marko Robnik-Šikonja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The sarcasm detection task in natural language processing tries to classify
whether an utterance is sarcastic or not. It is related to sentiment analysis
since it often inverts surface sentiment. Because sarcastic sentences are
highly dependent on context, and they are often accompanied by various
non-verbal cues, the task is challenging. Most of related work focuses on
high-resourced languages like English. To build a sarcasm detection dataset for
a less-resourced language, such as Slovenian, we leverage two modern
techniques: a machine translation specific medium-size transformer model, and a
very large generative language model. We explore the viability of translated
datasets and how the size of a pretrained transformer affects its ability to
detect sarcasm. We train ensembles of detection models and evaluate models'
performance. The results show that larger models generally outperform smaller
ones and that ensembling can slightly improve sarcasm detection performance.
Our best ensemble approach achieves an $\text{F}_1$-score of 0.765 which is
close to annotators' agreement in the source language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, published in the Slovenian Conference on Artificial
  Intelligence</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural-based Control for CubeSat Docking Maneuvers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Stoisa, Federica Paganelli Azza, Luca Romanelli, Mattia Varile
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous Rendezvous and Docking (RVD) have been extensively studied in
recent years, addressing the stringent requirements of spacecraft dynamics
variations and the limitations of GNC systems. This paper presents an
innovative approach employing Artificial Neural Networks (ANN) trained through
Reinforcement Learning (RL) for autonomous spacecraft guidance and control
during the final phase of the rendezvous maneuver. The proposed strategy is
easily implementable onboard and offers fast adaptability and robustness to
disturbances by learning control policies from experience rather than relying
on predefined models. Extensive Monte Carlo simulations within a relevant
environment are conducted in 6DoF settings to validate our approach, along with
hardware tests that demonstrate deployment feasibility. Our findings highlight
the efficacy of RL in assuring the adaptability and efficiency of spacecraft
RVD, offering insights into future mission expectations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via
  Lightweight Value Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12700v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12700v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in diffusion models trained on large-scale data have
enabled the generation of indistinguishable human-level images, yet they often
produce harmful content misaligned with human values, e.g., social bias, and
offensive content. Despite extensive research on Large Language Models (LLMs),
the challenge of Text-to-Image (T2I) model alignment remains largely
unexplored. Addressing this problem, we propose LiVO (Lightweight Value
Optimization), a novel lightweight method for aligning T2I models with human
values. LiVO only optimizes a plug-and-play value encoder to integrate a
specified value principle with the input prompt, allowing the control of
generated images over both semantics and values. Specifically, we design a
diffusion model-tailored preference optimization loss, which theoretically
approximates the Bradley-Terry model used in LLM alignment but provides a more
flexible trade-off between image quality and value conformity. To optimize the
value encoder, we also develop a framework to automatically construct a
text-image preference dataset of 86k (prompt, aligned image, violating image,
value principle) samples. Without updating most model parameters and through
adaptive value selection from the input prompt, LiVO significantly reduces
harmful outputs and achieves faster convergence, surpassing several strong
baselines and taking an initial step towards ethically aligned T2I models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024. The dataset and code can be found at
  https://github.com/achernarwang/LiVO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Machine Learning Approach to Brain Tumor Detection and Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alice Oh, Inyoung Noh, Jian Choo, Jihoo Lee, Justin Park, Kate Hwang, Sanghyeon Kim, Soo Min Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Brain tumor detection and classification are critical tasks in medical image
analysis, particularly in early-stage diagnosis, where accurate and timely
detection can significantly improve treatment outcomes. In this study, we apply
various statistical and machine learning models to detect and classify brain
tumors using brain MRI images. We explore a variety of statistical models
including linear, logistic, and Bayesian regressions, and the machine learning
models including decision tree, random forest, single-layer perceptron,
multi-layer perceptron, convolutional neural network (CNN), recurrent neural
network, and long short-term memory. Our findings show that CNN outperforms
other models, achieving the best performance. Additionally, we confirm that the
CNN model can also work for multi-class classification, distinguishing between
four categories of brain MRI images such as normal, glioma, meningioma, and
pituitary tumor images. This study demonstrates that machine learning
approaches are suitable for brain tumor detection and classification,
facilitating real-world medical applications in assisting radiologists with
early and accurate diagnosis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 2 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Local transfer learning Gaussian process modeling, with applications to
  surrogate modeling of expensive computer simulators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinming Wang, Simon Mak, John Miller, Jianguo Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A critical bottleneck for scientific progress is the costly nature of
computer simulations for complex systems. Surrogate models provide an appealing
solution: such models are trained on simulator evaluations, then used to
emulate and quantify uncertainty on the expensive simulator at unexplored
inputs. In many applications, one often has available data on related systems.
For example, in designing a new jet turbine, there may be existing studies on
turbines with similar configurations. A key question is how information from
such "source" systems can be transferred for effective surrogate training on
the "target" system of interest. We thus propose a new LOcal transfer Learning
Gaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussian
process to transfer such information for surrogate modeling. The key novelty of
the LOL-GP is a latent regularization model, which identifies regions where
transfer should be performed and regions where it should be avoided. This
"local transfer" property is desirable in scientific systems: at certain
parameters, such systems may behave similarly and thus transfer is beneficial;
at other parameters, they may behave differently and thus transfer is
detrimental. By accounting for local transfer, the LOL-GP can rectify a
critical limitation of "negative transfer" in existing transfer learning
models, where the transfer of information worsens predictive performance. We
derive a Gibbs sampling algorithm for efficient posterior predictive sampling
on the LOL-GP, for both the multi-source and multi-fidelity transfer settings.
We then show, via a suite of numerical experiments and an application for jet
turbine design, the improved surrogate performance of the LOL-GP over existing
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A distance function for stochastic matrices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12689v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12689v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antony Lee, Peter Tino, Iain Bruce Styles
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by information geometry, a distance function on the space of
stochastic matrices is advocated. Starting with sequences of Markov chains the
Bhattacharyya angle is advocated as the natural tool for comparing both short
and long term Markov chain runs. Bounds on the convergence of the distance and
mixing times are derived. Guided by the desire to compare different Markov
chain models, especially in the setting of healthcare processes, a new distance
function on the space of stochastic matrices is presented. It is a true
distance measure which has a closed form and is efficient to implement for
numerical evaluation. In the case of ergodic Markov chains, it is shown that
considering either the Bhattacharyya angle on Markov sequences or the new
stochastic matrix distance leads to the same distance between models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic Mapping of Anatomical Landmarks from Free-Text Using Large
  Language Models: Insights from Llama-2 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12686v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12686v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anatomical landmarks are vital in medical imaging for navigation and anomaly
detection. Modern large language models (LLMs), like Llama-2, offer promise for
automating the mapping of these landmarks in free-text radiology reports to
corresponding positions in image data. Recent studies propose LLMs may develop
coherent representations of generative processes. Motivated by these insights,
we investigated whether LLMs accurately represent the spatial positions of
anatomical landmarks. Through experiments with Llama-2 models, we found that
they can linearly represent anatomical landmarks in space with considerable
robustness to different prompts. These results underscore the potential of LLMs
to enhance the efficiency and accuracy of medical imaging workflows.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Neural Reparameterization for Differentiable PDE-constrained
  Optimization <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12683v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12683v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Archis S. Joglekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Partial-differential-equation (PDE)-constrained optimization is a well-worn
technique for acquiring optimal parameters of systems governed by PDEs.
However, this approach is limited to providing a single set of optimal
parameters per optimization. Given a differentiable PDE solver, if the free
parameters are reparameterized as the output of a neural network, that neural
network can be trained to learn a map from a probability distribution to the
distribution of optimal parameters. This proves useful in the case where there
are many well performing local minima for the PDE. We apply this technique to
train a neural network that generates optimal parameters that minimize
laser-plasma instabilities relevant to laser fusion and show that the neural
network generates many well performing and diverse minima.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to D3S3: Data-driven and Differentiable Simulations,
  Surrogates, and Solvers - Workshop @ NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Multi-Task Learning for Accurate Spacecraft Pose Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesco Evangelisti, Francesco Rossi, Tobia Giani, Ilaria Bloise, Mattia Varile
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate satellite pose estimation is crucial for autonomous guidance,
navigation, and control (GNC) systems in in-orbit servicing (IOS) missions.
This paper explores the impact of different tasks within a multi-task learning
(MTL) framework for satellite pose estimation using monocular images. By
integrating tasks such as direct pose estimation, keypoint prediction, object
localization, and segmentation into a single network, the study aims to
evaluate the reciprocal influence between tasks by testing different multi-task
configurations thanks to the modularity of the convolutional neural network
(CNN) used in this work. The trends of mutual bias between the analyzed tasks
are found by employing different weighting strategies to further test the
robustness of the findings. A synthetic dataset was developed to train and test
the MTL network. Results indicate that direct pose estimation and heatmap-based
pose estimation positively influence each other in general, while both the
bounding box and segmentation tasks do not provide significant contributions
and tend to degrade the overall estimation accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Optimization Algorithms for Linear Adversarial Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antônio H. RIbeiro, Thomas B. Schön, Dave Zahariah, Francis Bach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial training can be used to learn models that are robust against
perturbations. For linear models, it can be formulated as a convex optimization
problem. Compared to methods proposed in the context of deep learning,
leveraging the optimization structure allows significantly faster convergence
rates. Still, the use of generic convex solvers can be inefficient for
large-scale problems. Here, we propose tailored optimization algorithms for the
adversarial training of linear models, which render large-scale regression and
classification problems more tractable. For regression problems, we propose a
family of solvers based on iterative ridge regression and, for classification,
a family of solvers based on projected gradient descent. The methods are based
on extended variable reformulations of the original problem. We illustrate
their efficiency in numerical examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context Matters: Leveraging Contextual Features for Time Series
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12672v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12672v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sameep Chattopadhyay, Pulkit Paliwal, Sai Shankar Narasimhan, Shubhankar Agarwal, Sandeep P. Chinchali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series forecasts are often influenced by exogenous contextual features
in addition to their corresponding history. For example, in financial settings,
it is hard to accurately predict a stock price without considering public
sentiments and policy decisions in the form of news articles, tweets, etc.
Though this is common knowledge, the current state-of-the-art (SOTA)
forecasting models fail to incorporate such contextual information, owing to
its heterogeneity and multimodal nature. To address this, we introduce
ContextFormer, a novel plug-and-play method to surgically integrate multimodal
contextual information into existing pre-trained forecasting models.
ContextFormer effectively distills forecast-specific information from rich
multimodal contexts, including categorical, continuous, time-varying, and even
textual information, to significantly enhance the performance of existing base
forecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on
a range of real-world datasets spanning energy, traffic, environmental, and
financial domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ New Paradigm of Adversarial Training: Breaking Inherent Trade-Off
  between Accuracy and Robustness via Dummy Classes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanyun Wang, Li Liu, Zi Liang, Qingqing Ye, Haibo Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial Training (AT) is one of the most effective methods to enhance the
robustness of DNNs. However, existing AT methods suffer from an inherent
trade-off between adversarial robustness and clean accuracy, which seriously
hinders their real-world deployment. While this problem has been widely studied
within the current AT paradigm, existing AT methods still typically experience
a reduction in clean accuracy by over 10% to date, without significant
improvements in robustness compared with simple baselines like PGD-AT. This
inherent trade-off raises a question: whether the current AT paradigm, which
assumes to learn the corresponding benign and adversarial samples as the same
class, inappropriately combines clean and robust objectives that may be
essentially inconsistent. In this work, we surprisingly reveal that up to 40%
of CIFAR-10 adversarial samples always fail to satisfy such an assumption
across various AT methods and robust models, explicitly indicating the
improvement room for the current AT paradigm. Accordingly, to relax the tension
between clean and robust learning derived from this overstrict assumption, we
propose a new AT paradigm by introducing an additional dummy class for each
original class, aiming to accommodate the hard adversarial samples with shifted
distribution after perturbation. The robustness w.r.t. these adversarial
samples can be achieved by runtime recovery from the predicted dummy classes to
their corresponding original ones, eliminating the compromise with clean
learning. Building on this new paradigm, we propose a novel plug-and-play AT
technology named DUmmy Classes-based Adversarial Training (DUCAT). Extensive
experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that the
DUCAT concurrently improves clean accuracy and adversarial robustness compared
with state-of-the-art benchmarks, effectively breaking the existing inherent
trade-off.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Work in progress. The code is available at
  https://github.com/FlaAI/DUCAT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explanation-Preserving Augmentation for Semi-Supervised Graph
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuomin Chen, Jingchao Ni, Hojat Allah Salehi, Xu Zheng, Esteban Schafir, Farhad Shirani, Dongsheng Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph representation learning (GRL), enhanced by graph augmentation methods,
has emerged as an effective technique achieving performance improvements in
wide tasks such as node classification and graph classification. In
self-supervised GRL, paired graph augmentations are generated from each graph.
Its objective is to infer similar representations for augmentations of the same
graph, but maximally distinguishable representations for augmentations of
different graphs. Analogous to image and language domains, the desiderata of an
ideal augmentation method include both (1) semantics-preservation; and (2)
data-perturbation; i.e., an augmented graph should preserve the semantics of
its original graph while carrying sufficient variance. However, most existing
(un-)/self-supervised GRL methods focus on data perturbation but largely
neglect semantics preservation. To address this challenge, in this paper, we
propose a novel method, Explanation-Preserving Augmentation (EPA), that
leverages graph explanation techniques for generating augmented graphs that can
bridge the gap between semantics-preservation and data-perturbation. EPA first
uses a small number of labels to train a graph explainer to infer the
sub-structures (explanations) that are most relevant to a graph's semantics.
These explanations are then used to generate semantics-preserving augmentations
for self-supervised GRL, namely EPA-GRL. We demonstrate theoretically, using an
analytical example, and through extensive experiments on a variety of benchmark
datasets that EPA-GRL outperforms the state-of-the-art (SOTA) GRL methods,
which are built upon semantics-agnostic data augmentations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 7 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Position Specific Scoring Is All You Need? Revisiting Protein Sequence
  Classification Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarwan Ali, Taslim Murad, Prakash Chourasia, Haris Mansoor, Imdad Ullah Khan, Pin-Yu Chen, Murray Patterson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the structural and functional characteristics of proteins are
crucial for developing preventative and curative strategies that impact fields
from drug discovery to policy development. An important and popular technique
for examining how amino acids make up these characteristics of the protein
sequences with position-specific scoring (PSS). While the string kernel is
crucial in natural language processing (NLP), it is unclear if string kernels
can extract biologically meaningful information from protein sequences, despite
the fact that they have been shown to be effective in the general sequence
analysis tasks. In this work, we propose a weighted PSS kernel matrix (or
W-PSSKM), that combines a PSS representation of protein sequences, which
encodes the frequency information of each amino acid in a sequence, with the
notion of the string kernel. This results in a novel kernel function that
outperforms many other approaches for protein sequence classification. We
perform extensive experimentation to evaluate the proposed method. Our findings
demonstrate that the W-PSSKM significantly outperforms existing baselines and
state-of-the-art methods and achieves up to 45.1\% improvement in
classification accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constrained Posterior Sampling: Time Series Generation with Hard
  Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12652v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12652v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sai Shankar Narasimhan, Shubhankar Agarwal, Litu Rout, Sanjay Shakkottai, Sandeep P. Chinchali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating realistic time series samples is crucial for stress-testing models
and protecting user privacy by using synthetic data. In engineering and
safety-critical applications, these samples must meet certain hard constraints
that are domain-specific or naturally imposed by physics or nature. Consider,
for example, generating electricity demand patterns with constraints on peak
demand times. This can be used to stress-test the functioning of power grids
during adverse weather conditions. Existing approaches for generating
constrained time series are either not scalable or degrade sample quality. To
address these challenges, we introduce Constrained Posterior Sampling (CPS), a
diffusion-based sampling algorithm that aims to project the posterior mean
estimate into the constraint set after each denoising update. Notably, CPS
scales to a large number of constraints (~100) without requiring additional
training. We provide theoretical justifications highlighting the impact of our
projection step on sampling. Empirically, CPS outperforms state-of-the-art
methods in sample quality and similarity to real time series by around 10% and
42%, respectively, on real-world stocks, traffic, and air quality datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimization and Application of Cloud-based Deep Learning Architecture
  for Multi-Source Data Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Zhang, Fa Wang, Xin Huang, Xintao Li, Sibei Liu, Hansong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study develops a cloud-based deep learning system for early prediction
of diabetes, leveraging the distributed computing capabilities of the AWS cloud
platform and deep learning technologies to achieve efficient and accurate risk
assessment. The system utilizes EC2 p3.8xlarge GPU instances to accelerate
model training, reducing training time by 93.2% while maintaining a prediction
accuracy of 94.2%. With an automated data processing and model training
pipeline built using Apache Airflow, the system can complete end-to-end updates
within 18.7 hours. In clinical applications, the system demonstrates a
prediction accuracy of 89.8%, sensitivity of 92.3%, and specificity of 95.1%.
Early interventions based on predictions lead to a 37.5% reduction in diabetes
incidence among the target population. The system's high performance and
scalability provide strong support for large-scale diabetes prevention and
management, showcasing significant public health value.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 Pages, 5 Figures, 3 Tables. The final version will be published in
  the proceedings of the IEEE conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Arbitrary QUBO Optimization: Analysis of Classical and
  Quantum-Activated Feedforward Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12636v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12636v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chia-Tso Lai, Carsten Blank, Peter Schmelcher, Rick Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quadratic Unconstrained Binary Optimization (QUBO) sits at the heart of many
industries and academic fields such as logistics, supply chain, finance,
pharmaceutical science, chemistry, IT, and energy sectors, among others. These
problems typically involve optimizing a large number of binary variables, which
makes finding exact solutions exponentially more difficult. Consequently, most
QUBO problems are classified as NP-hard. To address this challenge, we
developed a powerful feedforward neural network (FNN) optimizer for arbitrary
QUBO problems. In this work, we demonstrate that the FNN optimizer can provide
high-quality approximate solutions for large problems, including dense
80-variable weighted MaxCut and random QUBOs, achieving an average accuracy of
over 99% in less than 1.1 seconds on an 8-core CPU. Additionally, the FNN
optimizer outperformed the Gurobi optimizer by 72% on 200-variable random QUBO
problems within a 100-second computation time limit, exhibiting strong
potential for real-time optimization tasks. Building on this model, we explored
the novel approach of integrating FNNs with a quantum annealer-based activation
function to create a quantum-classical encoder-decoder (QCED) optimizer, aiming
to further enhance the performance of FNNs in QUBO optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Exact Finite-dimensional Explicit Feature Map for Kernel Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kamaledin Ghiasi-Shirazi, Mohammadreza Qaraei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kernel methods in machine learning use a kernel function that takes two data
points as input and returns their inner product after mapping them to a Hilbert
space, implicitly and without actually computing the mapping. For many kernel
functions, such as Gaussian and Laplacian kernels, the feature space is known
to be infinite-dimensional, making operations in this space possible only
implicitly. This implicit nature necessitates algorithms to be expressed using
dual representations and the kernel trick. In this paper, given an arbitrary
kernel function, we introduce an explicit, finite-dimensional feature map for
any arbitrary kernel function that ensures the inner product of data points in
the feature space equals the kernel function value, during both training and
testing. The existence of this explicit mapping allows for kernelized
algorithms to be formulated in their primal form, without the need for the
kernel trick or the dual representation. As a first application, we demonstrate
how to derive kernelized machine learning algorithms directly, without
resorting to the dual representation, and apply this method specifically to
PCA. As another application, without any changes to the t-SNE algorithm and its
implementation, we use it for visualizing the feature space of kernel
functions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explainable Moral Values: a neuro-symbolic approach to value
  classification <span class="chip">ESWC24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicolas Lazzari, Stefano De Giorgis, Aldo Gangemi, Valentina Presutti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work explores the integration of ontology-based reasoning and Machine
Learning techniques for explainable value classification. By relying on an
ontological formalization of moral values as in the Moral Foundations Theory,
relying on the DnS Ontology Design Pattern, the \textit{sandra} neuro-symbolic
reasoner is used to infer values (fomalized as descriptions) that are
\emph{satisfied by} a certain sentence. Sentences, alongside their structured
representation, are automatically generated using an open-source Large Language
Model. The inferred descriptions are used to automatically detect the value
associated with a sentence. We show that only relying on the reasoner's
inference results in explainable classification comparable to other more
complex approaches. We show that combining the reasoner's inferences with
distributional semantics methods largely outperforms all the baselines,
including complex models based on neural network architectures. Finally, we
build a visualization tool to explore the potential of theory-based values
classification, which is publicly available at http://xmv.geomeaning.com/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ESWC24 Satellite Event</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety,
  Toxicity, and Legal Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruimeng Ye, Yang Xiao, Bo Hui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) continue to advance, ensuring their alignment
with human values becomes increasingly critical. Traditional alignment methods
heavily rely on human feedback to fine-tune models. With the emergence of
superhuman models whose outputs may surpass human understanding, evaluating and
aligning these models using human judgments poses significant challenges. To
address the challenges, recent works use weak supervisors to elicit knowledge
from much stronger models. However, there are important disanalogies between
the empirical setup in the existing works and the genuine goal of alignment. We
remark that existing works investigate the phenomenon of weak-to-strong
generation in analogous setup (i.e., binary classification), rather than
practical alignment-relevant tasks (e.g., safety). In this paper, we bridge
this gap by extending weak-to-strong generation to the context of practical
alignment. We empirically demonstrate the widespread phenomenon of
weak-to-strong generation in three complicated alignment tasks: safety,
toxicity, and legal reasoning}. Furthermore, we explore efficient strategies
for improving alignment performance to enhance the quality of model outcomes.
Lastly, we summarize and analyze the challenges and potential solutions in
regard to specific alignment tasks, which we hope to catalyze the research
progress on the topic of weak-to-strong generalization. Our code is released at
https://github.com/yeruimeng/WTS.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Model Kinship for Merging Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yedi Hu, Yunzhi Yao, Ningyu Zhang, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging has become one of the key technologies for enhancing the
capabilities and efficiency of Large Language Models (LLMs). However, our
understanding of the expected performance gains and principles when merging any
two models remains limited. In this work, we introduce model kinship, the
degree of similarity or relatedness between LLMs, analogous to biological
evolution. With comprehensive empirical analysis, we find that there is a
certain relationship between model kinship and the performance gains after
model merging, which can help guide our selection of candidate models. Inspired
by this, we propose a new model merging strategy: Top-k Greedy Merging with
Model Kinship, which can yield better performance on benchmark datasets.
Specifically, we discover that using model kinship as a criterion can assist us
in continuously performing model merging, alleviating the degradation (local
optima) in model evolution, whereas model kinship can serve as a guide to
escape these traps. Code is available at
https://github.com/zjunlp/ModelKinship.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Graph Foundation Models: The Perspective of Zero-shot Reasoning
  on Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Wang, Siqiang Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inspired by the success of artificial general intelligence, there is a trend
towards developing Graph Foundation Models that excel in generalization across
various graph tasks and domains. However, current models often require
extensive training or fine-tuning to capture structural and semantic insights
on new graphs, which limits their versatility. In this work, we explore graph
foundation models from the perspective of zero-shot reasoning on Knowledge
Graphs (KGs). Our focus is on utilizing KGs as a unified topological structure
to tackle diverse tasks, while addressing semantic isolation challenges in KG
reasoning to effectively integrate diverse semantic and structural features.
This brings us new methodological insights into KG reasoning, as well as high
generalizability towards foundation models in practice. Methodologically, we
introduce SCORE, a unified graph reasoning framework that effectively
generalizes diverse graph tasks using zero-shot learning. At the core of SCORE
is semantic conditional message passing, a technique designed to capture both
structural and semantic invariances in graphs, with theoretical backing for its
expressive power. Practically, we evaluate the zero-shot reasoning capability
of SCORE using 38 diverse graph datasets, covering node-level, link-level, and
graph-level tasks across multiple domains. Our experiments reveal a substantial
performance improvement over prior foundation models and supervised baselines,
highlighting the efficacy and adaptability of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 Pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Rank Adversarial PGD Attack 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12607v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12607v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dayana Savostianova, Emanuele Zangrando, Francesco Tudisco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial attacks on deep neural network models have seen rapid development
and are extensively used to study the stability of these networks. Among
various adversarial strategies, Projected Gradient Descent (PGD) is a widely
adopted method in computer vision due to its effectiveness and quick
implementation, making it suitable for adversarial training. In this work, we
observe that in many cases, the perturbations computed using PGD predominantly
affect only a portion of the singular value spectrum of the original image,
suggesting that these perturbations are approximately low-rank. Motivated by
this observation, we propose a variation of PGD that efficiently computes a
low-rank attack. We extensively validate our method on a range of standard
models as well as robust models that have undergone adversarial training. Our
analysis indicates that the proposed low-rank PGD can be effectively used in
adversarial training due to its straightforward and fast implementation coupled
with competitive performance. Notably, we find that low-rank PGD often performs
comparably to, and sometimes even outperforms, the traditional full-rank PGD
attack, while using significantly less memory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Self-Supervised</span> Learning of Disentangled Representations for
  Multivariate Time-Series <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ching Chang, Chiao-Tung Chan, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multivariate time-series data in fields like healthcare and industry are
informative but challenging due to high dimensionality and lack of labels.
Recent self-supervised learning methods excel in learning rich representations
without labels but struggle with disentangled embeddings and inductive bias
issues like transformation-invariance. To address these challenges, we
introduce TimeDRL, a framework for multivariate time-series representation
learning with dual-level disentangled embeddings. TimeDRL features: (i)
disentangled timestamp-level and instance-level embeddings using a [CLS] token
strategy; (ii) timestamp-predictive and instance-contrastive tasks for
representation learning; and (iii) avoidance of augmentation methods to
eliminate inductive biases. Experiments on forecasting and classification
datasets show TimeDRL outperforms existing methods, with further validation in
semi-supervised settings with limited labeled data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024 Workshop: Self-Supervised Learning - Theory and Practice</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Bayesian Confidence (BACON) Estimator for Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick D. Kee, Max J. Brown, Jonathan C. Rice, Christian A. Howell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces the Bayesian Confidence Estimator (BACON) for deep
neural networks. Current practice of interpreting Softmax values in the output
layer as probabilities of outcomes is prone to extreme predictions of class
probability. In this work we extend Waagen's method of representing the
terminal layers with a geometric model, where the probability associated with
an output vector is estimated with Bayes' Rule using validation data to provide
likelihood and normalization values. This estimator provides superior ECE and
ACE calibration error compared to Softmax for ResNet-18 at 85% network
accuracy, and EfficientNet-B0 at 95% network accuracy, on the CIFAR-10 dataset
with an imbalanced test set, except for very high accuracy edge cases. In
addition, when using the ACE metric, BACON demonstrated improved calibration
error when estimating probabilities for the imbalanced test set when using
actual class distribution fractions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 15 figures (10 of which include sub-figures)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Henrique Donâncio, Antoine Barrier, Leah F. South, Florence Forbes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Deep Reinforcement Learning models trained using gradient-based
techniques, the choice of optimizer and its learning rate are crucial to
achieving good performance: higher learning rates can prevent the model from
learning effectively, while lower ones might slow convergence. Additionally,
due to the non-stationarity of the objective function, the best-performing
learning rate can change over the training steps. To adapt the learning rate, a
standard technique consists of using decay schedulers. However, these
schedulers assume that the model is progressively approaching convergence,
which may not always be true, leading to delayed or premature adjustments. In
this work, we propose dynamic Learning Rate for deep Reinforcement Learning
(LRRL), a meta-learning approach that selects the learning rate based on the
agent's performance during training. LRRL is based on a multi-armed bandit
algorithm, where each arm represents a different learning rate, and the bandit
feedback is provided by the cumulative returns of the RL policy to update the
arms' probability distribution. Our empirical results demonstrate that LRRL can
substantially improve the performance of deep RL algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Personalized Prediction Models for Changes in Knee Pain among Patients
  with Osteoarthritis Participating in Supervised Exercise and Education 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        M. Rafiei, S. Das, M. Bakhtiari, E. M. Roos, S. T. Skou, D. T. Grønne, J. Baumbach, L. Baumbach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knee osteoarthritis (OA) is a widespread chronic condition that impairs
mobility and diminishes quality of life. Despite the proven benefits of
exercise therapy and patient education in managing the OA symptoms pain and
functional limitations, these strategies are often underutilized. Personalized
outcome prediction models can help motivate and engage patients, but the
accuracy of existing models in predicting changes in knee pain remains
insufficiently examined. To validate existing models and introduce a concise
personalized model predicting changes in knee pain before to after
participating in a supervised education and exercise therapy program (GLA:D)
for knee OA patients. Our models use self-reported patient information and
functional measures. To refine the number of variables, we evaluated the
variable importance and applied clinical reasoning. We trained random forest
regression models and compared the rate of true predictions of our models with
those utilizing average values. We evaluated the performance of a full,
continuous, and concise model including all 34, all 11 continuous, and the six
most predictive variables respectively. All three models performed similarly
and were comparable to the existing model, with R-squares of 0.31-0.32 and
RMSEs of 18.65-18.85 - despite our increased sample size. Allowing a deviation
of 15 VAS points from the true change in pain, our concise model and utilizing
the average values estimated the change in pain at 58% and 51% correctly,
respectively. Our supplementary analysis led to similar outcomes. Our concise
personalized prediction model more accurately predicts changes in knee pain
following the GLA:D program compared to average pain improvement values.
Neither the increase in sample size nor the inclusion of additional variables
improved previous models. To improve predictions, new variables beyond those in
the GLA:D are required.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Expand and Compress: Exploring Tuning Principles for Continual
  Spatio-Temporal Graph Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12593v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12593v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Chen, Yuxuan Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The widespread deployment of sensing devices leads to a surge in data for
spatio-temporal forecasting applications such as traffic flow, air quality, and
wind energy. Although spatio-temporal graph neural networks have achieved
success in modeling various static spatio-temporal forecasting scenarios,
real-world spatio-temporal data are typically received in a streaming manner,
and the network continuously expands with the installation of new sensors.
Thus, spatio-temporal forecasting in streaming scenarios faces dual challenges:
the inefficiency of retraining models over newly arrived data and the
detrimental effects of catastrophic forgetting over long-term history. To
address these challenges, we propose a novel prompt tuning-based continuous
forecasting method, following two fundamental tuning principles guided by
empirical and theoretical analysis: expand and compress, which effectively
resolve the aforementioned problems with lightweight tuning parameters.
Specifically, we integrate the base spatio-temporal graph neural network with a
continuous prompt pool, utilizing stored prompts (i.e., few learnable
parameters) in memory, and jointly optimize them with the base spatio-temporal
graph neural network. This method ensures that the model sequentially learns
from the spatio-temporal data stream to accomplish tasks for corresponding
periods. Extensive experimental results on multiple real-world datasets
demonstrate the multi-faceted superiority of our method over the
state-of-the-art baselines, including effectiveness, efficiency, universality,
etc.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor
  Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minkyoung Cho, Yulong Cao, Jiachen Sun, Qingzhao Zhang, Marco Pavone, Jeong Joon Park, Heng Yang, Z. Morley Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An important paradigm in 3D object detection is the use of multiple
modalities to enhance accuracy in both normal and challenging conditions,
particularly for long-tail scenarios. To address this, recent studies have
explored two directions of adaptive approaches: MoE-based adaptive fusion,
which struggles with uncertainties arising from distinct object configurations,
and late fusion for output-level adaptive fusion, which relies on separate
detection pipelines and limits comprehensive understanding. In this work, we
introduce Cocoon, an object- and feature-level uncertainty-aware fusion
framework. The key innovation lies in uncertainty quantification for
heterogeneous representations, enabling fair comparison across modalities
through the introduction of a feature aligner and a learnable surrogate ground
truth, termed feature impression. We also define a training objective to ensure
that their relationship provides a valid metric for uncertainty quantification.
Cocoon consistently outperforms existing static and adaptive methods in both
normal and challenging conditions, including those with natural and artificial
corruptions. Furthermore, we show the validity and efficacy of our uncertainty
metric across diverse datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Lab to Pocket: A Novel Continual Learning-based Mobile Application
  for Screening COVID-19 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danny Falero, Muhammad Ashad Kabir, Nusrat Homaira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence (AI) has emerged as a promising tool for predicting
COVID-19 from medical images. In this paper, we propose a novel continual
learning-based approach and present the design and implementation of a mobile
application for screening COVID-19. Our approach demonstrates the ability to
adapt to evolving datasets, including data collected from different locations
or hospitals, varying virus strains, and diverse clinical presentations,
without retraining from scratch. We have evaluated state-of-the-art continual
learning methods for detecting COVID-19 from chest X-rays and selected the
best-performing model for our mobile app. We evaluated various deep learning
architectures to select the best-performing one as a foundation model for
continual learning. Both regularization and memory-based methods for continual
learning were tested, using different memory sizes to develop the optimal
continual learning model for our app. DenseNet161 emerged as the best
foundation model with 96.87\% accuracy, and Learning without Forgetting (LwF)
was the top continual learning method with an overall performance of 71.99\%.
The mobile app design considers both patient and doctor perspectives. It
incorporates the continual learning DenseNet161 LwF model on a cloud server,
enabling the model to learn from new instances of chest X-rays and their
classifications as they are submitted. The app is designed, implemented, and
evaluated to ensure it provides an efficient tool for COVID-19 screening. The
app is available to download from
https://github.com/DannyFGitHub/COVID-19PneumoCheckApp.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-DenseMobileNet: A Robust Framework for Lung Nodule Classification
  using Self-ONN and Stacking-based Meta-Classifier 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md. Sohanur Rahman, Muhammad E. H. Chowdhury, Hasib Ryan Rahman, Mosabber Uddin Ahmed, Muhammad Ashad Kabir, Sanjiban Sekhar Roy, Rusab Sarmun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we propose a novel and robust framework, Self-DenseMobileNet,
designed to enhance the classification of nodules and non-nodules in chest
radiographs (CXRs). Our approach integrates advanced image standardization and
enhancement techniques to optimize the input quality, thereby improving
classification accuracy. To enhance predictive accuracy and leverage the
strengths of multiple models, the prediction probabilities from
Self-DenseMobileNet were transformed into tabular data and used to train eight
classical machine learning (ML) models; the top three performers were then
combined via a stacking algorithm, creating a robust meta-classifier that
integrates their collective insights for superior classification performance.
To enhance the interpretability of our results, we employed class activation
mapping (CAM) to visualize the decision-making process of the best-performing
model. Our proposed framework demonstrated remarkable performance on internal
validation data, achieving an accuracy of 99.28\% using a Meta-Random Forest
Classifier. When tested on an external dataset, the framework maintained strong
generalizability with an accuracy of 89.40\%. These results highlight a
significant improvement in the classification of CXRs with lung nodules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Role of Activation Functions in EEG-To-Text Decoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12572v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12572v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zenon Lamprou, Iakovos Tenedios, Yashar Moshfeghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, much interdisciplinary research has been conducted exploring
potential use cases of neuroscience to advance the field of information
retrieval. Initial research concentrated on the use of fMRI data, but fMRI was
deemed to be not suitable for real-world applications, and soon, research
shifted towards using EEG data. In this paper, we try to improve the original
performance of a first attempt at generating text using EEG by focusing on the
less explored area of optimising neural network performance. We test a set of
different activation functions and compare their performance. Our results show
that introducing a higher degree polynomial activation function can enhance
model performance without changing the model architecture. We also show that
the learnable 3rd-degree activation function performs better on the 1-gram
evaluation compared to a 3rd-degree non-learnable function. However, when
evaluating the model on 2-grams and above, the polynomial function lacks in
performance, whilst the leaky ReLU activation function outperforms the
baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Step Diffusion via Shortcut Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Frans, Danijar Hafner, Sergey Levine, Pieter Abbeel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models and flow-matching models have enabled generating diverse and
realistic images by learning to transfer noise to data. However, sampling from
these models involves iterative denoising over many neural network passes,
making generation slow and expensive. Previous approaches for speeding up
sampling require complex training regimes, such as multiple training phases,
multiple networks, or fragile scheduling. We introduce shortcut models, a
family of generative models that use a single network and training phase to
produce high-quality samples in a single or multiple sampling steps. Shortcut
models condition the network not only on the current noise level but also on
the desired step size, allowing the model to skip ahead in the generation
process. Across a wide range of sampling step budgets, shortcut models
consistently produce higher quality samples than previous approaches, such as
consistency models and reflow. Compared to distillation, shortcut models reduce
complexity to a single network and training phase and additionally allow
varying step budgets at inference time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating Sensitive Directions in <span class="highlight-title">GPT</span>-2: An Improved Baseline and
  Comparative Analysis of SAEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel J. Lee, Stefan Heimersheim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sensitive directions experiments attempt to understand the computational
features of Language Models (LMs) by measuring how much the next token
prediction probabilities change by perturbing activations along specific
directions. We extend the sensitive directions work by introducing an improved
baseline for perturbation directions. We demonstrate that KL divergence for
Sparse Autoencoder (SAE) reconstruction errors are no longer pathologically
high compared to the improved baseline. We also show that feature directions
uncovered by SAEs have varying impacts on model outputs depending on the SAE's
sparsity, with lower L0 SAE feature directions exerting a greater influence.
Additionally, we find that end-to-end SAE features do not exhibit stronger
effects on model outputs compared to traditional SAEs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Utility of Memory Efficient Medical Image Generation: A Study
  on Lung Nodule Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kathrin Khadra, Utku Türkbey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scarcity of publicly available medical imaging data limits the
development of effective AI models. This work proposes a memory-efficient
patch-wise denoising diffusion probabilistic model (DDPM) for generating
synthetic medical images, focusing on CT scans with lung nodules. Our approach
generates high-utility synthetic images with nodule segmentation while
efficiently managing memory constraints, enabling the creation of training
datasets. We evaluate the method in two scenarios: training a segmentation
model exclusively on synthetic data, and augmenting real-world training data
with synthetic images. In the first case, models trained solely on synthetic
data achieve Dice scores comparable to those trained on real-world data
benchmarks. In the second case, augmenting real-world data with synthetic
images significantly improves segmentation performance. The generated images
demonstrate their potential to enhance medical image datasets in scenarios with
limited real-world data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Complex Query Answering Really Complex? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cosimo Gregucci, Bo Xiong, Daniel Hernandez, Lorenzo Loconte, Pasquale Minervini, Steffen Staab, Antonio Vergari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum
as a challenging reasoning task. In this paper, we show that the current
benchmarks for CQA are not really complex, and the way they are built distorts
our perception of progress in this field. For example, we find that in these
benchmarks, most queries (up to 98% for some query types) can be reduced to
simpler problems, e.g., link prediction, where only one link needs to be
predicted. The performance of state-of-the-art CQA models drops significantly
when such models are evaluated on queries that cannot be reduced to easier
types. Thus, we propose a set of more challenging benchmarks, composed of
queries that require models to reason over multiple hops and better reflect the
construction of real-world KGs. In a systematic empirical investigation, the
new benchmarks show that current methods leave much to be desired from current
CQA methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SiFiSinger: A High-Fidelity End-to-End Singing Voice Synthesizer based
  on Source-filter Model <span class="chip">ICASSP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12536v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12536v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianwei Cui, Yu Gu, Chao Weng, Jie Zhang, Liping Chen, Lirong Dai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an advanced end-to-end singing voice synthesis (SVS)
system based on the source-filter mechanism that directly translates lyrical
and melodic cues into expressive and high-fidelity human-like singing.
Similarly to VISinger 2, the proposed system also utilizes training paradigms
evolved from VITS and incorporates elements like the fundamental pitch (F0)
predictor and waveform generation decoder. To address the issue that the
coupling of mel-spectrogram features with F0 information may introduce errors
during F0 prediction, we consider two strategies. Firstly, we leverage
mel-cepstrum (mcep) features to decouple the intertwined mel-spectrogram and F0
characteristics. Secondly, inspired by the neural source-filter models, we
introduce source excitation signals as the representation of F0 in the SVS
system, aiming to capture pitch nuances more accurately. Meanwhile,
differentiable mcep and F0 losses are employed as the waveform decoder
supervision to fortify the prediction accuracy of speech envelope and pitch in
the generated speech. Experiments on the Opencpop dataset demonstrate efficacy
of the proposed model in synthesis quality and intonation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICASSP 2024, Synthesized audio samples are available at:
  https://sounddemos.github.io/sifisinger</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling data distribution for Federated Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyuan Zhao, Hanlin Gu, Lixin Fan, Qiang Yang, Yuxing Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Learning (FL) facilitates collaborative training of a global model
whose performance is boosted by private data owned by distributed clients,
without compromising data privacy. Yet the wide applicability of FL is hindered
by entanglement of data distributions across different clients. This paper
demonstrates for the first time that by disentangling data distributions FL can
in principle achieve efficiencies comparable to those of distributed systems,
requiring only one round of communication. To this end, we propose a novel
FedDistr algorithm, which employs stable diffusion models to decouple and
recover data distributions. Empirical results on the CIFAR100 and DomainNet
datasets show that FedDistr significantly enhances model utility and efficiency
in both disentangled and near-disentangled scenarios while ensuring privacy,
outperforming traditional federated learning methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MING: A Functional Approach to Learning Molecular Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Van Khoa Nguyen, Maciej Falkiewicz, Giangiacomo Mercatali, Alexandros Kalousis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional molecule generation methods often rely on sequence or graph-based
representations, which can limit their expressive power or require complex
permutation-equivariant architectures. This paper introduces a novel paradigm
for learning molecule generative models based on functional representations.
Specifically, we propose Molecular Implicit Neural Generation (MING), a
diffusion-based model that learns molecular distributions in function space.
Unlike standard diffusion processes in data space, MING employs a novel
functional denoising probabilistic process, which jointly denoises the
information in both the function's input and output spaces by leveraging an
expectation-maximization procedure for latent implicit neural representations
of data. This approach allows for a simple yet effective model design that
accurately captures underlying function distributions. Experimental results on
molecule-related datasets demonstrate MING's superior performance and ability
to generate plausible molecular samples, surpassing state-of-the-art data-space
methods while offering a more streamlined architecture and significantly faster
generation times.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ End-to-end Planner Training for Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathan Cornille, Florian Mai, Jingyuan Sun, Marie-Francine Moens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Through end-to-end training to predict the next token, LLMs have become
valuable tools for various tasks. Enhancing their core training in language
modeling can improve numerous downstream applications. A successful approach to
enhance language modeling uses a separate planning module to predict abstract
labels of future sentences and conditions the LM on these predictions. However,
this method is non-differentiable, preventing joint end-to-end tuning of the
planner with the LM. We propose an effective method to improve this approach by
enabling joint fine-tuning of the planner and the LM. We show that a naive way
of approximating the gradient of selecting a label via the straight-through
estimator is not effective. Instead, we propose to use the predicted label
probabilities as mixing weights to condition the LM on a weighted average of
label embeddings in a differentiable manner. This not only enables joint
fine-tuning of the planner and the LM, but also allows the LM to draw on the
full label distribution predicted by the planner, retaining more information.
Our experimental results show consistent improvements in perplexity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data-Driven Gyroscope Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12485v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12485v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeev Yampolsky, Itzik Klein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gyroscopes are inertial sensors that measure the angular velocity of the
platforms to which they are attached. To estimate the gyroscope deterministic
error terms prior mission start, a calibration procedure is performed. When
considering low-cost gyroscopes, the calibration requires a turntable as the
gyros are incapable of sensing the Earth turn rate. In this paper, we propose a
data-driven framework to estimate the scale factor and bias of a gyroscope. To
train and validate our approach, a dataset of 56 minutes was recorded using a
turntable. We demonstrated that our proposed approach outperforms the
model-based approach, in terms of accuracy and convergence time. Specifically,
we improved the scale factor and bias estimation by an average of 72% during
six seconds of calibration time, demonstrating an average of 75% calibration
time improvement. That is, instead of minutes, our approach requires only
several seconds for the calibration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 Pages, 5 Figures, 3 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and
  Hindsight Relabeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loris Gaven, Clement Romac, Thomas Carta, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The past years have seen Large Language Models (LLMs) strive not only as
generative models but also as agents solving textual sequential decision-making
tasks. When facing complex environments where their zero-shot abilities are
insufficient, recent work showed online Reinforcement Learning (RL) could be
used for the LLM agent to discover and learn efficient strategies
interactively. However, most prior work sticks to on-policy algorithms, which
greatly reduces the scope of methods such agents could use for both exploration
and exploitation, such as experience replay and hindsight relabeling. Yet, such
methods may be key for LLM learning agents, and in particular when designing
autonomous intrinsically motivated agents sampling and pursuing their own goals
(i.e. autotelic agents). This paper presents and studies an adaptation of Soft
Actor-Critic and hindsight relabeling to LLM agents. Our method not only paves
the path towards autotelic LLM agents that learn online but can also outperform
on-policy methods in more classic multi-goal RL environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KcMF: A Knowledge-compliant Framework for Schema and Entity Matching
  with Fine-tuning-free LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongqin Xu, Huan Li, Ke Chen, Lidan Shou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Schema and entity matching tasks are crucial for data integration and
management. While large language models (LLMs) have shown promising results in
these tasks, they suffer from hallucinations and confusion about task
instructions. In this paper, we present the Knowledge-Compliant Matching
Framework (KcMF), an LLM-based approach that addresses these issues without the
need for domain-specific fine-tuning. KcMF employs a pseudo-code-based task
decomposition strategy to adopt task-specific natural language statements that
guide LLM reasoning and reduce confusion. We also propose two mechanisms,
Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build domain
knowledge sets when unstructured domain knowledge is lacking. Additionally, we
introduce a result-ensembling strategy to leverage multiple knowledge sources
and suppress poorly formatted outputs. Comprehensive evaluations on schema and
entity matching tasks demonstrate that KcMF outperforms previous non-LLM
state-of-the-art (SOTA) methods by an average F1 score of 22.9% and competes
effectively with SOTA fine-tuned LLMs. Moreover, KcMF generalizes well across
different LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zerui Xu, Fang Wu, Tianfan Fu, Yue Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning (ML) exhibits promise in the clinical domain. However, it is
constrained by data scarcity and ethical considerations, as the generation of
clinical trials presents significant challenges due to stringent privacy
regulations, high costs, and the extended duration required for conducting
studies with human participants. Despite the advancements of large language
models (LLMs) in general generation tasks, their potential in facilitating the
generation of synthetic clinical trials is under-explored. To address this gap,
we introduce a novel Retrieval-Reasoning few-shot framework that leverages LLMs
to generate artificial yet realistic and diverse clinical trials with binary
success/failure labels. Experiments conducted on real clinical trials from the
\url{ClinicalTrials.gov} database demonstrate that our synthetic data can
effectively augment real datasets. Furthermore, by fine-tuning a pre-trained
model as a binary classifier on synthetic clinical trial datasets, we
demonstrate that this augmentation enhances model training for downstream tasks
such as trial outcome prediction. Our findings suggest that LLMs for synthetic
clinical trial generation hold promise for accelerating clinical research and
upholding ethical standards for patient privacy. The code is publicly available
at
https://anonymous.4open.science/r/Retrieval_Reasoning_Clinical_Trial_Generation-3EC4.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Gap Between Prototypes and Images in Cross-domain Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongduan Tian, Feng Liu, Zhanke Zhou, Tongliang Liu, Chengqi Zhang, Bo Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In cross-domain few-shot classification (CFC), recent works mainly focus on
adapting a simple transformation head on top of a frozen pre-trained backbone
with few labeled data to project embeddings into a task-specific metric space
where classification can be performed by measuring similarities between image
instance and prototype representations. Technically, an assumption implicitly
adopted in such a framework is that the prototype and image instance embeddings
share the same representation transformation. However, in this paper, we find
that there naturally exists a gap, which resembles the modality gap, between
the prototype and image instance embeddings extracted from the frozen
pre-trained backbone, and simply applying the same transformation during the
adaptation phase constrains exploring the optimal representations and shrinks
the gap between prototype and image representations. To solve this problem, we
propose a simple yet effective method, contrastive prototype-image adaptation
(CoPA), to adapt different transformations respectively for prototypes and
images similarly to CLIP by treating prototypes as text prompts. Extensive
experiments on Meta-Dataset demonstrate that CoPA achieves the state-of-the-art
performance more efficiently. Meanwhile, further analyses also indicate that
CoPA can learn better representation clusters, enlarge the gap, and achieve
minimal validation loss at the enlarged gap.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Challenges, Methods, Data -- a <span class="highlight-title">Survey</span> of Machine Learning in Water
  Distribution Networks <span class="chip">ICANN 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12461v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12461v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Valerie Vaquet, Fabian Hinder, André Artelt, Inaam Ashraf, Janine Strotherm, Jonas Vaquet, Johannes Brinkrolf, Barbara Hammer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on methods for planning and controlling water distribution networks
gains increasing relevance as the availability of drinking water will decrease
as a consequence of climate change. So far, the majority of approaches is based
on hydraulics and engineering expertise. However, with the increasing
availability of sensors, machine learning techniques constitute a promising
tool. This work presents the main tasks in water distribution networks,
discusses how they relate to machine learning and analyses how the
particularities of the domain pose challenges to and can be leveraged by
machine learning approaches. Besides, it provides a technical toolkit by
presenting evaluation benchmarks and a structured survey of the exemplary task
of leakage detection and localization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This preprint has not undergone any post-submission improvements or
  corrections. The Version of Record of this contribution is published in
  Artificial Neural Networks and Machine Learning -- ICANN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HELM: Hierarchical Encoding for mRNA Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12459v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12459v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehdi Yazdani-Jahromi, Mangal Prakash, Tommaso Mansi, Artem Moskalev, Rui Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its
codon structure directly impacting biological properties. While Language Models
(LMs) have shown promise in analyzing biological sequences, existing approaches
fail to account for the hierarchical nature of mRNA's codon structure. We
introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel
pre-training strategy that incorporates codon-level hierarchical structure into
language model training. HELM modulates the loss function based on codon
synonymity, aligning the model's learning process with the biological reality
of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks,
demonstrating that HELM outperforms standard language model pre-training as
well as existing foundation model baselines on six diverse downstream property
prediction tasks and an antibody region annotation tasks on average by around
8\%. Additionally, HELM enhances the generative capabilities of language model,
producing diverse mRNA sequences that better align with the underlying true
data distribution compared to non-hierarchical baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sharpness-Aware Black-Box Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feiyang Ye, Yueming Lyu, Xuehao Wang, Masashi Sugiyama, Yu Zhang, Ivor Tsang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Black-box optimization algorithms have been widely used in various machine
learning problems, including reinforcement learning and prompt fine-tuning.
However, directly optimizing the training loss value, as commonly done in
existing black-box optimization methods, could lead to suboptimal model quality
and generalization performance. To address those problems in black-box
optimization, we propose a novel Sharpness-Aware Black-box Optimization (SABO)
algorithm, which applies a sharpness-aware minimization strategy to improve the
model generalization. Specifically, the proposed SABO method first
reparameterizes the objective function by its expectation over a Gaussian
distribution. Then it iteratively updates the parameterized distribution by
approximated stochastic gradients of the maximum objective value within a small
neighborhood around the current solution in the Gaussian distribution space.
Theoretically, we prove the convergence rate and generalization bound of the
proposed SABO algorithm. Empirically, extensive experiments on the black-box
prompt fine-tuning tasks demonstrate the effectiveness of the proposed SABO
method in improving model generalization performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training Neural Samplers with Reverse Diffusive KL Divergence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12456v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12456v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajun He, Wenlin Chen, Mingtian Zhang, David Barber, José Miguel Hernández-Lobato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training generative models to sample from unnormalized density functions is
an important and challenging task in machine learning. Traditional training
methods often rely on the reverse Kullback-Leibler (KL) divergence due to its
tractability. However, the mode-seeking behavior of reverse KL hinders
effective approximation of multi-modal target distributions. To address this,
we propose to minimize the reverse KL along diffusion trajectories of both
model and target densities. We refer to this objective as the reverse diffusive
KL divergence, which allows the model to capture multiple modes. Leveraging
this objective, we train neural samplers that can efficiently generate samples
from the target distribution in one step. We demonstrate that our method
enhances sampling performance across various Boltzmann distributions, including
both synthetic multi-modal densities and n-body particle systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures, 3 tables, 1 algorithm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Loss Landscape Characterization of Neural Networks without
  Over-Parametrziation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rustem Islamov, Niccolò Ajroldi, Antonio Orvieto, Aurelien Lucchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimization methods play a crucial role in modern machine learning, powering
the remarkable empirical achievements of deep learning models. These successes
are even more remarkable given the complex non-convex nature of the loss
landscape of these models. Yet, ensuring the convergence of optimization
methods requires specific structural conditions on the objective function that
are rarely satisfied in practice. One prominent example is the widely
recognized Polyak-Lojasiewicz (PL) inequality, which has gained considerable
attention in recent years. However, validating such assumptions for deep neural
networks entails substantial and often impractical levels of
over-parametrization. In order to address this limitation, we propose a novel
class of functions that can characterize the loss landscape of modern deep
models without requiring extensive over-parametrization and can also include
saddle points. Crucially, we prove that gradient-based optimizers possess
theoretical guarantees of convergence under this assumption. Finally, we
validate the soundness of our new function class through both theoretical
analysis and empirical experimentation across a diverse range of deep learning
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FairGLVQ: Fairness in Partition-Based Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Störck, Fabian Hinder, Johannes Brinkrolf, Benjamin Paassen, Valerie Vaquet, Barbara Hammer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fairness is an important objective throughout society. From the distribution
of limited goods such as education, over hiring and payment, to taxes,
legislation, and jurisprudence. Due to the increasing importance of machine
learning approaches in all areas of daily life including those related to
health, security, and equity, an increasing amount of research focuses on fair
machine learning. In this work, we focus on the fairness of partition- and
prototype-based models. The contribution of this work is twofold: 1) we develop
a general framework for fair machine learning of partition-based models that
does not depend on a specific fairness definition, and 2) we derive a fair
version of learning vector quantization (LVQ) as a specific instantiation. We
compare the resulting algorithm against other algorithms from the literature on
theoretical and real-world data showing its practical relevance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This preprint has not undergone any post-submission improvements or
  corrections. The Version of Record of this contribution is published in
  Advances in Self-Organizing Maps, Learning Vector Quantization, Interpretable
  Machine Learning, and Beyond</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reconstruction of Differentially Private Text Sanitization via Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12443v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12443v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differential privacy (DP) is the de facto privacy standard against privacy
leakage attacks, including many recently discovered ones against large language
models (LLMs). However, we discovered that LLMs could reconstruct the
altered/removed privacy from given DP-sanitized prompts. We propose two attacks
(black-box and white-box) based on the accessibility to LLMs and show that LLMs
could connect the pair of DP-sanitized text and the corresponding private
training data of LLMs by giving sample text pairs as instructions (in the
black-box attacks) or fine-tuning data (in the white-box attacks). To
illustrate our findings, we conduct comprehensive experiments on modern LLMs
(e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3,
Claude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used
datasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and
sentence-level DP. The experimental results show promising recovery rates,
e.g., the black-box attacks against the word-level DP over WikiMIA dataset gave
72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on
ChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study
indicates that these well-known LLMs have emerged as a new security risk for
existing DP text sanitization approaches in the current environment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ConLUX: Concept-Based Local Unified Explanations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhao Liu, Haonan Yu, Xin Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancements of various machine learning models, there is a
significant demand for model-agnostic explanation techniques, which can explain
these models across different architectures. Mainstream model-agnostic
explanation techniques generate local explanations based on basic features
(e.g., words for text models and (super-)pixels for image models). However,
these explanations often do not align with the decision-making processes of the
target models and end-users, resulting in explanations that are unfaithful and
difficult for users to understand. On the other hand, concept-based techniques
provide explanations based on high-level features (e.g., topics for text models
and objects for image models), but most are model-specific or require
additional pre-defined external concept knowledge. To address this limitation,
we propose \toolname, a general framework to provide concept-based local
explanations for any machine learning models. Our key insight is that we can
automatically extract high-level concepts from large pre-trained models, and
uniformly extend existing local model-agnostic techniques to provide unified
concept-based explanations. We have instantiated \toolname on four different
types of explanation techniques: LIME, Kernel SHAP, Anchor, and LORE, and
applied these techniques to text and image models. Our evaluation results
demonstrate that 1) compared to the vanilla versions, \toolname offers more
faithful explanations and makes them more understandable to users, and 2) by
offering multiple forms of explanations, \toolname outperforms state-of-the-art
concept-based explanation techniques specifically designed for text and image
models, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Approaching Metaheuristic Deep Learning Combos for Automated Data Mining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gustavo Assunção, Paulo Menezes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lack of data on which to perform experimentation is a recurring issue in many
areas of research, particularly in machine learning. The inability of most
automated data mining techniques to be generalized to all types of data is
inherently related with their dependency on those types which deems them
ineffective against anything slightly different. Meta-heuristics are algorithms
which attempt to optimize some solution independently of the type of data used,
whilst classifiers or neural networks focus on feature extrapolation and
dimensionality reduction to fit some model onto data arranged in a particular
way. These two algorithmic fields encompass a group of characteristics which
when combined are seemingly capable of achieving data mining regardless of how
it is arranged. To this end, this work proposes a means of combining
meta-heuristic methods with conventional classifiers and neural networks in
order to perform automated data mining. Experiments on the MNIST dataset for
handwritten digit recognition were performed and it was empirically observed
that using a ground truth labeled dataset's validation accuracy is inadequate
for correcting labels of other previously unseen data instances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tentative submission for data mining and knowledge discovery</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Perseus: Leveraging Common Data Patterns with Curriculum Learning for
  More Robust Graph Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12425v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12425v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiwen Xia, Huijun Wu, Duanyu Li, Min Xie, Ruibo Wang, Wenzhe Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) excel at handling graph data but remain
vulnerable to adversarial attacks. Existing defense methods typically rely on
assumptions like graph sparsity and homophily to either preprocess the graph or
guide structure learning. However, preprocessing methods often struggle to
accurately distinguish between normal edges and adversarial perturbations,
leading to suboptimal results due to the loss of valuable edge information.
Robust graph neural network models train directly on graph data affected by
adversarial perturbations, without preprocessing. This can cause the model to
get stuck in poor local optima, negatively affecting its performance. To
address these challenges, we propose Perseus, a novel adversarial defense
method based on curriculum learning. Perseus assesses edge difficulty using
global homophily and applies a curriculum learning strategy to adjust the
learning order, guiding the model to learn the full graph structure while
adaptively focusing on common data patterns. This approach mitigates the impact
of adversarial perturbations. Experiments show that models trained with Perseus
achieve superior performance and are significantly more robust to adversarial
attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Nonlinear bayesian tomography of ion temperature and velocity for
  Doppler coherence imaging spectroscopy in RT-1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12424v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12424v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenji Ueda, Masaki. Nishiura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel Bayesian tomography approach for Coherence Imaging
Spectroscopy (CIS) that simultaneously reconstructs ion temperature and
velocity distributions in plasmas. Utilizing nonlinear Gaussian Process
Tomography (GPT) with the Laplace approximation, we model prior distributions
of log-emissivity, temperature, and velocity as Gaussian processes. This
framework rigorously incorporates nonlinear effects and temperature
dependencies often neglected in conventional CIS tomography, enabling robust
reconstruction even in the region of high temperature and velocity. By applying
a log-Gaussian process, we also address issues like velocity divergence in
low-emissivity regions. Validated with phantom simulations and experimental
data from the RT-1 device, our method reveals detailed spatial structures of
ion temperature and toroidal ion flow characteristic of magnetospheric plasma.
This work significantly broadens the scope of CIS tomography, offering a robust
tool for plasma diagnostics and facilitating integration with complementary
measurement techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 page, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tracking Universal Features Through Fine-Tuning and Model Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12391v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12391v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niels Horn, Desmond Elliott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study how features emerge, disappear, and persist across models fine-tuned
on different domains of text. More specifically, we start from a base one-layer
Transformer language model that is trained on a combination of the BabyLM
corpus, and a collection of Python code from The Stack. This base model is
adapted to two new domains of text: TinyStories, and the Lua programming
language, respectively; and then these two models are merged using these two
models using spherical linear interpolation. Our exploration aims to provide
deeper insights into the stability and transformation of features across
typical transfer-learning scenarios using small-scale models and sparse
auto-encoders.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive and Stratified Subsampling Techniques for High Dimensional
  Non-Standard Data Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prateek Mittal, Jai Dalmotra, Joohi Chauhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the challenge of estimating high-dimensional parameters
in non-standard data environments, where traditional methods often falter due
to issues such as heavy-tailed distributions, data contamination, and dependent
observations. We propose robust subsampling techniques, specifically Adaptive
Importance Sampling (AIS) and Stratified Subsampling, designed to enhance the
reliability and efficiency of parameter estimation. Under some clearly outlined
conditions, we establish consistency and asymptotic normality for the proposed
estimators, providing non-asymptotic error bounds that quantify their
performance. Our theoretical foundations are complemented by controlled
experiments demonstrating the superiority of our methods over conventional
approaches. By bridging the gap between theory and practice, this work offers
significant contributions to robust statistical estimation, paving the way for
advancements in various applied domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Neural Scaling Laws for Time Series Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12360v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12360v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingren Yao, Chao-Han Huck Yang, Renhe Jiang, Yuxuan Liang, Ming Jin, Shirui Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling laws offer valuable insights into the design of time series
foundation models (TSFMs). However, previous research has largely focused on
the scaling laws of TSFMs for in-distribution (ID) data, leaving their
out-of-distribution (OOD) scaling behavior and the influence of model
architectures less explored. In this work, we examine two common TSFM
architectures, encoder-only and decoder-only Transformers, and investigate
their scaling behavior on both ID and OOD data. These models are trained and
evaluated across varying parameter counts, compute budgets, and dataset sizes.
Our experiments reveal that the log-likelihood loss of TSFMs exhibits similar
scaling behavior in both OOD and ID settings. We further compare the scaling
properties across different architectures, incorporating two state-of-the-art
TSFMs as case studies, showing that model architecture plays a significant role
in scaling. The encoder-only Transformers demonstrate better scalability than
the decoder-only Transformers, while the architectural enhancements in the two
advanced TSFMs primarily improve ID performance but reduce OOD scalability.
While scaling up TSFMs is expected to drive performance breakthroughs, the lack
of a comprehensive understanding of TSFM scaling laws has hindered the
development of a robust framework to guide model scaling. We fill this gap in
this work by synthesizing our findings and providing practical guidelines for
designing and scaling larger TSFMs with enhanced model capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Temporal Graph Clustering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Zihao Zhou, Xianghong Xu, Qian Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal graph clustering is a complex task that involves discovering
meaningful structures in dynamic graphs where relationships and entities change
over time. Existing methods typically require centralized data collection,
which poses significant privacy and communication challenges. In this work, we
introduce a novel Federated Temporal Graph Clustering (FTGC) framework that
enables decentralized training of graph neural networks (GNNs) across multiple
clients, ensuring data privacy throughout the process. Our approach
incorporates a temporal aggregation mechanism to effectively capture the
evolution of graph structures over time and a federated optimization strategy
to collaboratively learn high-quality clustering representations. By preserving
data privacy and reducing communication overhead, our framework achieves
competitive performance on temporal graph datasets, making it a promising
solution for privacy-sensitive, real-world applications involving dynamic data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MAX: Masked Autoencoder for X-ray Fluorescence in Geological
  Investigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12330v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12330v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        An-Sheng Lee, Yu-Wen Pao, Hsuan-Tien Lin, Sofia Ya Hsuan Liou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-training foundation models has become the de-facto procedure for deep
learning approaches, yet its application remains limited in the geological
studies, where in needs of the model transferability to break the shackle of
data scarcity. Here we target on the X-ray fluorescence (XRF) scanning data, a
standard high-resolution measurement in extensive scientific drilling projects.
We propose a scalable self-supervised learner, masked autoencoders on XRF
spectra (MAX), to pre-train a foundation model covering geological records from
multiple regions of the Pacific and Southern Ocean. In pre-training, we find
that masking a high proportion of the input spectrum (50\%) yields a nontrivial
and meaningful self-supervisory task. For downstream tasks, we select the
quantification of XRF spectra into two costly geochemical measurements,
CaCO$_3$ and total organic carbon, due to their importance in understanding the
paleo-oceanic carbon system. Our results show that MAX, requiring only
one-third of the data, outperforms models without pre-training in terms of
quantification accuracy. Additionally, the model's generalizability improves by
more than 60\% in zero-shot tests on new materials, with explainability further
ensuring its robustness. Thus, our approach offers a promising pathway to
overcome data scarcity in geological discovery by leveraging the
self-supervised foundation model and fast-acquired XRF scanning data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improved Anomaly Detection through Conditional Latent Space VAE
  Ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Åström, Alexandros Sopasakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel Conditional Latent space Variational Autoencoder (CL-VAE)
to perform improved pre-processing for anomaly detection on data with known
inlier classes and unknown outlier classes. This proposed variational
autoencoder (VAE) improves latent space separation by conditioning on
information within the data. The method fits a unique prior distribution to
each class in the dataset, effectively expanding the classic prior distribution
for VAEs to include a Gaussian mixture model. An ensemble of these VAEs are
merged in the latent spaces to form a group consensus that greatly improves the
accuracy of anomaly detection across data sets. Our approach is compared
against the capabilities of a typical VAE, a CNN, and a PCA, with regards AUC
for anomaly detection. The proposed model shows increased accuracy in anomaly
detection, achieving an AUC of 97.4% on the MNIST dataset compared to 95.7% for
the second best model. In addition, the CL-VAE shows increased benefits from
ensembling, a more interpretable latent space, and an increased ability to
learn patterns in complex data with limited model sizes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages of main article, 19 pages including references and appendix,
  4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisited Large Language Model for Time Series Analysis through Modality
  Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liangwei Nathan Zheng, Chang George Dong, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models have demonstrated impressive performance in many
pivotal web applications such as sensor data analysis. However, since LLMs are
not designed for time series tasks, simpler models like linear regressions can
often achieve comparable performance with far less complexity. In this study,
we perform extensive experiments to assess the effectiveness of applying LLMs
to key time series tasks, including forecasting, classification, imputation,
and anomaly detection. We compare the performance of LLMs against simpler
baseline models, such as single-layer linear models and randomly initialized
LLMs. Our results reveal that LLMs offer minimal advantages for these core time
series tasks and may even distort the temporal structure of the data. In
contrast, simpler models consistently outperform LLMs while requiring far fewer
parameters. Furthermore, we analyze existing reprogramming techniques and show,
through data manifold analysis, that these methods fail to effectively align
time series data with language and display pseudo-alignment behaviour in
embedding space. Our findings suggest that the performance of LLM-based methods
in time series tasks arises from the intrinsic characteristics and structure of
time series data, rather than any meaningful alignment with the language model
architecture.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TPFL: A Trustworthy Personalized Federated Learning Framework via
  Subjective Logic 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinqian Chen, Jihua Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning (FL) enables collaborative model training across
distributed clients while preserving data privacy. Despite its widespread
adoption, most FL approaches focusing solely on privacy protection fall short
in scenarios where trustworthiness is crucial, necessitating advancements in
secure training, dependable decision-making mechanisms, robustness on
corruptions, and enhanced performance with Non-IID data. To bridge this gap, we
introduce Trustworthy Personalized Federated Learning (TPFL) framework designed
for classification tasks via subjective logic in this paper. Specifically, TPFL
adopts a unique approach by employing subjective logic to construct federated
models, providing probabilistic decisions coupled with an assessment of
uncertainty rather than mere probability assignments. By incorporating a
trainable heterogeneity prior to the local training phase, TPFL effectively
mitigates the adverse effects of data heterogeneity. Model uncertainty and
instance uncertainty are further utilized to ensure the safety and reliability
of the training and inference stages. Through extensive experiments on widely
recognized federated learning benchmarks, we demonstrate that TPFL not only
achieves competitive performance compared with advanced methods but also
exhibits resilience against prevalent malicious attacks, robustness on domain
shifts, and reliability in high-stake scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 Pages with Appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in
  Frequency Domain 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fengpeng Li, Kemou Li, Haiwei Wu, Jinyu Tian, Jiantao Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To protect deep neural networks (DNNs) from adversarial attacks, adversarial
training (AT) is developed by incorporating adversarial examples (AEs) into
model training. Recent studies show that adversarial attacks disproportionately
impact the patterns within the phase of the sample's frequency spectrum --
typically containing crucial semantic information -- more than those in the
amplitude, resulting in the model's erroneous categorization of AEs. We find
that, by mixing the amplitude of training samples' frequency spectrum with
those of distractor images for AT, the model can be guided to focus on phase
patterns unaffected by adversarial perturbations. As a result, the model's
robustness can be improved. Unfortunately, it is still challenging to select
appropriate distractor images, which should mix the amplitude without affecting
the phase patterns. To this end, in this paper, we propose an optimized
Adversarial Amplitude Generator (AAG) to achieve a better tradeoff between
improving the model's robustness and retaining phase patterns. Based on this
generator, together with an efficient AE production procedure, we design a new
Dual Adversarial Training (DAT) strategy. Experiments on various datasets show
that our proposed DAT leads to significantly improved robustness against
diverse adversarial attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Continuous Pupillography: A Case for Visual Health Ecosystem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12303v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12303v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Usama Younus, Nirupam Roy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This article aims to cover pupillography, and its potential use in a number
of ophthalmological diagnostic applications in biomedical space. With the
ever-increasing incorporation of technology within our daily lives and an
ever-growing active research into smart devices and technologies, we try to
make a case for a health ecosystem that revolves around continuous eye
monitoring. We tend to summarize the design constraints & requirements for an
IoT-based continuous pupil detection system, with an attempt at developing a
pipeline for wearable pupillographic device, while comparing two compact
mini-camera modules currently available in the market. We use a light algorithm
that can be directly adopted to current micro-controllers, and share our
results for different lighting conditions, and scenarios. Lastly, we present
our findings, along with an analysis on the challenges faced and a way ahead
towards successfully building this ecosystem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Two Birds with One Stone: Multi-Task Semantic Communications Systems
  over Relay Channel 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12302v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12302v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Cao, Tong Wu, Zhiyong Chen, Yin Xu, Meixia Tao, Wenjun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel multi-task, multi-link relay semantic
communications (MTML-RSC) scheme that enables the destination node to
simultaneously perform image reconstruction and classification with one
transmission from the source node. In the MTML-RSC scheme, the source node
broadcasts a signal using semantic communications, and the relay node forwards
the signal to the destination. We analyze the coupling relationship between the
two tasks and the two links (source-to-relay and source-to-destination) and
design a semantic-focused forward method for the relay node, where it
selectively forwards only the semantics of the relevant class while ignoring
others. At the destination, the node combines signals from both the source node
and the relay node to perform classification, and then uses the classification
result to assist in decoding the signal from the relay node for image
reconstructing. Experimental results demonstrate that the proposed MTML-RSC
scheme achieves significant performance gains, e.g., $1.73$ dB improvement in
peak-signal-to-noise ratio (PSNR) for image reconstruction and increasing the
accuracy from $64.89\%$ to $70.31\%$ for classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>submitted to IEEE WCNC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conjunction Subspaces Test for Conformal and Selective Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zengyou He, Zerun Li, Junjie Dong, Xinying Liu, Mudi Jiang, Lianyu Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a new classifier, which integrates significance
testing results over different random subspaces to yield consensus p-values for
quantifying the uncertainty of classification decision. The null hypothesis is
that the test sample has no association with the target class on a randomly
chosen subspace, and hence the classification problem can be formulated as a
problem of testing for the conjunction of hypotheses. The proposed classifier
can be easily deployed for the purpose of conformal prediction and selective
classification with reject and refine options by simply thresholding the
consensus p-values. The theoretical analysis on the generalization error bound
of the proposed classifier is provided and empirical studies on real data sets
are conducted as well to demonstrate its effectiveness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Consistency Calibration: Improving Uncertainty Calibration via
  Consistency among Perturbed Neighbors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12295v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12295v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linwei Tao, Haolan Guo, Minjing Dong, Chang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Calibration is crucial in deep learning applications, especially in fields
like healthcare and autonomous driving, where accurate confidence estimates are
vital for decision-making. However, deep neural networks often suffer from
miscalibration, with reliability diagrams and Expected Calibration Error (ECE)
being the only standard perspective for evaluating calibration performance. In
this paper, we introduce the concept of consistency as an alternative
perspective on model calibration, inspired by uncertainty estimation literature
in large language models (LLMs). We highlight its advantages over the
traditional reliability-based view. Building on this concept, we propose a
post-hoc calibration method called Consistency Calibration (CC), which adjusts
confidence based on the model's consistency across perturbed inputs. CC is
particularly effective in locally uncertainty estimation, as it requires no
additional data samples or label information, instead generating input
perturbations directly from the source data. Moreover, we show that performing
perturbations at the logit level significantly improves computational
efficiency. We validate the effectiveness of CC through extensive comparisons
with various post-hoc and training-time calibration methods, demonstrating
state-of-the-art performance on standard datasets such as CIFAR-10, CIFAR-100,
and ImageNet, as well as on long-tailed datasets like ImageNet-LT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Scalable Exact Machine Unlearning Using Parameter-Efficient
  Fine-Tuning <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somnath Basu Roy Chowdhury, Krzysztof Choromanski, Arijit Sehanobish, Avinava Dubey, Snigdha Chaturvedi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine unlearning is the process of efficiently removing the influence of a
training data instance from a trained machine learning model without retraining
it from scratch. A popular subclass of unlearning approaches is exact machine
unlearning, which focuses on techniques that explicitly guarantee the removal
of the influence of a data instance from a model. Exact unlearning approaches
use a machine learning model in which individual components are trained on
disjoint subsets of the data. During deletion, exact unlearning approaches only
retrain the affected components rather than the entire model. While existing
approaches reduce retraining costs, it can still be expensive for an
organization to retrain a model component as it requires halting a system in
production, which leads to service failure and adversely impacts customers. To
address these challenges, we introduce an exact unlearning framework --
Sequence-aware Sharded Sliced Training (S3T), which is designed to enhance the
deletion capabilities of an exact unlearning system while minimizing the impact
on model's performance. At the core of S3T, we utilize a lightweight
parameter-efficient fine-tuning approach that enables parameter isolation by
sequentially training layers with disjoint data slices. This enables efficient
unlearning by simply deactivating the layers affected by data deletion.
Furthermore, to reduce the retraining cost and improve model performance, we
train the model on multiple data sequences, which allows S3T to handle an
increased number of deletion requests. Both theoretically and empirically, we
demonstrate that S3T attains superior deletion capabilities and enhanced
performance compared to baselines across a wide range of settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preliminary version accepted at the SafeGenAi Workshop, NeurIPS, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neural Algorithmic Reasoning with Multiple Correct Solutions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06953v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06953v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeno Kujawa, John Poole, Dobrik Georgiev, Danilo Numeroso, Pietro Liò
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms.
However, canonical implementations of NAR train neural networks to return only
a single solution, even when there are multiple correct solutions to a problem,
such as single-source shortest paths. For some applications, it is desirable to
recover more than one correct solution. To that end, we give the first method
for NAR with multiple solutions. We demonstrate our method on two classical
algorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeper
insight into two algorithms over a broader survey of algorithms. This method
involves generating appropriate training data as well as sampling and
validating solutions from model output. Each step of our method, which can
serve as a framework for neural algorithmic reasoning beyond the tasks
presented in this paper, might be of independent interest to the field and our
results represent the first attempt at this task in the NAR literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ cedar: Optimized and Unified Machine Learning Input Data Pipelines <span class="chip">VLDB</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.08895v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.08895v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mark Zhao, Emanuel Adamiak, Christos Kozyrakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The input data pipeline is an essential component of each machine learning
(ML) training job. It is responsible for reading massive amounts of training
data, processing batches of samples using complex transformations, and loading
them onto training nodes at low latency and high throughput. Performant input
data systems are becoming increasingly critical, driven by skyrocketing data
volumes and training throughput demands. Unfortunately, current input data
systems cannot fully leverage key performance optimizations, resulting in
hugely inefficient infrastructures that require significant resources - or
worse - underutilize expensive accelerators.
  To address these demands, we present cedar, an optimized and unified
programming framework for ML input data pipelines. cedar allows users to define
input data pipelines using composable operators that support arbitrary ML
frameworks and libraries. cedar introduces an extensible optimizer that
systematically applies a complex combination of optimizations (e.g.,
offloading, caching, prefetching, fusion, and reordering). It orchestrates
processing across a customizable set of local and distributed compute resources
in order to improve processing performance and efficiency, all without user
input. Across eight pipelines, cedar improves performance by up to 1.87x to
10.65x compared to state-of-the-art input data systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to PVLDB Volume 18</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adversarial Training of Two-Layer Polynomial and ReLU Activation
  Networks via Convex Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14033v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14033v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Kuelbs, Sanjay Lall, Mert Pilanci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training neural networks which are robust to adversarial attacks remains an
important problem in deep learning, especially as heavily overparameterized
models are adopted in safety-critical settings. Drawing from recent work which
reformulates the training problems for two-layer ReLU and polynomial activation
networks as convex programs, we devise a convex semidefinite program (SDP) for
adversarial training of two-layer polynomial activation networks and prove that
the convex SDP achieves the same globally optimal solution as its nonconvex
counterpart. The convex SDP is observed to improve robust test accuracy against
$\ell_\infty$ attacks relative to the original convex training formulation on
multiple datasets. Additionally, we present scalable implementations of
adversarial training for two-layer polynomial and ReLU networks which are
compatible with standard machine learning libraries and GPU acceleration.
Leveraging these implementations, we retrain the final two fully connected
layers of a Pre-Activation ResNet-18 model on the CIFAR-10 dataset with both
polynomial and ReLU activations. The two `robustified' models achieve
significantly higher robust test accuracies against $\ell_\infty$ attacks than
a Pre-Activation ResNet-18 model trained with sharpness-aware minimization,
demonstrating the practical utility of convex adversarial training on
large-scale problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 2 figures. Added a proof of the main theorem in the
  appendix. Expanded numerical results section. Added references</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An exactly solvable model for emergence and scaling laws in the
  multitask sparse parity problem <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17563v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17563v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yoonsoo Nam, Nayara Fonseca, Seok Hyeong Lee, Chris Mingard, Ard A. Louis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models can exhibit what appears to be a sudden ability to solve
a new problem as training time, training data, or model size increases, a
phenomenon known as emergence. In this paper, we present a framework where each
new ability (a skill) is represented as a basis function. We solve a simple
multi-linear model in this skill-basis, finding analytic expressions for the
emergence of new skills, as well as for scaling laws of the loss with training
time, data size, model size, and optimal compute. We compare our detailed
calculations to direct simulations of a two-layer neural network trained on
multitask sparse parity, where the tasks in the dataset are distributed
according to a power-law. Our simple model captures, using a single fit
parameter, the sigmoidal emergence of multiple new skills as training time,
data size or model size increases in the neural network.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NeurIPS 2024 Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Energy and Carbon Considerations of Fine-Tuning <span class="highlight-title">BERT</span> <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10267v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10267v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaorong Wang, Clara Na, Emma Strubell, Sorelle Friedler, Sasha Luccioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP
community, existing work quantifying energy costs and associated carbon
emissions has largely focused on language model pre-training. Although a single
pre-training run draws substantially more energy than fine-tuning, fine-tuning
is performed more frequently by many more individual actors, and thus must be
accounted for when considering the energy and carbon footprint of NLP. In order
to better characterize the role of fine-tuning in the landscape of energy and
carbon emissions in NLP, we perform a careful empirical study of the
computational costs of fine-tuning across tasks, datasets, hardware
infrastructure and measurement modalities. Our experimental results allow us to
place fine-tuning energy and carbon costs into perspective with respect to
pre-training and inference, and outline recommendations to NLP researchers and
practitioners who wish to improve their fine-tuning energy efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings; First two authors contributed equally; 12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preferential Normalizing Flows <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08710v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08710v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Petrus Mikkola, Luigi Acerbi, Arto Klami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Eliciting a high-dimensional probability distribution from an expert via
noisy judgments is notoriously challenging, yet useful for many applications,
such as prior elicitation and reward modeling. We introduce a method for
eliciting the expert's belief density as a normalizing flow based solely on
preferential questions such as comparing or ranking alternatives. This allows
eliciting in principle arbitrarily flexible densities, but flow estimation is
susceptible to the challenge of collapsing or diverging probability mass that
makes it difficult in practice. We tackle this problem by introducing a novel
functional prior for the flow, motivated by a decision-theoretic argument, and
show empirically that the belief density can be inferred as the function-space
maximum a posteriori estimate. We demonstrate our method by eliciting
multivariate belief densities of simulated experts, including the prior belief
of a general-purpose large language model over a real-world dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 18 figures, Accepted at NeurIPS2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Effective Horizon of Inverse Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.06541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.06541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqing Xu, Finale Doshi-Velez, David Hsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse reinforcement learning (IRL) algorithms often rely on (forward)
reinforcement learning or planning over a given time horizon to compute an
approximately optimal policy for a hypothesized reward function and then match
this policy with expert demonstrations. The time horizon plays a critical role
in determining both the accuracy of reward estimates and the computational
efficiency of IRL algorithms. Interestingly, an \emph{effective time horizon}
shorter than the ground-truth value often produces better results faster. This
work formally analyzes this phenomenon and provides an explanation: the time
horizon controls the complexity of an induced policy class and mitigates
overfitting with limited data. This analysis serves as a guide for the
principled choice of the effective horizon for IRL. It also prompts us to
re-examine the classic IRL formulation: it is more natural to learn jointly the
reward and the effective horizon rather than the reward alone with a given
horizon. To validate our findings, we implement a cross-validation extension
and the experimental results confirm the theoretical analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Optimal Experimental Design for Parameter Estimation Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14003v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14003v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Shahriar Rahim Siddiqui, Arman Rahmim, Eldad Haber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimal experimental design is a well studied field in applied science and
engineering. Techniques for estimating such a design are commonly used within
the framework of parameter estimation. Nonetheless, in recent years parameter
estimation techniques are changing rapidly with the introduction of deep
learning techniques to replace traditional estimation methods. This in turn
requires the adaptation of optimal experimental design that is associated with
these new techniques. In this paper we investigate a new experimental design
methodology that uses deep learning. We show that the training of a network as
a Likelihood Free Estimator can be used to significantly simplify the design
process and circumvent the need for the computationally expensive bi-level
optimization problem that is inherent in optimal experimental design for
non-linear systems. Furthermore, deep design improves the quality of the
recovery process for parameter estimation problems. As proof of concept we
apply our methodology to two different systems of Ordinary Differential
Equations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Likelihood-based Differentiable Structure Learning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chang Deng, Kevin Bello, Pradeep Ravikumar, Bryon Aragam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing approaches to differentiable structure learning of directed acyclic
graphs (DAGs) rely on strong identifiability assumptions in order to guarantee
that global minimizers of the acyclicity-constrained optimization problem
identifies the true DAG. Moreover, it has been observed empirically that the
optimizer may exploit undesirable artifacts in the loss function. We explain
and remedy these issues by studying the behavior of differentiable
acyclicity-constrained programs under general likelihoods with multiple global
minimizers. By carefully regularizing the likelihood, it is possible to
identify the sparsest model in the Markov equivalence class, even in the
absence of an identifiable parametrization. We first study the Gaussian case in
detail, showing how proper regularization of the likelihood defines a score
that identifies the sparsest model. Assuming faithfulness, it also recovers the
Markov equivalence class. These results are then generalized to general models
and likelihoods, where the same claims hold. These theoretical results are
validated empirically, showing how this can be done using standard
gradient-based optimizers, thus paving the way for differentiable structure
learning under general models and losses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 14 figures, to appear at NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SplitLLM: Collaborative Inference of LLMs for Model Placement and
  Throughput Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10759v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10759v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akrit Mudvari, Yuang Jiang, Leandros Tassiulas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been a disruptive innovation in recent
years, and they play a crucial role in our daily lives due to their ability to
understand and generate human-like text. Their capabilities include natural
language understanding, information retrieval and search, translation,
chatbots, virtual assistance, and many more. However, it is well known that
LLMs are massive in terms of the number of parameters. Additionally, the
self-attention mechanism in the underlying architecture of LLMs, Transformers,
has quadratic complexity in terms of both computation and memory with respect
to the input sequence length. For these reasons, LLM inference is
resource-intensive, and thus, the throughput of LLM inference is limited,
especially for the longer sequences. In this report, we design a collaborative
inference architecture between a server and its clients to alleviate the
throughput limit. In this design, we consider the available resources on both
sides, i.e., the computation and communication costs. We develop a dynamic
programming-based algorithm to optimally allocate computation between the
server and the client device to increase the server throughput, while not
violating the service level agreement (SLA). We show in the experiments that we
are able to efficiently distribute the workload allowing for roughly 1/3
reduction in the server workload, while achieving 19 percent improvement over a
greedy method. As a result, we are able to demonstrate that, in an environment
with different types of LLM inference requests, the throughput of the server is
improved.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion Language Models Are Versatile Protein Learners <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18567v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18567v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces diffusion protein language model (DPLM), a versatile
protein language model that demonstrates strong generative and predictive
capabilities for protein sequences. We first pre-train scalable DPLMs from
evolutionary-scale protein sequences within a generative self-supervised
discrete diffusion probabilistic framework, which generalizes language modeling
for proteins in a principled way. After pre-training, DPLM exhibits the ability
to generate structurally plausible, novel, and diverse protein sequences for
unconditional generation. We further demonstrate the proposed diffusion
generative pre-training makes DPLM possess a better understanding of proteins,
making it a superior representation learner, which can be fine-tuned for
various predictive tasks, comparing favorably to ESM2 (Lin et al., 2022).
Moreover, DPLM can be tailored for various needs, which showcases its prowess
of conditional generation in several ways: (1) conditioning on partial peptide
sequences, e.g., generating scaffolds for functional motifs with high success
rate; (2) incorporating other modalities as conditioner, e.g.,
structure-conditioned generation for inverse folding; and (3) steering sequence
generation towards desired properties, e.g., satisfying specified secondary
structures, through a plug-and-play classifier guidance. Code is released at
\url{https://github.com/bytedance/dplm}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024 camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extreme time extrapolation capabilities and thermodynamic consistency of
  physics-inspired Neural Networks for the 3D microstructure evolution of
  materials via Cahn-Hilliard flow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.20126v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.20126v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniele Lanzoni, Andrea Fantasia, Roberto Bergamaschini, Olivier Pierre-Louis, Francesco Montalenti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce the
evolution of the spinodal decomposition process in three dimensions as
described by the Cahn-Hilliard equation. A specialized, physics-inspired
architecture is proven to provide close accordance between the predicted
evolutions and the ground truth ones obtained via conventional integration
schemes. The method can accurately reproduce the evolution of microstructures
not represented in the training set at a fraction of the computational costs.
Extremely long-time extrapolation capabilities are achieved, up to reaching the
theoretically expected equilibrium state of the system, consisting of a
layered, phase-separated morphology, despite the training set containing only
relatively-short, initial phases of the evolution. Quantitative accordance with
the decay rate of the Free energy is also demonstrated up to the late
coarsening stages, proving that this class of Machine Learning approaches can
become a new and powerful tool for the long timescale and high throughput
simulation of materials, while retaining thermodynamic consistency and
high-accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6 main text figures, 2 appendix figures, 1 supplementary
  material figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Source Conversational AI with SpeechBrain 1.0 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00463v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00463v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,
focused particularly on speech processing tasks such as speech recognition,
speech enhancement, speaker recognition, text-to-speech, and much more. It
promotes transparency and replicability by releasing both the pre-trained
models and the complete "recipes" of code and algorithms required for training
them. This paper presents SpeechBrain 1.0, a significant milestone in the
evolution of the toolkit, which now has over 200 recipes for speech, audio, and
language processing tasks, and more than 100 models available on Hugging Face.
SpeechBrain 1.0 introduces new technologies to support diverse learning
modalities, Large Language Model (LLM) integration, and advanced decoding
strategies, along with novel models, tasks, and modalities. It also includes a
new benchmark repository, offering researchers a unified platform for
evaluating models across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Journal of Machine Learning research (JMLR), Machine
  Learning Open Source Software</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nearly Tight Black-Box Auditing of Differentially Private Machine
  Learning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14106v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14106v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meenatchi Sundaram Muthu Selva Annamalai, Emiliano De Cristofaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an auditing procedure for the Differentially Private
Stochastic Gradient Descent (DP-SGD) algorithm in the black-box threat model
that is substantially tighter than prior work. The main intuition is to craft
worst-case initial model parameters, as DP-SGD's privacy analysis is agnostic
to the choice of the initial model parameters. For models trained on MNIST and
CIFAR-10 at theoretical $\varepsilon=10.0$, our auditing procedure yields
empirical estimates of $\varepsilon_{emp} = 7.21$ and $6.95$, respectively, on
a 1,000-record sample and $\varepsilon_{emp}= 6.48$ and $4.96$ on the full
datasets. By contrast, previous audits were only (relatively) tight in stronger
white-box models, where the adversary can access the model's inner parameters
and insert arbitrary gradients. Overall, our auditing procedure can offer
valuable insight into how the privacy analysis of DP-SGD could be improved and
detect bugs and DP violations in real-world implementations. The source code
needed to reproduce our experiments is available at
https://github.com/spalabucr/bb-audit-dpsgd.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in the Proceedings of the Thirty-eighth Annual Conference
  on Neural Information Processing Systems (NeurIPS 2024). Please cite
  accordingly</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task Aware Modulation using Representation Learning: An Approach for Few
  Shot Learning in Environmental Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.04727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.04727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arvind Renganathan, Rahul Ghosh, Ankush Khandelwal, Vipin Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce TAM-RL (Task Aware Modulation using Representation Learning), a
novel multimodal meta-learning framework for few-shot learning in heterogeneous
systems, designed for science and engineering problems where entities share a
common underlying forward model but exhibit heterogeneity due to
entity-specific characteristics. TAM-RL leverages an amortized training process
with a modulation network and a base network to learn task-specific modulation
parameters, enabling efficient adaptation to new tasks with limited data. We
evaluate TAM-RL on two real-world environmental datasets: Gross Primary Product
(GPP) prediction and streamflow forecasting, demonstrating significant
improvements over existing meta-learning methods. On the FLUXNET dataset,
TAM-RL improves RMSE by 18.9\% over MMAML with just one month of few-shot data,
while for streamflow prediction, it achieves an 8.21\% improvement with one
year of data. Synthetic data experiments further validate TAM-RL's superior
performance in heterogeneous task distributions, outperforming the baselines in
the most heterogeneous setting. Notably, TAM-RL offers substantial
computational efficiency, with at least 3x faster training times compared to
gradient-based meta-learning approaches while being much simpler to train due
to reduced complexity. Ablation studies highlight the importance of pretraining
and adaptation mechanisms in TAM-RL's performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncovering, Explaining, and Mitigating the Superficial Safety of
  Backdoor Defense <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09838v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09838v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Min, Zeyu Qin, Nevin L. Zhang, Li Shen, Minhao Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) as
they allow attackers to manipulate model predictions with backdoor triggers. To
address these security vulnerabilities, various backdoor purification methods
have been proposed to purify compromised models. Typically, these purified
models exhibit low Attack Success Rates (ASR), rendering them resistant to
backdoored inputs. However, Does achieving a low ASR through current safety
purification methods truly eliminate learned backdoor features from the
pretraining phase? In this paper, we provide an affirmative answer to this
question by thoroughly investigating the Post-Purification Robustness of
current backdoor purification methods. We find that current safety purification
methods are vulnerable to the rapid re-learning of backdoor behavior, even when
further fine-tuning of purified models is performed using a very small number
of poisoned samples. Based on this, we further propose the practical
Query-based Reactivation Attack (QRA) which could effectively reactivate the
backdoor by merely querying purified models. We find the failure to achieve
satisfactory post-purification robustness stems from the insufficient deviation
of purified models from the backdoored model along the backdoor-connected path.
To improve the post-purification robustness, we propose a straightforward
tuning defense, Path-Aware Minimization (PAM), which promotes deviation along
backdoor-connected paths with extra model updates. Extensive experiments
demonstrate that PAM significantly improves post-purification robustness while
maintaining a good clean accuracy and low ASR. Our work provides a new
perspective on understanding the effectiveness of backdoor safety tuning and
highlights the importance of faithfully assessing the model's safety.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024 Spotlight paper. The first two authors contributed
  equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pessimistic Backward Policy for GFlowNets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyosoon Jang, Yunhui Jang, Minsu Kim, Jinkyoo Park, Sungsoo Ahn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies Generative Flow Networks (GFlowNets), which learn to
sample objects proportionally to a given reward function through the trajectory
of state transitions. In this work, we observe that GFlowNets tend to
under-exploit the high-reward objects due to training on insufficient number of
trajectories, which may lead to a large gap between the estimated flow and the
(known) reward value. In response to this challenge, we propose a pessimistic
backward policy for GFlowNets (PBP-GFN), which maximizes the observed flow to
align closely with the true reward for the object. We extensively evaluate
PBP-GFN across eight benchmarks, including hyper-grid environment, bag
generation, structured set generation, molecular generation, and four RNA
sequence generation tasks. In particular, PBP-GFN enhances the discovery of
high-reward objects, maintains the diversity of the objects, and consistently
outperforms existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ITINERA: Integrating Spatial Optimization with Large Language Models for
  Open-domain Urban Itinerary Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07204v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07204v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Citywalk, a recently popular form of urban travel, requires genuine
personalization and understanding of fine-grained requests compared to
traditional itinerary planning. In this paper, we introduce the novel task of
Open-domain Urban Itinerary Planning (OUIP), which generates personalized urban
itineraries from user requests in natural language. We then present ITINERA, an
OUIP system that integrates spatial optimization with large language models to
provide customized urban itineraries based on user needs. This involves
decomposing user requests, selecting candidate points of interest (POIs),
ordering the POIs based on cluster-aware spatial optimization, and generating
the itinerary. Experiments on real-world datasets and the performance of the
deployed system demonstrate our system's capacity to deliver personalized and
spatially coherent itineraries compared to current solutions. Source codes of
ITINERA are available at https://github.com/YihongT/ITINERA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CELL your Model: Contrastive Explanations for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11785v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11785v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronny Luss, Erik Miehling, Amit Dhurandhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI,
such as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a scoring function that has meaning to the user and not necessarily a
specific real valued quantity (viz. class label). We offer two algorithms for
finding contrastive explanations: i) A myopic algorithm, which although
effective in creating contrasts, requires many model calls and ii) A budgeted
algorithm, our main algorithmic contribution, which intelligently creates
contrasts adhering to a query budget, necessary for longer contexts. We show
the efficacy of these methods on diverse natural language tasks such as
open-text generation, automated red teaming, and explaining conversational
degradation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Light-Weight Fault Tolerant Attention for Large Language Model Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11720v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11720v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable performance in
various natural language processing tasks. However, the training of these
models is computationally intensive and susceptible to faults, particularly in
the attention mechanism, which is a critical component of transformer-based
LLMs. In this paper, we investigate the impact of faults on LLM training,
focusing on INF, NaN, and near-INF values in the computation results with
systematic fault injection experiments. We observe the propagation patterns of
these errors, which can trigger non-trainable states in the model and disrupt
training, forcing the procedure to load from checkpoints. To mitigate the
impact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault
Tolerance (ABFT) technique tailored for the attention mechanism in LLMs.
ATTNChecker is designed based on fault propagation patterns of LLM and
incorporates performance optimization to adapt to both system reliability and
model vulnerability while providing lightweight protection for fast LLM
training. Evaluations on four LLMs show that ATTNChecker on average incurs on
average 7% overhead on training while detecting and correcting all extreme
errors. Compared with the state-of-the-art checkpoint/restore approach,
ATTNChecker reduces recovery overhead by up to 49x.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CECILIA: Comprehensive Secure Machine Learning Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2202.03023v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2202.03023v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Burak Ünal, Nico Pfeifer, Mete Akgün
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since ML algorithms have proven their success in many different applications,
there is also a big interest in privacy preserving (PP) ML methods for building
models on sensitive data. Moreover, the increase in the number of data sources
and the high computational power required by those algorithms force individuals
to outsource the training and/or the inference of a ML model to the clouds
providing such services. To address this, we propose a secure 3-party
computation framework, CECILIA, offering PP building blocks to enable complex
operations privately. In addition to the adapted and common operations like
addition and multiplication, it offers multiplexer, most significant bit and
modulus conversion. The first two are novel in terms of methodology and the
last one is novel in terms of both functionality and methodology. CECILIA also
has two complex novel methods, which are the exact exponential of a public base
raised to the power of a secret value and the inverse square root of a secret
Gram matrix. We use CECILIA to realize the private inference on pre-trained
RKNs, which require more complex operations than most other DNNs, on the
structural classification of proteins as the first study ever accomplishing the
PP inference on RKNs. In addition to the successful private computation of
basic building blocks, the results demonstrate that we perform the exact and
fully private exponential computation, which is done by approximation in the
literature so far. Moreover, they also show that we compute the exact inverse
square root of a secret Gram matrix up to a certain privacy level, which has
not been addressed in the literature at all. We also analyze the scalability of
CECILIA to various settings on a synthetic dataset. The framework shows a great
promise to make other ML algorithms as well as further computations privately
computable by the building blocks of the framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint version of "A privacy-preserving approach for cloud-based
  protein fold recognition" paper published in Patterns, ~8 pages of the main
  paper, ~5 pages of Supplement</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards aerodynamic surrogate modeling based on $β$-variational
  autoencoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.04969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.04969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Víctor Francés-Belda, Alberto Solera-Rico, Javier Nieto-Centenero, Esther Andrés, Carlos Sanmiguel Vila, Rodrigo Castellanos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surrogate models that combine dimensionality reduction and regression
techniques are essential to reduce the need for costly high-fidelity
computational fluid dynamics data. New approaches using $\beta$-Variational
Autoencoder ($\beta$-VAE) architectures have shown promise in obtaining
high-quality low-dimensional representations of high-dimensional flow data
while enabling physical interpretation of their latent spaces. We propose a
surrogate model based on latent space regression to predict pressure
distributions on a transonic wing given the flight conditions: Mach number and
angle of attack. The $\beta$-VAE model, enhanced with Principal Component
Analysis (PCA), maps high-dimensional data to a low-dimensional latent space,
showing a direct correlation with flight conditions. Regularization through
$\beta$ requires careful tuning to improve overall performance, while PCA
preprocessing helps to construct an effective latent space, improving
autoencoder training and performance. Gaussian Process Regression is used to
predict latent space variables from flight conditions, showing robust behavior
independent of $\beta$, and the decoder reconstructs the high-dimensional
pressure field data. This pipeline provides insight into unexplored flight
conditions. Furthermore, a fine-tuning process of the decoder further refines
the model, reducing the dependence on $\beta$ and enhancing accuracy.
Structured latent space, robust regression performance, and significant
improvements in fine-tuning collectively create a highly accurate and efficient
surrogate model. Our methodology demonstrates the effectiveness of $\beta$-VAEs
for aerodynamic surrogate modeling, offering a rapid, cost-effective, and
reliable alternative for aerodynamic data prediction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reward-Robust RLHF in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15360v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15360v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzi Yan, Xingzhou Lou, Jialian Li, Yiping Zhang, Jian Xie, Chao Yu, Yu Wang, Dong Yan, Yuan Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) continue to progress toward more advanced
forms of intelligence, Reinforcement Learning from Human Feedback (RLHF) is
increasingly seen as a key pathway toward achieving Artificial General
Intelligence (AGI). However, the reliance on reward-model-based (RM-based)
alignment methods introduces significant challenges due to the inherent
instability and imperfections of Reward Models (RMs), which can lead to
critical issues such as reward hacking and misalignment with human intentions.
In this paper, we introduce a reward-robust RLHF framework aimed at addressing
these fundamental challenges, paving the way for more reliable and resilient
learning in LLMs. Our approach introduces a novel optimization objective that
carefully balances performance and robustness by incorporating Bayesian Reward
Model Ensembles (BRME) to model the uncertainty set of reward functions. This
allows the framework to integrate both nominal performance and minimum reward
signals, ensuring more stable learning even with imperfect RMs. Empirical
results demonstrate that our framework consistently outperforms baselines
across diverse benchmarks, showing improved accuracy and long-term stability.
We also provide a theoretical analysis, demonstrating that reward-robust RLHF
approaches the stability of constant reward settings, which proves to be
acceptable even in a stochastic-case analysis. Together, these contributions
highlight the framework potential to enhance both the performance and stability
of LLM alignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Time-Varying Gaussian Process Bandits with Unknown Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01632v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01632v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juliusz Ziomek, Masaki Adachi, Michael A. Osborne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Bayesian optimisation requires fitting a Gaussian process model, which in
turn requires specifying prior on the unknown black-box function -- most of the
theoretical literature assumes this prior is known. However, it is common to
have more than one possible prior for a given black-box function, for example
suggested by domain experts with differing opinions. In some cases, the type-II
maximum likelihood estimator for selecting prior enjoys the consistency
guarantee, but it does not universally apply to all types of priors. If the
problem is stationary, one could rely on the Regret Balancing scheme to conduct
the optimisation, but in the case of time-varying problems, such a scheme
cannot be used. To address this gap in existing research, we propose a novel
algorithm, PE-GP-UCB, which is capable of solving time-varying Bayesian
optimisation problems even without the exact knowledge of the function's prior.
The algorithm relies on the fact that either the observed function values are
consistent with some of the priors, in which case it is easy to reject the
wrong priors, or the observations are consistent with all candidate priors, in
which case it does not matter which prior our model relies on. We provide a
regret bound on the proposed algorithm. Finally, we empirically evaluate our
algorithm on toy and real-world time-varying problems and show that it
outperforms the maximum likelihood estimator, fully Bayesian treatment of
unknown prior and Regret Balancing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Energy-Efficient Computation with DVFS using Deep Reinforcement Learning
  for Multi-Task Systems in Edge Computing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19434v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19434v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Li, Ti Zhou, Haoyu Wang, Man Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Periodic soft real-time systems have broad applications in many areas, such
as IoT. Finding an optimal energy-efficient policy that is adaptable to
underlying edge devices while meeting deadlines for tasks has always been
challenging. This research studies generalized systems with multi-task,
multi-deadline scenarios with reinforcement learning-based DVFS for energy
saving. This work addresses the limitation of previous work that models a
periodic system as a single task and single-deadline scenario, which is too
simplified to cope with complex situations. The method encodes time series
information in the Linux kernel into information that is easy to use for
reinforcement learning, allowing the system to generate DVFS policies to adapt
system patterns based on the general workload. For encoding, we present two
different methods for comparison. Both methods use only one performance
counter: system utilization and the kernel only needs minimal information from
the userspace. Our method is implemented on Jetson Nano Board (2GB) and is
tested with three fixed multitask workloads, which are three, five, and eight
tasks in the workload, respectively. For randomness and generalization, we also
designed a random workload generator to build different multitask workloads to
test. Based on the test results, our method could save 3%-10% power compared to
Linux built-in governors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReadMe++: Benchmarking Multilingual Language Models for Multi-Domain
  Readability Assessment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14463v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14463v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tarek Naous, Michael J. Ryan, Anton Lavrouk, Mohit Chandra, Wei Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a comprehensive evaluation of large language models for
multilingual readability assessment. Existing evaluation resources lack domain
and language diversity, limiting the ability for cross-domain and cross-lingual
analyses. This paper introduces ReadMe++, a multilingual multi-domain dataset
with human annotations of 9757 sentences in Arabic, English, French, Hindi, and
Russian, collected from 112 different data sources. This benchmark will
encourage research on developing robust multilingual readability assessment
methods. Using ReadMe++, we benchmark multilingual and monolingual language
models in the supervised, unsupervised, and few-shot prompting settings. The
domain and language diversity in ReadMe++ enable us to test more effective
few-shot prompting, and identify shortcomings in state-of-the-art unsupervised
methods. Our experiments also reveal exciting results of superior domain
generalization and enhanced cross-lingual transfer capabilities by models
trained on ReadMe++. We will make our data publicly available and release a
python package tool for multilingual sentence readability prediction using our
trained models at: https://github.com/tareknaous/readme
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Increasing Both Batch Size and Learning Rate Accelerates Stochastic
  Gradient Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08770v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08770v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hikaru Umeda, Hideaki Iiduka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of mini-batch stochastic gradient descent (SGD) strongly
depends on setting the batch size and learning rate to minimize the empirical
loss in training the deep neural network. In this paper, we present theoretical
analyses of mini-batch SGD with four schedulers: (i) constant batch size and
decaying learning rate scheduler, (ii) increasing batch size and decaying
learning rate scheduler, (iii) increasing batch size and increasing learning
rate scheduler, and (iv) increasing batch size and warm-up decaying learning
rate scheduler. We show that mini-batch SGD using scheduler (i) does not always
minimize the expectation of the full gradient norm of the empirical loss,
whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore,
schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides
numerical results of supporting analyses showing that using scheduler (iii) or
(iv) minimizes the full gradient norm of the empirical loss faster than using
scheduler (i) or (ii).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 18 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Explainable to Interpretable Deep Learning for Natural Language
  Processing in Healthcare: How Far from Reality? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.11894v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.11894v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangming Huang, Yingya Li, Shoaib Jameel, Yunfei Long, Giorgos Papanastasiou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning (DL) has substantially enhanced natural language processing
(NLP) in healthcare research. However, the increasing complexity of DL-based
NLP necessitates transparent model interpretability, or at least
explainability, for reliable decision-making. This work presents a thorough
scoping review of explainable and interpretable DL in healthcare NLP. The term
"eXplainable and Interpretable Artificial Intelligence" (XIAI) is introduced to
distinguish XAI from IAI. Different models are further categorized based on
their functionality (model-, input-, output-based) and scope (local, global).
Our analysis shows that attention mechanisms are the most prevalent emerging
IAI technique. The use of IAI is growing, distinguishing it from XAI. The major
challenges identified are that most XIAI does not explore "global" modelling
processes, the lack of best practices, and the lack of systematic evaluation
and benchmarks. One important opportunity is to use attention mechanisms to
enhance multi-modal XIAI for personalized medicine. Additionally, combining DL
with causal logic holds promise. Our discussion encourages the integration of
XIAI in Large Language Models (LLMs) and domain-specific smaller models. In
conclusion, XIAI adoption in healthcare requires dedicated in-house expertise.
Collaboration with domain experts, end-users, and policymakers can lead to
ready-to-use XIAI methods across NLP and medical tasks. While challenges exist,
XIAI techniques offer a valuable foundation for interpretable NLP algorithms in
healthcare.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by Computational and Structural
  Biotechnology Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram
  <span class="highlight-title">Dataset</span> of Over Half a Million Posts for Multilingual Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03293v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03293v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The work presented in this paper makes three scientific contributions with a
specific focus on mining and analysis of COVID-19-related posts on Instagram.
First, it presents a multilingual dataset of 500,153 Instagram posts about
COVID-19 published between January 2020 and September 2024. This dataset,
available at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in
161 different languages as well as 535,021 distinct hashtags. After the
development of this dataset, multilingual sentiment analysis was performed,
which involved classifying each post as positive, negative, or neutral. The
results of sentiment analysis are presented as a separate attribute in this
dataset. Second, it presents the results of performing sentiment analysis per
year from 2020 to 2024. The findings revealed the trends in sentiment related
to COVID-19 on Instagram since the beginning of the pandemic. For instance,
between 2020 and 2024, the sentiment trends show a notable shift, with positive
sentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from
44.19% to 58.34%. Finally, the paper also presents findings of
language-specific sentiment analysis. This analysis highlighted similar and
contrasting trends of sentiment across posts published in different languages
on Instagram. For instance, out of all English posts, 49.68% were positive,
14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts,
4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting
distinct differences in the sentiment distribution between these two languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic Token Reweighting for Interpretable and Controllable Text
  Embeddings in CLIP <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eunji Kim, Kyuhong Shim, Simyung Chang, Sungroh Yoon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A text encoder within Vision-Language Models (VLMs) like CLIP plays a crucial
role in translating textual input into an embedding space shared with images,
thereby facilitating the interpretative analysis of vision tasks through
natural language. Despite the varying significance of different textual
elements within a sentence depending on the context, efforts to account for
variation of importance in constructing text embeddings have been lacking. We
propose a framework of Semantic Token Reweighting to build Interpretable text
embeddings (SToRI), which incorporates controllability as well. SToRI refines
the text encoding process in CLIP by differentially weighting semantic elements
based on contextual importance, enabling finer control over emphasis responsive
to data-driven insights and user preferences. The efficacy of SToRI is
demonstrated through comprehensive experiments on few-shot image classification
and image retrieval tailored to user preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud
  Registration Algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Efimia Panagiotaki, Daniele De Martini, Lars Kunze, Petar Veličković
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the intersection of neural networks and classical
robotics algorithms through the Neural Algorithmic Reasoning (NAR) framework,
allowing to train neural networks to effectively reason like classical robotics
algorithms by learning to execute them. Algorithms are integral to robotics and
safety-critical applications due to their predictable and consistent
performance through logical and mathematical principles. In contrast, while
neural networks are highly adaptable, handling complex, high-dimensional data
and generalising across tasks, they often lack interpretability and
transparency in their internal computations. We propose a Graph Neural Network
(GNN)-based learning framework, NAR-*ICP, which learns the intermediate
algorithmic steps of classical ICP-based pointcloud registration algorithms,
and extend the CLRS Algorithmic Reasoning Benchmark with classical robotics
perception algorithms. We evaluate our approach across diverse datasets, from
real-world to synthetic, demonstrating its flexibility in handling complex and
noisy inputs, along with its potential to be used as part of a larger learning
system. Our results indicate that our method achieves superior performance
across all benchmarks and datasets, consistently surpassing even the algorithms
it has been trained on, further demonstrating its ability to generalise beyond
the capabilities of traditional algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TorchQL: A Programming Framework for Integrity Constraints in Machine
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.06686v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.06686v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaditya Naik, Adam Stein, Yinjun Wu, Mayur Naik, Eric Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Finding errors in machine learning applications requires a thorough
exploration of their behavior over data. Existing approaches used by
practitioners are often ad-hoc and lack the abstractions needed to scale this
process. We present TorchQL, a programming framework to evaluate and improve
the correctness of machine learning applications. TorchQL allows users to write
queries to specify and check integrity constraints over machine learning models
and datasets. It seamlessly integrates relational algebra with functional
programming to allow for highly expressive queries using only eight intuitive
operators. We evaluate TorchQL on diverse use-cases including finding critical
temporal inconsistencies in objects detected across video frames in autonomous
driving, finding data imputation errors in time-series medical records, finding
data labeling errors in real-world images, and evaluating biases and
constraining outputs of language models. Our experiments show that TorchQL
enables up to 13x faster query executions than baselines like Pandas and
MongoDB, and up to 40% shorter queries than native Python. We also conduct a
user study and find that TorchQL is natural enough for developers familiar with
Python to specify complex integrity constraints.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>DSI: <span class="highlight-title">Prompt</span>-based Rehearsal-free Instance-wise Incremental
  Learning for Document Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan-Luc Huynh, Thuy-Trang Vu, Weiqing Wang, Yinwei Wei, Trung Le, Dragan Gasevic, Yuan-Fang Li, Thanh-Toan Do
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiable Search Index (DSI) utilizes Pre-trained Language Models (PLMs)
for efficient document retrieval without relying on external indexes. However,
DSI needs full re-training to handle updates in dynamic corpora, causing
significant computational inefficiencies. We introduce PromptDSI, a
prompt-based rehearsal-free approach for instance-wise incremental learning
document retrieval. PromptDSI attaches prompts to the frozen PLM's encoder of
DSI, leveraging its powerful representation to efficiently index new corpora
while maintaining a balance between stability and plasticity. We eliminate the
initial forward pass of prompt-based continual learning methods that doubles
training and inference time. Moreover, we propose a topic-aware prompt pool
that employs neural topic embeddings as fixed keys. This strategy ensures
diverse and effective prompt usage, addressing the challenge of parameter
underutilization caused by the collapse of the query-key matching mechanism.
Our empirical evaluations demonstrate that BERT-based PromptDSI matches IncDSI
in managing forgetting while improving new corpora performance by more than 4%
Hits@10 on NQ320k and upto 3% MRR@10 on MS MARCO 300k.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Augmentation for Continual RL via Adversarial Gradient Episodic
  Memory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13452v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13452v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sihao Wu, Xingyu Zhao, Xiaowei Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data efficiency of learning, which plays a key role in the Reinforcement
Learning (RL) training process, becomes even more important in continual RL
with sequential environments. In continual RL, the learner interacts with
non-stationary, sequential tasks and is required to learn new tasks without
forgetting previous knowledge. However, there is little work on implementing
data augmentation for continual RL. In this paper, we investigate the efficacy
of data augmentation for continual RL. Specifically, we provide benchmarking
data augmentations for continual RL, by (1) summarising existing data
augmentation methods and (2) including a new augmentation method for continual
RL: Adversarial Augmentation with Gradient Episodic Memory (Adv-GEM). Extensive
experiments show that data augmentations, such as random amplitude scaling,
state-switch, mixup, adversarial augmentation, and Adv-GEM, can improve
existing continual RL algorithms in terms of their average performance,
catastrophic forgetting, and forward transfer, on robot control tasks. All data
augmentation methods are implemented as plug-in modules for trivial integration
into continual RL methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Structure Learning for Sparse Context-Specific Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07762v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07762v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Leopoldo Rios, Alex Markham, Liam Solus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Several approaches to graphically representing context-specific relations
among jointly distributed categorical variables have been proposed, along with
structure learning algorithms. While existing optimization-based methods have
limited scalability due to the large number of context-specific models, the
constraint-based methods are more prone to error than even constraint-based
directed acyclic graph learning algorithms since more relations must be tested.
We present an algorithm for learning context-specific models that scales to
hundreds of variables. Scalable learning is achieved through a combination of
an order-based Markov chain Monte-Carlo search and a novel, context-specific
sparsity assumption that is analogous to those typically invoked for directed
acyclic graphical models. Unlike previous Markov chain Monte-Carlo search
methods, our Markov chain is guaranteed to have the true posterior of the
variable orderings as the stationary distribution. To implement the method, we
solve a first case of an open problem recently posed by Alon and Balogh. Future
work solving increasingly general instances of this problem would allow our
methods to learn increasingly dense models. The method is shown to perform well
on synthetic data and real world examples, in terms of both accuracy and
scalability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 6 figures; for associated code, see
  https://cstrees.readthedocs.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL systems have become crucial for translating natural language into
SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, the Execution Accuracy
(EX), the most prevalent evaluation metric, still shows many false positives
and negatives. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our metric improves
agreement with human experts (from 62 to 87.04 in Cohen's kappa) with
comprehensive context and sophisticated criteria. Our extensive experiments
yield several key insights: (1) Models' performance increases by over 2.6
points on average, substantially affecting rankings on Spider and BIRD
benchmarks; (2) The underestimation of models in EX primarily stems from
annotation quality issues; and (3) Model performance on particularly
challenging questions tends to be overestimated. This work contributes to a
more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixture of Experts Made Personalized: Federated <span class="highlight-title">Prompt</span> Learning for
  Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10114v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10114v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Luo, Chen Chen, Shandong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning for pre-trained Vision-Language Models (VLMs) like CLIP has
demonstrated potent applicability across diverse downstream tasks. This
lightweight approach has quickly gained traction from federated learning (FL)
researchers who seek to efficiently adapt VLMs to heterogeneous scenarios.
However, current federated prompt learning methods are habitually restricted to
the traditional FL paradigm, where the participating clients are generally only
allowed to download a single globally aggregated model from the server. While
justifiable for training full-sized models under federated settings, in this
work, we argue that this paradigm is ill-suited for lightweight prompts. By
facilitating the clients to download multiple pre-aggregated prompts as fixed
non-local experts, we propose Personalized Federated Mixture of Adaptive
Prompts (pFedMoAP), a novel FL framework that personalizes the prompt learning
process through the lens of Mixture of Experts (MoE). pFedMoAP implements a
local attention-based gating network that learns to generate enhanced text
features for better alignment with local image data on the client, benefiting
from both local and downloaded non-local adaptive prompt experts. The non-local
experts are sparsely selected from a server-maintained pool, fostering
collaborative learning across clients. To evaluate the proposed algorithm, we
conduct extensive experiments across 9 datasets under various heterogeneous
federated settings. The results show that pFedMoAP consistently outperforms the
state-of-the-art alternatives, underscoring its efficacy in personalizing
prompt learning for CLIP within the federated learning paradigm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Causal Discovery under Latent Class Confounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07454v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07454v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bijan Mazaheri, Spencer Gordon, Yuval Rabani, Leonard Schulman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An acyclic causal structure can be described with directed acyclic graph
(DAG), where arrows indicate the possibility of direct causation. The task of
learning this structure from data is known as "causal discovery." Diverse
populations or changing environments can sometimes give rise to data that is
heterogeneous in the following sense: each population/environment is a "source"
which idiosyncratically determines the forms of those direct causal effects.
From this perspective, the source is a latent common cause for every observed
variable. While some methods for causal discovery are able to work around
latent confounding in special cases, especially when only few observables are
confounded, a global confounder is a difficult challenge. The only known ways
to deal with latent global confounding involve assumptions that limit the
structural equations and/or noise functions. We demonstrate that globally
confounded causal structures can still be identifiable with arbitrary
structural equations and noise functions, so long as the number of latent
classes remains small relative to the size and sparsity of the underlying DAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Parsimony or Capability? Decomposition Delivers Both in Long-term Time
  Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11929v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11929v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinliang Deng, Feiyang Ye, Du Yin, Xuan Song, Ivor W. Tsang, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-term time series forecasting (LTSF) represents a critical frontier in
time series analysis, characterized by extensive input sequences, as opposed to
the shorter spans typical of traditional approaches. While longer sequences
inherently offer richer information for enhanced predictive precision,
prevailing studies often respond by escalating model complexity. These
intricate models can inflate into millions of parameters, resulting in
prohibitive parameter scales. Our study demonstrates, through both analytical
and empirical evidence, that decomposition is key to containing excessive model
inflation while achieving uniformly superior and robust results across various
datasets. Remarkably, by tailoring decomposition to the intrinsic dynamics of
time series data, our proposed model outperforms existing benchmarks, using
over 99 \% fewer parameters than the majority of competing methods. Through
this work, we aim to unleash the power of a restricted set of parameters by
capitalizing on domain characteristics--a timely reminder that in the realm of
LTSF, bigger is not invariably better.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Interpret Your Decision: Logical Reasoning Regularization for
  Generalization in Visual Classification <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04492v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04492v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaorui Tan, Xi Yang, Qiufeng Wang, Anh Nguyen, Kaizhu Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision models excel in image classification but struggle to generalize to
unseen data, such as classifying images from unseen domains or discovering
novel categories. In this paper, we explore the relationship between logical
reasoning and deep learning generalization in visual classification. A logical
regularization termed L-Reg is derived which bridges a logical analysis
framework to image classification. Our work reveals that L-Reg reduces the
complexity of the model in terms of the feature distribution and classifier
weights. Specifically, we unveil the interpretability brought by L-Reg, as it
enables the model to extract the salient features, such as faces to persons,
for classification. Theoretical analysis and experiments demonstrate that L-Reg
enhances generalization across various scenarios, including multi-domain
generalization and generalized category discovery. In complex real-world
scenarios where images span unknown classes and unseen domains, L-Reg
consistently improves generalization, highlighting its practical efficacy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS2024 as Spotlight</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Token-based Decision Criteria Are Suboptimal in In-context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16535v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16535v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hakaze Cho, Yoshihiro Sakai, Mariko Kato, Kenshiro Tanaka, Akira Ishii, Naoya Inoue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-Context Learning (ICL) typically utilizes classification criteria from
output probabilities of manually selected label tokens. However, we argue that
such token-based classification criteria lead to suboptimal decision
boundaries, despite delicate calibrations through translation and constrained
rotation applied. To address this problem, we propose Hidden Calibration, which
renounces token probabilities and uses the nearest centroid classifier on the
LM's last hidden states. In detail, we assign the label of the nearest centroid
previously estimated from a calibration set to the test sample as the predicted
label. Our experiments on 6 models and 10 classification datasets indicate that
Hidden Calibration consistently outperforms current token-based baselines by
about 20%~50%, achieving a strong state-of-the-art in ICL. Our further analysis
demonstrates that Hidden Calibration finds better classification criteria with
less inter-class overlap, and LMs provide linearly separable intra-class
clusters with the help of demonstrations, which supports Hidden Calibration and
gives new insights into the principle of ICL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 15 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeltaDock: A Unified Framework for Accurate, Efficient, and Physically
  Reliable Molecular Docking <span class="chip">NeurIPS'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11224v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11224v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxian Yan, Zaixi Zhang, Jintao Zhu, Kai Zhang, Jianfeng Pei, Qi Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular docking, a technique for predicting ligand binding poses, is
crucial in structure-based drug design for understanding protein-ligand
interactions. Recent advancements in docking methods, particularly those
leveraging geometric deep learning (GDL), have demonstrated significant
efficiency and accuracy advantages over traditional sampling methods. Despite
these advancements, current methods are often tailored for specific docking
settings, and limitations such as the neglect of protein side-chain structures,
difficulties in handling large binding pockets, and challenges in predicting
physically valid structures exist. To accommodate various docking settings and
achieve accurate, efficient, and physically reliable docking, we propose a
novel two-stage docking framework, DeltaDock, consisting of pocket prediction
and site-specific docking. We innovatively reframe the pocket prediction task
as a pocket-ligand alignment problem rather than direct prediction in the first
stage. Then we follow a bi-level coarse-to-fine iterative refinement process to
perform site-specific docking. Comprehensive experiments demonstrate the
superior performance of DeltaDock. Notably, in the blind docking setting,
DeltaDock achieves a 31\% relative improvement over the docking success rate
compared with the previous state-of-the-art GDL model. With the consideration
of physical validity, this improvement increases to about 300\%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sharing to learn and learning to share; Fitting together Meta-Learning,
  Multi-Task Learning, and Transfer Learning: A meta <span class="highlight-title">review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2111.12146v8">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2111.12146v8.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Richa Upadhyay, Ronald Phlypo, Rajkumar Saini, Marcus Liwicki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Integrating knowledge across different domains is an essential feature of
human learning. Learning paradigms such as transfer learning, meta-learning,
and multi-task learning reflect the human learning process by exploiting the
prior knowledge for new tasks, encouraging faster learning and good
generalization for new tasks. This article gives a detailed view of these
learning paradigms and their comparative analysis. The weakness of one learning
algorithm turns out to be a strength of another, and thus, merging them is a
prevalent trait in the literature. Numerous research papers focus on each of
these learning paradigms separately and provide a comprehensive overview of
them. However, this article reviews research studies that combine (two of)
these learning algorithms. This survey describes how these techniques are
combined to solve problems in many different fields of research, including
computer vision, natural language processing, hyper-spectral imaging, and many
more, in a supervised setting only. Based on the knowledge accumulated from the
literature, we hypothesize a generic task-agnostic and model-agnostic learning
network - an ensemble of meta-learning, transfer learning, and multi-task
learning, termed Multi-modal Multi-task Meta Transfer Learning. We also present
some open research questions, limitations, and future research directions for
this proposed network. The aim of this article is to spark interest among
scholars in effectively merging existing learning algorithms with the intention
of advancing research in this field. Instead of presenting experimental
results, we invite readers to explore and contemplate techniques for merging
algorithms while navigating through their limitations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This article has been accepted for publication in IEEE Access. This
  is the author's version which has not been fully edited and content may
  slightly change prior to final publication. Citation information: DOI
  10.1109/ACCESS.2024.3478805</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mini-Omni2: Towards Open-source <span class="highlight-title">GPT</span>-4o with Vision, Speech and Duplex
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11190v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11190v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhifei Xie, Changqiao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  GPT-4o, an all-encompassing model, represents a milestone in the development
of large multi-modal language models. It can understand visual, auditory, and
textual modalities, directly output audio, and support flexible duplex
interaction. Models from the open-source community often achieve some
functionalities of GPT-4o, such as visual understanding and voice chat.
Nevertheless, training a unified model that incorporates all modalities is
challenging due to the complexities of multi-modal data, intricate model
architectures, and training processes. In this paper, we introduce Mini-Omni2,
a visual-audio assistant capable of providing real-time, end-to-end voice
responses to visoin and audio queries. By integrating pretrained visual and
auditory encoders, Mini-Omni2 maintains performance in individual modalities.
We propose a three-stage training process to align modalities, allowing the
language model to handle multi-modal inputs and outputs after training on a
limited dataset. For interaction, we introduce a command-based interruption
mechanism, enabling more flexible interaction with users. To the best of our
knowledge, Mini-Omni2 is one of the closest reproductions of GPT-4o, which have
similar form of functionality, and we hope it can offer valuable insights for
subsequent research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FedCCRL: Federated Domain Generalization with Cross-Client
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11267v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11267v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinpeng Wang, Xiaoying Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain Generalization (DG) aims to train models that can effectively
generalize to unseen domains. However, in the context of Federated Learning
(FL), where clients collaboratively train a model without directly sharing
their data, most existing DG algorithms are not directly applicable to the FL
setting due to privacy constraints, as well as the limited data quantity and
domain diversity at each client. To tackle these challenges, we propose
FedCCRL, a novel federated domain generalization method that significantly
improves the model's ability to generalize to unseen domains without
compromising privacy or incurring excessive computational and communication
costs. Specifically, we adapt MixStyle to the federated setting to transfer
domain-specific features while AugMix is employed to perturb domain-invariant
features. Furthermore, we leverage supervised contrastive loss for
representation alignment and utilize Jensen-Shannon divergence to ensure
consistent predictions between original and augmented samples. Extensive
experimental results demonstrate that FedCCRL achieves the state-of-the-art
performances on the PACS, OfficeHome and miniDomainNet datasets across varying
numbers of clients. Code is available at
https://github.com/SanphouWang/FedCCRL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixed-Precision Federated Learning via Multi-Precision Over-The-Air
  Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03402v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03402v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinsheng Yuan, Zhuangkun Wei, Weisi Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over-the-Air Federated Learning (OTA-FL) is a privacy-preserving distributed
learning mechanism, by aggregating updates in the electromagnetic channel
rather than at the server. A critical research gap in existing OTA-FL research
is the assumption of homogeneous client computational bit precision. While in
real world application, clients with varying hardware resources may exploit
approximate computing (AxC) to operate at different bit precisions optimized
for energy and computational efficiency. And model updates of various
precisions amongst clients poses an open challenge for OTA-FL, as it is
incompatible in the wireless modulation superposition. Here, we propose an
mixed-precision OTA-FL framework of clients with multiple bit precisions,
demonstrating the following innovations: (i) the superior trade-off for both
server and clients within the constraints of varying edge computing
capabilities, energy efficiency, and learning accuracy requirements comparing
to homogeneous client bit precision, and (ii) a multi-precision gradient
modulation scheme to ensure compatibility with OTA aggregation and eliminate
the overheads of precision conversion. Through case study with real world data,
we validate our modulation scheme that enables AxC based mixed-precision
OTA-FL. In comparison to homogeneous standard precision of 32-bit and 16-bit,
our framework presents more than 10% in 4-bit ultra low precision client
performance and over 65%and 13% of energy savings respectively. This
demonstrates the great potential of our mixed-precision OTA-FL approach in
heterogeneous edge computing environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to WCNC 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Parallel Momentum Methods Under Biased Gradient Estimations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.00853v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.00853v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parallel stochastic gradient methods are gaining prominence in solving
large-scale machine learning problems that involve data distributed across
multiple nodes. However, obtaining unbiased stochastic gradients, which have
been the focus of most theoretical research, is challenging in many distributed
machine learning applications. The gradient estimations easily become biased,
for example, when gradients are compressed or clipped, when data is shuffled,
and in meta-learning and reinforcement learning. In this work, we establish
worst-case bounds on parallel momentum methods under biased gradient estimation
on both general non-convex and $\mu$-PL problems. Our analysis covers general
distributed optimization problems, and we work out the implications for special
cases where gradient estimates are biased, i.e. in meta-learning and when the
gradients are compressed or clipped. Our numerical experiments verify our
theoretical findings and show faster convergence performance of momentum
methods than traditional biased gradient descent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reverse Stable Diffusion: What <span class="highlight-title">prompt</span> was used to generate this image? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.01472v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.01472v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image diffusion models have recently attracted the interest of many
researchers, and inverting the diffusion process can play an important role in
better understanding the generative process and how to engineer prompts in
order to obtain the desired images. To this end, we study the task of
predicting the prompt embedding given an image generated by a generative
diffusion model. We consider a series of white-box and black-box models (with
and without access to the weights of the diffusion network) to deal with the
proposed task. We propose a novel learning framework comprising a joint prompt
regression and multi-label vocabulary classification objective that generates
improved prompts. To further improve our method, we employ a curriculum
learning procedure that promotes the learning of image-prompt pairs with lower
labeling noise (i.e. that are better aligned). We conduct experiments on the
DiffusionDB data set, predicting text prompts from images generated by Stable
Diffusion. In addition, we make an interesting discovery: training a diffusion
model on the prompt generation task can make the model generate images that are
much better aligned with the input prompts, when the model is directly reused
for text-to-image generation. Our code is publicly available for download at
https://github.com/CroitoruAlin/Reverse-Stable-Diffusion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in Computer Vision and Image Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Instruction-Guided Visual Masking <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19783v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19783v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinliang Zheng, Jianxiong Li, Sijie Cheng, Yinan Zheng, Jiaming Li, Jihao Liu, Yu Liu, Jingjing Liu, Xianyuan Zhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction following is crucial in contemporary LLM. However, when extended
to multimodal setting, it often suffers from misalignment between specific
textual instruction and targeted local region of an image. To achieve more
accurate and nuanced multimodal instruction following, we introduce
Instruction-guided Visual Masking (IVM), a new versatile visual grounding model
that is compatible with diverse multimodal models, such as LMM and robot model.
By constructing visual masks for instruction-irrelevant regions, IVM-enhanced
multimodal models can effectively focus on task-relevant image regions to
better align with complex instructions. Specifically, we design a visual
masking data generation pipeline and create an IVM-Mix-1M dataset with 1
million image-instruction pairs. We further introduce a new learning technique,
Discriminator Weighted Supervised Learning (DWSL) for preferential IVM training
that prioritizes high-quality data samples. Experimental results on generic
multimodal tasks such as VQA and embodied robotic control demonstrate the
versatility of IVM, which as a plug-and-play tool, significantly boosts the
performance of diverse multimodal models, yielding new state-of-the-art results
across challenging multimodal benchmarks. Code, model and data are available at
https://github.com/2toinf/IVM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Collocation-based Robust Variational Physics-Informed Neural Networks
  (CRVPINN) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.02300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.02300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcin Łoś, Tomasz Służalec, Paweł Maczuga, Askold Vilkha, Carlos Uriarte, Maciej Paszyński
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Physics-Informed Neural Networks (PINNs) have been successfully applied to
solve Partial Differential Equations (PDEs). Their loss function is founded on
a strong residual minimization scheme. Variational Physics-Informed Neural
Networks (VPINNs) are their natural extension to weak variational settings. In
this context, the recent work of Robust Variational Physics-Informed Neural
Networks (RVPINNs) highlights the importance of conveniently translating the
norms of the underlying continuum-level spaces to the discrete level.
Otherwise, VPINNs might become unrobust, implying that residual minimization
might be highly uncorrelated with a desired minimization of the error in the
energy norm. However, applying this robustness to VPINNs typically entails
dealing with the inverse of a Gram matrix, usually producing slow convergence
speeds during training. In this work, we accelerate the implementation of
RVPINN, establishing a LU factorization of sparse Gram matrix in a kind of
point-collocation scheme with the same spirit as original PINNs. We call out
method the Collocation-based Robust Variational Physics Informed Neural
Networks (CRVPINN). We test our efficient CRVPINN algorithm on Laplace,
advection-diffusion, and Stokes problems in two spatial dimensions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Manifolds, Random Matrices and Spectral Gaps: The geometric phases of
  generative diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05898v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05898v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enrico Ventura, Beatrice Achilli, Gianluigi Silvestri, Carlo Lucibello, Luca Ambrogioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the latent geometry of generative diffusion
models under the manifold hypothesis. To this purpose, we analyze the spectrum
of eigenvalues (and singular values) of the Jacobian of the score function,
whose discontinuities (gaps) reveal the presence and dimensionality of distinct
sub-manifolds. Using a statistical physics approach, we derive the spectral
distributions and formulas for the spectral gaps under several distributional
assumptions and we compare these theoretical predictions with the spectra
estimated from trained networks. Our analysis reveals the existence of three
distinct qualitative phases during the generative process: a trivial phase; a
manifold coverage phase where the diffusion process fits the distribution
internal to the manifold; a consolidation phase where the score becomes
orthogonal to the manifold and all particles are projected on the support of
the data. This `division of labor' between different timescales provides an
elegant explanation on why generative diffusion models are not affected by the
manifold overfitting phenomenon that plagues likelihood-based models, since the
internal distribution and the manifold geometry are produced at different time
points during generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Search-Based Testing with Pareto Optimization Effectively Cover
  Failure-Revealing Test Inputs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11769v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11769v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lev Sorokin, Damir Safin, Shiva Nejati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search-based software testing (SBST) is a widely adopted technique for
testing complex systems with large input spaces, such as Deep Learning-enabled
(DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization,
where multiple objectives are optimized in parallel to reveal failures.
However, it is important to ensure that identified failures are spread
throughout the entire failure-inducing area of a search domain and not
clustered in a sub-region. This ensures that identified failures are
semantically diverse and reveal a wide range of underlying causes. In this
paper, we present a theoretical argument explaining why testing based on Pareto
optimization is inadequate for covering failure-inducing areas within a search
domain. We support our argument with empirical results obtained by applying two
widely used types of Pareto-based optimization techniques, namely NSGA-II (an
evolutionary algorithm) and OMOPSO (a swarm-based Pareto-optimization
algorithm), to two DL-enabled systems: an industrial Automated Valet Parking
(AVP) system and a system for classifying handwritten digits. We measure the
coverage of failure-revealing test inputs in the input space using a metric
that we refer to as the Coverage Inverted Distance quality indicator. Our
results show that NSGA-II-based search and OMOPSO are not more effective than a
na\"ive random search baseline in covering test inputs that reveal failures.
The replication package for this study is available in a GitHub repository.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication by Empirical Software Engineering Journal
  (EMSE) (in October 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> of Out-of-distribution Generalization for Graph Machine
  Learning from a Causal View 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09858v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09858v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph machine learning (GML) has been successfully applied across a wide
range of tasks. Nonetheless, GML faces significant challenges in generalizing
over out-of-distribution (OOD) data, which raises concerns about its wider
applicability. Recent advancements have underscored the crucial role of
causality-driven approaches in overcoming these generalization challenges.
Distinct from traditional GML methods that primarily rely on statistical
dependencies, causality-focused strategies delve into the underlying causal
mechanisms of data generation and model prediction, thus significantly
improving the generalization of GML across different environments. This paper
offers a thorough review of recent progress in causality-involved GML
generalization. We elucidate the fundamental concepts of employing causality to
enhance graph model generalization and categorize the various approaches,
providing detailed descriptions of their methodologies and the connections
among them. Furthermore, we explore the incorporation of causality in other
related important areas of trustworthy GML, such as explanation, fairness, and
robustness. Concluding with a discussion on potential future research
directions, this review seeks to articulate the continuing development and
future potential of causality in enhancing the trustworthiness of graph machine
learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic
  Manipulation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10394v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10394v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaidong Zhang, Pengzhen Ren, Bingqian Lin, Junfan Lin, Shikui Ma, Hang Xu, Xiaodan Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language-guided robotic manipulation is a challenging task that requires an
embodied agent to follow abstract user instructions to accomplish various
complex manipulation tasks. Previous work trivially fitting the data without
revealing the relation between instruction and low-level executable actions,
these models are prone to memorizing the surficial pattern of the data instead
of acquiring the transferable knowledge, and thus are fragile to dynamic
environment changes. To address this issue, we propose a PrIrmitive-driVen
waypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses
solely on the prediction of task-relevant waypoints. Specifically, PIVOT-R
consists of a Waypoint-aware World Model (WAWM) and a lightweight action
prediction module. The former performs primitive action parsing and
primitive-driven waypoint prediction, while the latter focuses on decoding
low-level actions. Additionally, we also design an asynchronous hierarchical
executor (AHE), which can use different execution frequencies for different
modules of the model, thereby helping the model reduce computational redundancy
and improve model execution efficiency. Our PIVOT-R outperforms
state-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving
an average relative improvement of 19.45% across four levels of instruction
tasks. Moreover, compared to the synchronously executed PIVOT-R, the execution
efficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop
in performance. These results provide compelling evidence that our PIVOT-R can
significantly improve both the performance and efficiency of robotic
manipulation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding What Affects the Generalization Gap in Visual
  Reinforcement Learning: Theory and Empirical Evidence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiafei Lyu, Le Wan, Xiu Li, Zongqing Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, there are many efforts attempting to learn useful policies for
continuous control in visual reinforcement learning (RL). In this scenario, it
is important to learn a generalizable policy, as the testing environment may
differ from the training environment, e.g., there exist distractors during
deployment. Many practical algorithms are proposed to handle this problem.
However, to the best of our knowledge, none of them provide a theoretical
understanding of what affects the generalization gap and why their proposed
methods work. In this paper, we bridge this issue by theoretically answering
the key factors that contribute to the generalization gap when the testing
environment has distractors. Our theories indicate that minimizing the
representation distance between training and testing environments, which aligns
with human intuition, is the most critical for the benefit of reducing the
generalization gap. Our theoretical results are supported by the empirical
evidence in the DMControl Generalization Benchmark (DMC-GB).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Journal of Artificial Intelligence Research (JAIR)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nonconvex Stochastic Bregman Proximal Gradient Method with Application
  to Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.14522v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.14522v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuangyu Ding, Jingyang Li, Kim-Chuan Toh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stochastic gradient methods for minimizing nonconvex composite objective
functions typically rely on the Lipschitz smoothness of the differentiable
part, but this assumption fails in many important problem classes like
quadratic inverse problems and neural network training, leading to instability
of the algorithms in both theory and practice. To address this, we propose a
family of stochastic Bregman proximal gradient (SBPG) methods that only require
smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a
Bregman proximity measure, offering a better approximation model that handles
non-Lipschitz gradients in nonconvex objectives. We establish the convergence
properties of vanilla SBPG and show it achieves optimal sample complexity in
the nonconvex setting. Experimental results on quadratic inverse problems
demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to
the initial point. Furthermore, we introduce a momentum-based variant, MSBPG,
which enhances convergence by relaxing the mini-batch size requirement while
preserving the optimal oracle complexity. We apply MSBPG to the training of
deep neural networks, utilizing a polynomial kernel function to ensure smooth
adaptivity of the loss function. Experimental results on benchmark datasets
confirm the effectiveness and robustness of MSBPG in training neural networks.
Given its negligible additional computational cost compared to SGD in
large-scale optimization, MSBPG shows promise as a universal open-source
optimizer for future applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A SARS-CoV-2 Interaction <span class="highlight-title">Dataset</span> and VHH Sequence Corpus for Antibody
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18749v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18749v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hirofumi Tsuruta, Hiroyuki Yamazaki, Ryota Maeda, Ryotaro Tamura, Akihiro Imura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Antibodies are crucial proteins produced by the immune system to eliminate
harmful foreign substances and have become pivotal therapeutic agents for
treating human diseases. To accelerate the discovery of antibody therapeutics,
there is growing interest in constructing language models using antibody
sequences. However, the applicability of pre-trained language models for
antibody discovery has not been thoroughly evaluated due to the scarcity of
labeled datasets. To overcome these limitations, we introduce AVIDa-SARS-CoV-2,
a dataset featuring the antigen-variable domain of heavy chain of heavy chain
antibody (VHH) interactions obtained from two alpacas immunized with severe
acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike proteins.
AVIDa-SARS-CoV-2 includes binary labels indicating the binding or non-binding
of diverse VHH sequences to 12 SARS-CoV-2 mutants, such as the Delta and
Omicron variants. Furthermore, we release VHHCorpus-2M, a pre-training dataset
for antibody language models, containing over two million VHH sequences. We
report benchmark results for predicting SARS-CoV-2-VHH binding using VHHBERT
pre-trained on VHHCorpus-2M and existing general protein and antibody-specific
pre-trained language models. These results confirm that AVIDa-SARS-CoV-2
provides valuable benchmarks for evaluating the representation capabilities of
antibody language models for binding prediction, thereby facilitating the
development of AI-driven antibody discovery. The datasets are available at
https://datasets.cognanous.com.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benign Overfitting under Learning Rate Conditions for $α$
  Sub-exponential Input 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00733v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00733v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kota Okudo, Kei Kobayashi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the phenomenon of benign overfitting in binary
classification problems with heavy-tailed input distributions, extending the
analysis of maximum margin classifiers to $\alpha$ sub-exponential
distributions ($\alpha \in (0, 2]$). This generalizes previous work focused on
sub-gaussian inputs. We provide generalization error bounds for linear
classifiers trained using gradient descent on unregularized logistic loss in
this heavy-tailed setting. Our results show that, under certain conditions on
the dimensionality $p$ and the distance between the centers of the
distributions, the misclassification error of the maximum margin classifier
asymptotically approaches the noise level, the theoretical optimal value.
Moreover, we derive an upper bound on the learning rate $\beta$ for benign
overfitting to occur and show that as the tail heaviness of the input
distribution $\alpha$ increases, the upper bound on the learning rate
decreases. These results demonstrate that benign overfitting persists even in
settings with heavier-tailed inputs than previously studied, contributing to a
deeper understanding of the phenomenon in more realistic data environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Changes in Nation Perception with Nationality-Assigned
  Personas in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13993v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13993v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahammed Kamruzzaman, Gene Louis Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Persona assignment has become a common strategy for customizing LLM use to
particular tasks and contexts. In this study, we explore how evaluation of
different nations change when LLMs are assigned specific nationality personas.
We assign 193 different nationality personas (e.g., an American person) to four
LLMs and examine how the LLM evaluations (or ''perceptions'')of countries
change. We find that all LLM-persona combinations tend to favor Western
European nations, though nation-personas push LLM behaviors to focus more on
and treat the nation-persona's own region more favorably. Eastern European,
Latin American, and African nations are treated more negatively by different
nationality personas. We additionally find that evaluations by nation-persona
LLMs of other nations correlate with human survey responses but fail to match
the values closely. Our study provides insight into how biases and stereotypes
are realized within LLMs when adopting different national personas. In line
with the ''Blueprint for an AI Bill of Rights'', our findings underscore the
critical need for developing mechanisms to ensure that LLM outputs promote
fairness and avoid over-generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Pre-print, Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Models: What Do They Know? Do They Know Things? Let's Find
  Out! 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17137v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17137v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodan Du, Nicholas Kolkin, Greg Shakhnarovich, Anand Bhattad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models excel at mimicking real scenes, suggesting they might
inherently encode important intrinsic scene properties. In this paper, we aim
to explore the following key questions: (1) What intrinsic knowledge do
generative models like GANs, Autoregressive models, and Diffusion models
encode? (2) Can we establish a general framework to recover intrinsic
representations from these models, regardless of their architecture or model
type? (3) How minimal can the required learnable parameters and labeled data be
to successfully recover this knowledge? (4) Is there a direct link between the
quality of a generative model and the accuracy of the recovered scene
intrinsics?
  Our findings indicate that a small Low-Rank Adaptators (LoRA) can recover
intrinsic images-depth, normals, albedo and shading-across different generators
(Autoregressive, GANs and Diffusion) while using the same decoder head that
generates the image. As LoRA is lightweight, we introduce very few learnable
parameters (as few as 0.04% of Stable Diffusion model weights for a rank of 2),
and we find that as few as 250 labeled images are enough to generate intrinsic
images with these LoRA modules. Finally, we also show a positive correlation
between the generative model's quality and the accuracy of the recovered
intrinsics through control experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://intrinsic-lora.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptation Odyssey in LLMs: Why Does Additional <span class="highlight-title">Pretrain</span>ing Sometimes
  Fail to Improve? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05581v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05581v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fırat Öncel, Matthias Bethge, Beyza Ermis, Mirco Ravanelli, Cem Subakan, Çağatay Yıldız
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the last decade, the generalization and adaptation abilities of deep
learning models were typically evaluated on fixed training and test
distributions. Contrary to traditional deep learning, large language models
(LLMs) are (i) even more overparameterized, (ii) trained on unlabeled text
corpora curated from the Internet with minimal human intervention, and (iii)
trained in an online fashion. These stark contrasts prevent researchers from
transferring lessons learned on model generalization and adaptation in deep
learning contexts to LLMs. To this end, our short paper introduces empirical
observations that aim to shed light on further training of already pretrained
language models. Specifically, we demonstrate that training a model on a text
domain could degrade its perplexity on the test portion of the same domain. We
observe with our subsequent analysis that the performance degradation is
positively correlated with the similarity between the additional and the
original pretraining dataset of the LLM. Our further token-level perplexity
observations reveals that the perplexity degradation is due to a handful of
tokens that are not informative about the domain. We hope these findings will
guide us in determining when to adapt a model vs when to rely on its
foundational capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conv-Basis: A New Paradigm for Efficient Attention Inference and
  Gradient Computation in <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingyu Liang, Heshan Liu, Zhenmei Shi, Zhao Song, Zhuoyan Xu, Junze Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The self-attention mechanism is the key to the success of transformers in
recent Large Language Models (LLMs). However, the quadratic computational cost
$O(n^2)$ in the input sequence length $n$ is a notorious obstacle for further
improvement and scalability in longer contexts. In this work, we leverage the
convolution-like structure of attention matrices to develop an efficient
approximation method for attention computation using convolution matrices. We
propose a $\mathsf{conv}$ basis system, analogous to the rank basis, and show
that any lower triangular matrix can always be decomposed as a sum of
structured convolution matrices in this basis. We then design a fast algorithm
to approximate the attention matrix via a sum of such $k$ convolution matrices.
This allows us to compute the attention {\it inference} via Fast Fourier
Transforms (FFT) in $O(knd \log n)$ time, where $d$ is the hidden dimension,
and thus achieve almost linear time $n^{1+o(1)}$ in the practical scenario
where $kd = n^{o(1)}$. Furthermore, the attention {\it training forward} and
{\it backward gradient} can be computed in $n^{1+o(1)}$ as well. We provide
theoretical guarantees on the run time and approximation error and conduct
preliminary experiments to evaluate its effectiveness. We hope our new paradigm
for accelerating attention computation in transformer models can help their
application to longer contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Physically Consistent Deep Learning For Climate Model
  Parameterizations <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03920v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03920v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Birgit Kühbacher, Fernando Iglesias-Suarez, Niki Kilbertus, Veronika Eyring
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Climate models play a critical role in understanding and projecting climate
change. Due to their complexity, their horizontal resolution of about 40-100 km
remains too coarse to resolve processes such as clouds and convection, which
need to be approximated via parameterizations. These parameterizations are a
major source of systematic errors and large uncertainties in climate
projections. Deep learning (DL)-based parameterizations, trained on data from
computationally expensive short, high-resolution simulations, have shown great
promise for improving climate models in that regard. However, their lack of
interpretability and tendency to learn spurious non-physical correlations
result in reduced trust in the climate simulation. We propose an efficient
supervised learning framework for DL-based parameterizations that leads to
physically consistent models with improved interpretability and negligible
computational overhead compared to standard supervised training. First, key
features determining the target physical processes are uncovered. Subsequently,
the neural network is fine-tuned using only those relevant features. We show
empirically that our method robustly identifies a small subset of the inputs as
actual physical drivers, therefore removing spurious non-physical
relationships. This results in by design physically consistent and
interpretable neural networks while maintaining the predictive performance of
unconstrained black-box DL-based parameterizations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICMLA 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">6</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via
  Lightweight Value Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12700v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12700v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in diffusion models trained on large-scale data have
enabled the generation of indistinguishable human-level images, yet they often
produce harmful content misaligned with human values, e.g., social bias, and
offensive content. Despite extensive research on Large Language Models (LLMs),
the challenge of Text-to-Image (T2I) model alignment remains largely
unexplored. Addressing this problem, we propose LiVO (Lightweight Value
Optimization), a novel lightweight method for aligning T2I models with human
values. LiVO only optimizes a plug-and-play value encoder to integrate a
specified value principle with the input prompt, allowing the control of
generated images over both semantics and values. Specifically, we design a
diffusion model-tailored preference optimization loss, which theoretically
approximates the Bradley-Terry model used in LLM alignment but provides a more
flexible trade-off between image quality and value conformity. To optimize the
value encoder, we also develop a framework to automatically construct a
text-image preference dataset of 86k (prompt, aligned image, violating image,
value principle) samples. Without updating most model parameters and through
adaptive value selection from the input prompt, LiVO significantly reduces
harmful outputs and achieves faster convergence, surpassing several strong
baselines and taking an initial step towards ethically aligned T2I models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024. The dataset and code can be found at
  https://github.com/achernarwang/LiVO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Coarse-Grained Matching in Video-Text Retrieval <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12407v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12407v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aozhu Chen, Hazel Doughty, Xirong Li, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-text retrieval has seen significant advancements, yet the ability of
models to discern subtle differences in captions still requires verification.
In this paper, we introduce a new approach for fine-grained evaluation. Our
approach can be applied to existing datasets by automatically generating hard
negative test captions with subtle single-word variations across nouns, verbs,
adjectives, adverbs, and prepositions. We perform comprehensive experiments
using four state-of-the-art models across two standard benchmarks (MSR-VTT and
VATEX) and two specially curated datasets enriched with detailed descriptions
(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our
analyses show that the current evaluation benchmarks fall short in detecting a
model's ability to perceive subtle single-word differences, 2) our fine-grained
evaluation highlights the difficulty models face in distinguishing such subtle
variations. To enhance fine-grained understanding, we propose a new baseline
that can be easily combined with current methods. Experiments on our
fine-grained evaluations demonstrate that this approach enhances a model's
ability to understand fine-grained differences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Bjøntegaard Delta for Compression Efficiency Evaluation:
  Are We Calculating It Precisely and Reliably? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Hang, Shenpeng Song, Zhimeng Huang, Chuanmin Jia, Siwei Ma, Wen Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For decades, the Bj{\o}ntegaard Delta (BD) has been the metric for evaluating
codec Rate-Distortion (R-D) performance. Yet, in most studies, BD is determined
using just 4-5 R-D data points, could this be sufficient? As codecs and quality
metrics advance, does the conventional BD estimation still hold up? Crucially,
are the performance improvements of new codecs and tools genuine, or merely
artifacts of estimation flaws? This paper addresses these concerns by
reevaluating BD estimation. We present a novel approach employing a
parameterized deep neural network to model R-D curves with high precision
across various metrics, accompanied by a comprehensive R-D dataset. This
approach both assesses the reliability of BD calculations and serves as a
precise BD estimator. Our findings advocate for the adoption of rigorous R-D
sampling and reliability metrics in future compression research to ensure the
validity and reliability of results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmnixR: Evaluating Omni-modality Language Models on Reasoning across
  Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lichang Chen, Hexiang Hu, Mingda Zhang, Yiwen Chen, Zifeng Wang, Yandong Li, Pranav Shyam, Tianyi Zhou, Heng Huang, Ming-Hsuan Yang, Boqing Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce OmnixR, an evaluation suite designed to benchmark SoTA
Omni-modality Language Models, such as GPT-4o and Gemini. Evaluating OLMs,
which integrate multiple modalities such as text, vision, and audio, presents
unique challenges. Particularly, the user message might often consist of
multiple modalities, such that OLMs have to establish holistic understanding
and reasoning across modalities to accomplish the task. Existing benchmarks are
limited to single modality or dual-modality tasks, overlooking comprehensive
multi-modal assessments of model reasoning. To address this, OmnixR offers two
evaluation variants: (1)synthetic subset: a synthetic dataset generated
automatically by translating text into multiple modalities--audio, images,
video, and hybrids (Omnify). (2)realistic subset: a real-world dataset,
manually curated and annotated by experts, for evaluating cross-modal reasoning
in natural settings. OmnixR presents a unique evaluation towards assessing OLMs
over a diverse mix of modalities, such as a question that involves video,
audio, and text, providing a rigorous cross-modal reasoning testbed unlike any
existing benchmarks. Our experiments find that all state-of-the-art OLMs
struggle with OmnixR questions that require integrating information from
multiple modalities to answer. Further analysis highlights differences in
reasoning behavior, underscoring the challenges of omni-modal AI alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 6 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Test-time adaptation for image compression with distribution
  regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12191v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12191v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kecheng Chen, Pingping Zhang, Tiexin Qin, Shiqi Wang, Hong Yan, Haoliang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current test- or compression-time adaptation image compression (TTA-IC)
approaches, which leverage both latent and decoder refinements as a two-step
adaptation scheme, have potentially enhanced the rate-distortion (R-D)
performance of learned image compression models on cross-domain compression
tasks, \textit{e.g.,} from natural to screen content images. However, compared
with the emergence of various decoder refinement variants, the latent
refinement, as an inseparable ingredient, is barely tailored to cross-domain
scenarios. To this end, we aim to develop an advanced latent refinement method
by extending the effective hybrid latent refinement (HLR) method, which is
designed for \textit{in-domain} inference improvement but shows noticeable
degradation of the rate cost in \textit{cross-domain} tasks. Specifically, we
first provide theoretical analyses, in a cue of marginalization approximation
from in- to cross-domain scenarios, to uncover that the vanilla HLR suffers
from an underlying mismatch between refined Gaussian conditional and hyperprior
distributions, leading to deteriorated joint probability approximation of
marginal distribution with increased rate consumption. To remedy this issue, we
introduce a simple Bayesian approximation-endowed \textit{distribution
regularization} to encourage learning a better joint probability approximation
in a plug-and-play manner. Extensive experiments on six in- and cross-domain
datasets demonstrate that our proposed method not only improves the R-D
performance compared with other latent refinement counterparts, but also can be
flexibly integrated into existing TTA-IC methods with incremental benefits.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video-to-Audio Generation with Hidden Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07464v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07464v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manjie Xu, Chenxing Li, Xinyi Tu, Yong Ren, Rilin Chen, Yu Gu, Wei Liang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating semantically and temporally aligned audio content in accordance
with video input has become a focal point for researchers, particularly
following the remarkable breakthrough in text-to-video generation. In this
work, we aim to offer insights into the video-to-audio generation paradigm,
focusing on three crucial aspects: vision encoders, auxiliary embeddings, and
data augmentation techniques. Beginning with a foundational model built on a
simple yet surprisingly effective intuition, we explore various vision encoders
and auxiliary embeddings through ablation studies. Employing a comprehensive
evaluation pipeline that emphasizes generation quality and video-audio
synchronization alignment, we demonstrate that our model exhibits
state-of-the-art video-to-audio generation capabilities. Furthermore, we
provide critical insights into the impact of different data augmentation
methods on enhancing the generation framework's overall capacity. We showcase
possibilities to advance the challenge of generating synchronized audio from
semantic and temporal perspectives. We hope these insights will serve as a
stepping stone toward developing more realistic and accurate audio-visual
generation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://sites.google.com/view/vta-ldm</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-15T00:00:00Z">2024-10-15</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">13</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OMCAT: Omni Context Aware <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12109v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12109v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arushi Goel, Karan Sapra, Matthieu Le, Rafael Valle, Andrew Tao, Bryan Catanzaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have made significant strides in text generation
and comprehension, with recent advancements extending into multimodal LLMs that
integrate visual and audio inputs. However, these models continue to struggle
with fine-grained, cross-modal temporal understanding, particularly when
correlating events across audio and video streams. We address these challenges
with two key contributions: a new dataset and model, called OCTAV and OMCAT
respectively. OCTAV (Omni Context and Temporal Audio Video) is a novel dataset
designed to capture event transitions across audio and video. Second, OMCAT
(Omni Context Aware Transformer) is a powerful model that leverages RoTE
(Rotary Time Embeddings), an innovative extension of RoPE, to enhance temporal
grounding and computational efficiency in time-anchored tasks. Through a robust
three-stage training pipeline-feature alignment, instruction tuning, and
OCTAV-specific training-OMCAT excels in cross-modal temporal understanding. Our
model demonstrates state-of-the-art performance on Audio-Visual Question
Answering (AVQA) tasks and the OCTAV benchmark, showcasing significant gains in
temporal reasoning and cross-modal alignment, as validated through
comprehensive experiments and ablation studies. Our dataset and code will be
made publicly available. The link to our demo page is https://om-cat.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Demo page: https://om-cat.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SplatPose+: Real-time Image-Based Pose-Agnostic 3D Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12080v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12080v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhe Liu, Yan Song Hu, Yuhao Chen, John Zelek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image-based Pose-Agnostic 3D Anomaly Detection is an important task that has
emerged in industrial quality control. This task seeks to find anomalies from
query images of a tested object given a set of reference images of an
anomaly-free object. The challenge is that the query views (a.k.a poses) are
unknown and can be different from the reference views. Currently, new methods
such as OmniposeAD and SplatPose have emerged to bridge the gap by synthesizing
pseudo reference images at the query views for pixel-to-pixel comparison.
However, none of these methods can infer in real-time, which is critical in
industrial quality control for massive production. For this reason, we propose
SplatPose+, which employs a hybrid representation consisting of a Structure
from Motion (SfM) model for localization and a 3D Gaussian Splatting (3DGS)
model for Novel View Synthesis. Although our proposed pipeline requires the
computation of an additional SfM model, it offers real-time inference speeds
and faster training compared to SplatPose. Quality-wise, we achieved a new SOTA
on the Pose-agnostic Anomaly Detection benchmark with the Multi-Pose Anomaly
Detection (MAD-SIM) dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WeatherDG: LLM-assisted Procedural Weather Generation for
  Domain-Generalized Semantic Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12075v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12075v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenghao Qian, Yuhu Guo, Yuhong Mo, Wenjing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose a novel approach, namely WeatherDG, that can
generate realistic, weather-diverse, and driving-screen images based on the
cooperation of two foundation models, i.e, Stable Diffusion (SD) and Large
Language Model (LLM). Specifically, we first fine-tune the SD with source data,
aligning the content and layout of generated samples with real-world driving
scenarios. Then, we propose a procedural prompt generation method based on LLM,
which can enrich scenario descriptions and help SD automatically generate more
diverse, detailed images. In addition, we introduce a balanced generation
strategy, which encourages the SD to generate high-quality objects of tailed
classes under various weather conditions, such as riders and motorcycles. This
segmentation-model-agnostic method can improve the generalization ability of
existing models by additionally adapting them with the generated synthetic
data. Experiments on three challenging datasets show that our method can
significantly improve the segmentation performance of different
state-of-the-art models on target domains. Notably, in the setting of
''Cityscapes to ACDC'', our method improves the baseline HRDA by 13.9% in mIoU.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ nvTorchCam: An Open-source Library for Camera-Agnostic Differentiable
  Geometric Vision 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12074v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12074v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Lichy, Hang Su, Abhishek Badki, Jan Kautz, Orazio Gallo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce nvTorchCam, an open-source library under the Apache 2.0 license,
designed to make deep learning algorithms camera model-independent. nvTorchCam
abstracts critical camera operations such as projection and unprojection,
allowing developers to implement algorithms once and apply them across diverse
camera models--including pinhole, fisheye, and 360 equirectangular panoramas,
which are commonly used in automotive and real estate capture applications.
Built on PyTorch, nvTorchCam is fully differentiable and supports GPU
acceleration and batching for efficient computation. Furthermore, deep learning
models trained for one camera type can be directly transferred to other camera
types without requiring additional modification. In this paper, we provide an
overview of nvTorchCam, its functionality, and present various code examples
and diagrams to demonstrate its usage. Source code and installation
instructions can be found on the nvTorchCam GitHub page at
https://github.com/NVlabs/nvTorchCam.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Source code and installation instructions are available at
  https://github.com/NVlabs/nvTorchCam</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic
  Geometry Voting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12068v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12068v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuan Dang, Khang Nguyen, Mandfred Huber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simultaneous localization and mapping (SLAM) in highly dynamic environments
is challenging due to the correlation complexity between moving objects and the
camera pose. Many methods have been proposed to deal with this problem;
however, the moving properties of dynamic objects with a moving camera remain
unclear. Therefore, to improve SLAM's performance, minimizing disruptive events
of moving objects with a physical understanding of 3D shapes and dynamics of
objects is needed. In this paper, we propose a robust method, V3D-SLAM, to
remove moving objects via two lightweight re-evaluation stages, including
identifying potentially moving and static objects using a spatial-reasoned
Hough voting mechanism and refining static objects by detecting dynamic noise
caused by intra-object motions using Chamfer distances as similarity
measurements. Our experiment on the TUM RGB-D benchmark on dynamic sequences
with ground-truth camera trajectories showed that our methods outperform the
most recent state-of-the-art SLAM methods. Our source code is available at
https://github.com/tuantdang/v3d-slam.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SOE: SO(3)-Equivariant 3D MRI Encoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shizhe He, Magdalini Paschali, Jiahong Ouyang, Adnan Masood, Akshay Chaudhari, Ehsan Adeli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representation learning has become increasingly important, especially as
powerful models have shifted towards learning latent representations before
fine-tuning for downstream tasks. This approach is particularly valuable in
leveraging the structural information within brain anatomy. However, a common
limitation of recent models developed for MRIs is their tendency to ignore or
remove geometric information, such as translation and rotation, thereby
creating invariance with respect to geometric operations. We contend that
incorporating knowledge about these geometric transformations into the model
can significantly enhance its ability to learn more detailed anatomical
information within brain structures. As a result, we propose a novel method for
encoding 3D MRIs that enforces equivariance with respect to all rotations in 3D
space, in other words, SO(3)-equivariance (SOE). By explicitly modeling this
geometric equivariance in the representation space, we ensure that any
rotational operation applied to the input image space is also reflected in the
embedding representation space. This approach requires moving beyond
traditional representation learning methods, as we need a representation vector
space that allows for the application of the same SO(3) operation in that
space. To facilitate this, we leverage the concept of vector neurons. The
representation space formed by our method captures the brain's structural and
anatomical information more effectively. We evaluate SOE pretrained on the
structural MRIs of two public data sets with respect to the downstream task of
predicting age and diagnosing Alzheimer's Disease from T1-weighted brain scans
of the ADNI data set. We demonstrate that our approach not only outperforms
other methods but is also robust against various degrees of rotation along
different axes. The code is available at
https://github.com/shizhehe/SOE-representation-learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learned Neural Physics Simulation for Articulated 3D Human Pose
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12023v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12023v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mykhaylo Andriluka, Baruch Tabanpour, C. Daniel Freeman, Cristian Sminchisescu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel neural network approach, LARP (Learned Articulated Rigid
body Physics), to model the dynamics of articulated human motion with contact.
Our goal is to develop a faster and more convenient methodological alternative
to traditional physics simulators for use in computer vision tasks such as
human motion reconstruction from video. To that end we introduce a training
procedure and model components that support the construction of a recurrent
neural architecture to accurately simulate articulated rigid body dynamics. Our
neural architecture supports features typically found in traditional physics
simulators, such as modeling of joint motors, variable dimensions of body
parts, contact between body parts and objects, and is an order of magnitude
faster than traditional systems when multiple simulations are run in parallel.
To demonstrate the value of LARP we use it as a drop-in replacement for a state
of the art classical non-differentiable simulator in an existing video-based
reconstruction framework and show comparative or better 3D human pose
reconstruction accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LocoMotion: Learning Motion-Focused Video-Language Representations <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hazel Doughty, Fida Mohammad Thoker, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper strives for motion-focused video-language representations.
Existing methods to learn video-language representations use spatial-focused
data, where identifying the objects and scene is often enough to distinguish
the relevant caption. We instead propose LocoMotion to learn from
motion-focused captions that describe the movement and temporal progression of
local object motions. We achieve this by adding synthetic motions to videos and
using the parameters of these motions to generate corresponding captions.
Furthermore, we propose verb-variation paraphrasing to increase the caption
variety and learn the link between primitive motions and high-level verbs. With
this, we are able to learn a motion-focused video-language representation.
Experiments demonstrate our approach is effective for a variety of downstream
tasks, particularly when limited data is available for fine-tuning. Code is
available: https://hazeldoughty.github.io/Papers/LocoMotion/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Labels: A <span class="highlight-title">Self-Supervised</span> Framework with Masked Autoencoders and
  Random Cropping for Breast Cancer Subtype Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Annalisa Chiocchetti, Marco Dossena, Christopher Irwin, Luigi Portinale
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work contributes to breast cancer sub-type classification using
histopathological images. We utilize masked autoencoders (MAEs) to learn a
self-supervised embedding tailored for computer vision tasks in this domain.
This embedding captures informative representations of histopathological data,
facilitating feature learning without extensive labeled datasets. During
pre-training, we investigate employing a random crop technique to generate a
large dataset from WSIs automatically. Additionally, we assess the performance
of linear probes for multi-class classification tasks of cancer sub-types using
the representations learnt by the MAE. Our approach aims to achieve strong
performance on downstream tasks by leveraging the complementary strengths of
ViTs and autoencoders. We evaluate our model's performance on the BRACS dataset
and compare it with existing benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Invariance in Images through One-way Wave Equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.12976v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.12976v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinpeng Chen, Dongdong Chen, Xiyang Dai, Mengchen Liu, Yinan Feng, Youzuo Lin, Lu Yuan, Zicheng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we empirically reveal an invariance over images-images share a
set of one-way wave equations with latent speeds. Each image is uniquely
associated with a solution to these wave equations, allowing for its
reconstruction with high fidelity from an initial condition. We demonstrate it
using an intuitive encoder-decoder framework where each image is encoded into
its corresponding initial condition (a single vector). Subsequently, the
initial condition undergoes a specialized decoder, transforming the one-way
wave equations into a first-order norm + linear autoregressive process. This
process propagates the initial condition along the x and y directions,
generating a high-resolution feature map (up to the image resolution), followed
by a few convolutional layers to reconstruct image pixels. The revealed
invariance, rooted in the shared wave equations, offers a fresh perspective for
comprehending images, establishing a promising avenue for further exploration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is an improvement version, which fuses some parts from the
  preliminary work arXiv:2305.16319</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Rationality in Language and Multimodal Agents: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00252v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00252v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jiang, Yangxinyu Xie, Xiaomeng Wang, Yuan Yuan, Zhuoqun Hao, Xinyi Bai, Weijie J. Su, Camillo J. Taylor, Tanwi Mallick
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rationality is the quality of being guided by reason, characterized by
decision-making that aligns with evidence and logical principles. It plays a
crucial role in reliable problem-solving by ensuring well-grounded and
consistent solutions. While large language models (LLMs) have made significant
progress in generating human-like text, they still exhibit limitations such as
bounded knowledge space and inconsistent outputs. In response, recent efforts
have shifted toward developing multimodal and multi-agent systems, as well as
integrating modules like external tools, programming codes, symbolic reasoners,
utility function, and conformal risk controls rather than relying solely on a
single LLM for decision-making. This paper surveys the state-of-the-art
advancements in language and multimodal agents, evaluates how they contribute
to make intelligent agents more rational, and identifies open challenges and
future research directions. We maintain an open repository at
https://github.com/bowen-upenn/Agent_Rationality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We maintain an open repository at
  https://github.com/bowen-upenn/Agent_Rationality</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the power of data augmentation for head pose estimation <span class="chip">CVPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05357v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05357v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Welter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning has been impressively successful in the last decade in
predicting human head poses from monocular images. However, for in-the-wild
inputs the research community relies predominantly on a single training set,
300W-LP, of semisynthetic nature without many alternatives. This paper focuses
on gradual extension and improvement of the data to explore the performance
achievable with augmentation and synthesis strategies further. Modeling-wise a
novel multitask head/loss design which includes uncertainty estimation is
proposed. Overall, the thus obtained models are small, efficient, suitable for
full 6 DoF pose estimation, and exhibit very competitive accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR version. Added evaluation on BIWI. Plenty of writing changes</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Vision <span class="highlight-title">transformer</span>s in domain adaptation and domain generalization: a
  study of robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.04452v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.04452v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shadi Alijani, Jamil Fayyad, Homayoun Najjaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning models are often evaluated in scenarios where the data
distribution is different from those used in the training and validation
phases. The discrepancy presents a challenge for accurately predicting the
performance of models once deployed on the target distribution. Domain
adaptation and generalization are widely recognized as effective strategies for
addressing such shifts, thereby ensuring reliable performance. The recent
promising results in applying vision transformers in computer vision tasks,
coupled with advancements in self-attention mechanisms, have demonstrated their
significant potential for robustness and generalization in handling
distribution shifts. Motivated by the increased interest from the research
community, our paper investigates the deployment of vision transformers in
domain adaptation and domain generalization scenarios. For domain adaptation
methods, we categorize research into feature-level, instance-level, model-level
adaptations, and hybrid approaches, along with other categorizations with
respect to diverse strategies for enhancing domain adaptation. Similarly, for
domain generalization, we categorize research into multi-domain learning,
meta-learning, regularization techniques, and data augmentation strategies. We
further classify diverse strategies in research, underscoring the various
approaches researchers have taken to address distribution shifts by integrating
vision transformers. The inclusion of comprehensive tables summarizing these
categories is a distinct feature of our work, offering valuable insights for
researchers. These findings highlight the versatility of vision transformers in
managing distribution shifts, crucial for real-world applications, especially
in critical safety and decision-making scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Moral Case for Using Language Model Agents for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seth Lazar, Luke Thorburn, Tian Jin, Luca Belli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our information and communication environment has fallen short of the ideals
that networked global communication might have served. Identifying all the
causes of its pathologies is difficult, but existing recommender systems very
likely play a contributing role. In this paper, which draws on the normative
tools of philosophy of computing, informed by empirical and technical insights
from natural language processing and recommender systems, we make the moral
case for an alternative approach. We argue that existing recommenders
incentivise mass surveillance, concentrate power, fall prey to narrow
behaviourism, and compromise user agency. Rather than just trying to avoid
algorithms entirely, or to make incremental improvements to the current
paradigm, researchers and engineers should explore an alternative paradigm: the
use of language model (LM) agents to source and curate content that matches
users' preferences and values, expressed in natural language. The use of LM
agents for recommendation poses its own challenges, including those related to
candidate generation, computational efficiency, preference modelling, and
prompt injection. Nonetheless, if implemented successfully LM agents could:
guide us through the digital public sphere without relying on mass
surveillance; shift power away from platforms towards users; optimise for what
matters instead of just for behavioural proxies; and scaffold our agency
instead of undermining it.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11841v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11841v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Tang, Yongliang Shen, Hang Zhang, Zeqi Tan, Wenqi Zhang, Guiyang Hou, Kaitao Song, Weiming Lu, Yueting Zhuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language model-based explainable recommendation (LLM-based ER) systems
show promise in generating human-like explanations for recommendations.
However, they face challenges in modeling user-item collaborative preferences,
personalizing explanations, and handling sparse user-item interactions. To
address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated
Mixture of Experts framework for explainable recommendation. GaVaMoE introduces
two key components: (1) a rating reconstruction module that employs Variational
Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex
user-item collaborative preferences, serving as a pre-trained multi-gating
mechanism; and (2) a set of fine-grained expert models coupled with the
multi-gating mechanism for generating highly personalized explanations. The VAE
component models latent factors in user-item interactions, while the GMM
clusters users with similar behaviors. Each cluster corresponds to a gate in
the multi-gating mechanism, routing user-item pairs to appropriate expert
models. This architecture enables GaVaMoE to generate tailored explanations for
specific user types and preferences, mitigating data sparsity by leveraging
user similarities. Extensive experiments on three real-world datasets
demonstrate that GaVaMoE significantly outperforms existing methods in
explanation quality, personalization, and consistency. Notably, GaVaMoE
exhibits robust performance in scenarios with sparse user-item interactions,
maintaining high-quality explanations even for users with limited historical
data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Coordinators and <span class="highlight-title">Prompt</span>s on Heterogeneous Graphs for
  Cross-Domain Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11719v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11719v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yu Rong, Chengzhi Piao, Hong Cheng, Lingling Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the online digital world, users frequently engage with diverse items
across multiple domains (e.g., e-commerce platforms, streaming services, and
social media networks), forming complex heterogeneous interaction graphs.
Leveraging this multi-domain information can undoubtedly enhance the
performance of recommendation systems by providing more comprehensive user
insights and alleviating data sparsity in individual domains. However,
integrating multi-domain knowledge for the cross-domain recommendation is very
hard due to inherent disparities in user behavior and item characteristics and
the risk of negative transfer, where irrelevant or conflicting information from
the source domains adversely impacts the target domain's performance. To
address these challenges, we offer HAGO, a novel framework with
$\textbf{H}$eterogeneous $\textbf{A}$daptive $\textbf{G}$raph
co$\textbf{O}$rdinators, which dynamically integrate multi-domain graphs into a
cohesive structure by adaptively adjusting the connections between coordinators
and multi-domain graph nodes, thereby enhancing beneficial inter-domain
interactions while mitigating negative transfer effects. Additionally, we
develop a universal multi-domain graph pre-training strategy alongside HAGO to
collaboratively learn high-quality node representations across domains. To
effectively transfer the learned multi-domain knowledge to the target domain,
we design an effective graph prompting method, which incorporates pre-trained
embeddings with learnable prompts for the recommendation task. Our framework is
compatible with various graph-based models and pre-training techniques,
demonstrating broad applicability and effectiveness. Further experimental
results show that our solutions outperform state-of-the-art methods in
multi-domain recommendation scenarios and highlight their potential for
real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoActionGraphRec: Sequential Multi-Interest Recommendations Using
  Co-Action Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Sun, Yuri M. Brovman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There are unique challenges to developing item recommender systems for
e-commerce platforms like eBay due to sparse data and diverse user interests.
While rich user-item interactions are important, eBay's data sparsity exceeds
other e-commerce sites by an order of magnitude. To address this challenge, we
propose CoActionGraphRec (CAGR), a text based two-tower deep learning model
(Item Tower and User Tower) utilizing co-action graph layers. In order to
enhance user and item representations, a graph-based solution tailored to
eBay's environment is utilized. For the Item Tower, we represent each item
using its co-action items to capture collaborative signals in a co-action graph
that is fully leveraged by the graph neural network component. For the User
Tower, we build a fully connected graph of each user's behavior sequence, with
edges encoding pairwise relationships. Furthermore, an explicit interaction
module learns representations capturing behavior interactions. Extensive
offline and online A/B test experiments demonstrate the effectiveness of our
proposed approach and results show improved performance over state-of-the-art
methods on key metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under
  Low-Resource Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Wuzhenghong, Zhang Yongpan, Pan Su, Sun Yuwei, Lu Pengwei, Ding Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models revolutionize Text2SQL through supervised fine-tuning,
yet a crucial limitation is overlooked: the complexity of databases leads to an
increased context length, consequently resulting in higher GPU memory demands
for model fine-tuning. To address this issue, we propose LR-SQL. LR-SQL
comprises two supervised fine-tuning models: the schema\_link model and the
SQL\_generation model, with the schema\_link model serving as the focal point
for streamlining the overall process. During the fine-tuning of the
schema\_link model, LR-SQL breaks down the complete database into flexible
combinations of tables with adjustable quantities, enabling the model to learn
the relationships within the entire database from these dispersed slices.
Furthermore, to enhance the model's ability to perceive the relationships among
various discrete slices during inference, LR-SQL trains the model's
Chain-of-Thought capability for this task. Experimental results demonstrate
that LR-SQL can reduce the total GPU memory usage by 40\% compared to existing
fine-tuning methods, while only losing 2\% of table prediction accuracy in
schema\_link task. For the overall Text2SQL task, the Execution Accuracy
decrease by 0.6\%.Our project is now available on
https://github.com/hongWin/LR-SQL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12pages, 4 figures,submitting to a journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhance Graph Alignment for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11370v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11370v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-structured data is prevalent in the real world. Recently, due to the
powerful emergent capabilities, Large Language Models (LLMs) have shown
promising performance in modeling graphs. The key to effectively applying LLMs
on graphs is converting graph data into a format LLMs can comprehend.
Graph-to-token approaches are popular in enabling LLMs to process graph
information. They transform graphs into sequences of tokens and align them with
text tokens through instruction tuning, where self-supervised instruction
tuning helps LLMs acquire general knowledge about graphs, and supervised
fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their
initial success, we find that existing methods have a misalignment between
self-supervised tasks and supervised downstream tasks, resulting in negative
transfer from self-supervised fine-tuning to downstream tasks. To address these
issues, we propose Graph Alignment Large Language Models (GALLM) to benefit
from aligned task templates. In the self-supervised tuning stage, we introduce
a novel text matching task using templates aligned with downstream tasks. In
the task-specific tuning stage, we propose two category prompt methods that
learn supervision information from additional explanation with further aligned
templates. Experimental evaluations on four datasets demonstrate substantial
improvements in supervised learning, multi-dataset generalizability, and
particularly in zero-shot capability, highlighting the model's potential as a
graph foundation model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minoo Jafarlou, Mario M. Kubek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Labeling datasets is a noteworthy challenge in machine learning, both in
terms of cost and time. This research, however, leverages an efficient answer.
By exploring label propagation in semi-supervised learning, we can
significantly reduce the number of labels required compared to traditional
methods. We employ a transductive label propagation method based on the
manifold assumption for text classification. Our approach utilizes a
graph-based method to generate pseudo-labels for unlabeled data for the text
classification task, which are then used to train deep neural networks. By
extending labels based on cosine proximity within a nearest neighbor graph from
network embeddings, we combine unlabeled data into supervised learning, thereby
reducing labeling costs. Based on previous successes in other domains, this
study builds and evaluates this approach's effectiveness in sentiment analysis,
presenting insights into semi-supervised learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 7 figures, accepted at the 2024 8th International
  Conference on Natural Language Processing and Information Retrieval (NLPIR
  2024), Okayama, Japan, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sequential LLM Framework for Fashion Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11327v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11327v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Liu, Xianfeng Tang, Tianlang Chen, Jiapeng Liu, Indu Indu, Henry Peng Zou, Peng Dai, Roberto Fernandez Galan, Michael D Porter, Dongmei Jia, Ning Zhang, Lian Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The fashion industry is one of the leading domains in the global e-commerce
sector, prompting major online retailers to employ recommendation systems for
product suggestions and customer convenience. While recommendation systems have
been widely studied, most are designed for general e-commerce problems and
struggle with the unique challenges of the fashion domain. To address these
issues, we propose a sequential fashion recommendation framework that leverages
a pre-trained large language model (LLM) enhanced with recommendation-specific
prompts. Our framework employs parameter-efficient fine-tuning with extensive
fashion data and introduces a novel mix-up-based retrieval technique for
translating text into relevant product suggestions. Extensive experiments show
our proposed framework significantly enhances fashion recommendation
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Capacity of Citation Generation by Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haosheng Qian, Yixing Fan, Ruqing Zhang, Jiafeng Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) appears as a promising method to
alleviate the "hallucination" problem in large language models (LLMs), since it
can incorporate external traceable resources for response generation. The
essence of RAG in combating the hallucination issue lies in accurately
attributing claims in responses to the corresponding retrieved documents.
However, most of existing works focus on improving the quality of generated
responses from the LLM, while largely overlooked its ability to attribute
sources accurately. In this study, we conduct a systematic analysis about the
capabilities of LLMs in generating citations within response generation, and
further introduce a novel method to enhance their citation generation
abilities. Specifically, we evaluate both the correctness and citation quality
for seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce
new citation evaluation metrics to eliminate the over-penalization of
unnecessary and excessive citations in existing metrics. Furthermore, we
propose a Generate-then-Refine method that completes relevant citations and
removes irrelevant ones without altering the response text. The results on
WebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves
the quality of citations in responses generated by LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by CCIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Encoder-Only <span class="highlight-title">Transformer</span>s for Session-Based Recommendation
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anis Redjdal, Luis Pinto, Michel Desmarais
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based recommendation is the task of predicting the next item a user
will interact with, often without access to historical user data. In this work,
we introduce Sequential Masked Modeling, a novel approach for encoder-only
transformer architectures to tackle the challenges of single-session
recommendation. Our method combines data augmentation through window sliding
with a unique penultimate token masking strategy to capture sequential
dependencies more effectively. By enhancing how transformers handle session
data, Sequential Masked Modeling significantly improves next-item prediction
performance.
  We evaluate our approach on three widely-used datasets, Yoochoose 1/64,
Diginetica, and Tmall, comparing it to state-of-the-art single-session,
cross-session, and multi-relation approaches. The results demonstrate that our
Transformer-SMM models consistently outperform all models that rely on the same
amount of information, while even rivaling methods that have access to more
extensive user history. This study highlights the potential of encoder-only
transformers in session-based recommendation and opens the door for further
improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07722v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07722v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thong Nguyen, Shubham Chatterjee, Sean MacAvaney, Iain Mackie, Jeff Dalton, Andrew Yates
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learned Sparse Retrieval (LSR) models use vocabularies from pre-trained
transformers, which often split entities into nonsensical fragments. Splitting
entities can reduce retrieval accuracy and limits the model's ability to
incorporate up-to-date world knowledge not included in the training data. In
this work, we enhance the LSR vocabulary with Wikipedia concepts and entities,
enabling the model to resolve ambiguities more effectively and stay current
with evolving knowledge. Central to our approach is a Dynamic Vocabulary (DyVo)
head, which leverages existing entity embeddings and an entity retrieval
component that identifies entities relevant to a query or document. We use the
DyVo head to generate entity weights, which are then merged with word piece
weights to create joint representations for efficient indexing and retrieval
using an inverted index. In experiments across three entity-rich document
ranking datasets, the resulting DyVo model substantially outperforms
state-of-the-art baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/thongnt99/DyVo</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced
  Distillation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03764v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03764v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenjie Zhou, Zhenxin Ding, Xiaodong Zhang, Haibo Shi, Junfeng Wang, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models have become an integral component of
question-answering systems, achieving remarkable performance. However, for
practical deployment, it is crucial to perform knowledge distillation to
maintain high performance while operating under computational constraints. In
this paper, we address a key question: given the importance of unsupervised
distillation for student model performance, how can knowledge from multiple
teacher models be effectively ensemble during this stage without the guidance
of labels? We propose a novel algorithm, GOVERN, to tackle this issue. GOVERN
has demonstrated significant improvements in both offline and online
experiments, enabling the student model to achieve results comparable to that
of teacher ensembles. Our experiments show that GOVERN remarkably requires a
mere 1\% of the ensemble method's inference budget to achieve 99.5\% of
performance. The proposed algorithm has been successfully deployed in a
real-world commercial question-answering system, demonstrating its real-world
applicability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for
  Interpretable Job Recommendation <span class="chip">ICDM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07671v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07671v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoshan Yu, Chuan Qin, Qi Zhang, Chen Zhu, Haiping Ma, Xingyi Zhang, Hengshu Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development of online recruitment platforms has created
unprecedented opportunities for job seekers while concurrently posing the
significant challenge of quickly and accurately pinpointing positions that
align with their skills and preferences. Job recommendation systems have
significantly alleviated the extensive search burden for job seekers by
optimizing user engagement metrics, such as clicks and applications, thus
achieving notable success. In recent years, a substantial amount of research
has been devoted to developing effective job recommendation models, primarily
focusing on text-matching based and behavior modeling based methods. While
these approaches have realized impressive outcomes, it is imperative to note
that research on the explainability of recruitment recommendations remains
profoundly unexplored. To this end, in this paper, we propose DISCO, a
hierarchical Disentanglement based Cognitive diagnosis framework, aimed at
flexibly accommodating the underlying representation learning model for
effective and interpretable job recommendations. Specifically, we first design
a hierarchical representation disentangling module to explicitly mine the
hierarchical skill-related factors implied in hidden representations of job
seekers and jobs. Subsequently, we propose level-aware association modeling to
enhance information communication and robust representation learning both
inter- and intra-level, which consists of the interlevel knowledge influence
module and the level-wise contrastive learning. Finally, we devise an
interaction diagnosis module incorporating a neural diagnosis function for
effectively modeling the multi-level recruitment interaction process between
job seekers and jobs, which introduces the cognitive measurement theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICDM 2024. 10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Curriculum-scheduled Knowledge Distillation from Multiple <span class="highlight-title">Pre-train</span>ed
  Teachers for Multi-domain Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00797v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00797v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Sun, Ruobing Xie, Junjie Zhang, Wayne Xin Zhao, Leyu Lin, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained recommendation models (PRMs) have received increasing interest
recently. However, their intrinsically heterogeneous model structure, huge
model size and computation cost hinder their adoptions in practical recommender
systems. Hence, it is highly essential to explore how to use different
pre-trained recommendation models efficiently in real-world systems. In this
paper, we propose a novel curriculum-scheduled knowledge distillation from
multiple pre-trained teachers for multi-domain sequential recommendation,
called CKD-MDSR, which takes full advantages of different PRMs as multiple
teacher models to boost a small student recommendation model, integrating the
knowledge across multiple domains from PRMs. Specifically, CKD-MDSR first
adopts curriculum-scheduled user behavior sequence sampling and distills
informative knowledge jointly from the representative PRMs such as UniSRec and
Recformer. Then, the knowledge from the above PRMs are selectively integrated
into the student model in consideration of their confidence and consistency.
Finally, we verify the proposed method on multi-domain sequential
recommendation and further demonstrate its universality with multiple types of
student models, including feature interaction and graph based recommendation
models. Extensive experiments on five real-world datasets demonstrate the
effectiveness and efficiency of CKD-MDSR, which can be viewed as an efficient
shortcut using PRMs in real-world systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CoRA: Collaborative Information Perception by Large Language Model's
  Weights for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10645v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10645v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuting Liu, Jinghao Zhang, Yizhou Dang, Yuliang Liang, Qiang Liu, Guibing Guo, Jianzhe Zhao, Xingwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Involving collaborative information in Large Language Models (LLMs) is a
promising technique for adapting LLMs for recommendation. Existing methods
achieve this by concatenating collaborative features with text tokens into a
unified sequence input and then fine-tuning to align these features with LLM's
input space. Although effective, in this work, we identify two limitations when
adapting LLMs to recommendation tasks, which hinder the integration of general
knowledge and collaborative information, resulting in sub-optimal
recommendation performance. (1) Fine-tuning LLM with recommendation data can
undermine its inherent world knowledge and fundamental competencies, which are
crucial for interpreting and inferring recommendation text. (2) Incorporating
collaborative features into textual prompts disrupts the semantics of the
original prompts, preventing LLM from generating appropriate outputs. In this
paper, we propose a new paradigm, CoRA (an acronym for Collaborative LoRA),
with a collaborative weights generator. Rather than input space alignment, this
method aligns collaborative information with LLM's parameter space,
representing them as incremental weights to update LLM's output. This way, LLM
perceives collaborative information without altering its general knowledge and
text inference capabilities. Specifically, we employ a collaborative filtering
model to extract user and item embeddings, converting them into collaborative
weights with low-rank properties through the collaborative weights generator.
We then merge the collaborative weights into LLM's weights, enabling LLM to
perceive the collaborative signals and generate personalized recommendations
without fine-tuning or extra collaborative tokens in prompts. Extensive
experiments confirm that CoRA effectively integrates collaborative information
into LLM, enhancing recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recommenadation aided Caching using Combinatorial Multi-armed Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00080v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00080v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pavamana K J, Chandramani Kishore Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study content caching with recommendations in a wireless network where the
users are connected through a base station equipped with a finite-capacity
cache. We assume a fixed set of contents with unknown user preferences and
content popularities. The base station can cache a subset of the contents and
can also recommend subsets of the contents to different users in order to
encourage them to request the recommended contents. Recommendations, depending
on their acceptability, can thus be used to increase cache hits. We first
assume that the users' recommendation acceptabilities are known and formulate
the cache hit optimization problem as a combinatorial multi-armed bandit
(CMAB). We propose a UCB-based algorithm to decide which contents to cache and
recommend and provide an upper bound on the regret of this algorithm.
Subsequently, we consider a more general scenario where the users'
recommendation acceptabilities are also unknown and propose another UCB-based
algorithm that learns these as well. We numerically demonstrate the performance
of our algorithms and compare these to state-of-the-art algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spectral-Based Graph Neural Networks for Complementary Item
  Recommendation <span class="chip">AAAI-24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.02130v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.02130v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haitong Luo, Xuying Meng, Suhang Wang, Hanyun Cao, Weiyao Zhang, Yequan Wang, Yujun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling complementary relationships greatly helps recommender systems to
accurately and promptly recommend the subsequent items when one item is
purchased. Unlike traditional similar relationships, items with complementary
relationships may be purchased successively (such as iPhone and Airpods Pro),
and they not only share relevance but also exhibit dissimilarity. Since the two
attributes are opposites, modeling complementary relationships is challenging.
Previous attempts to exploit these relationships have either ignored or
oversimplified the dissimilarity attribute, resulting in ineffective modeling
and an inability to balance the two attributes. Since Graph Neural Networks
(GNNs) can capture the relevance and dissimilarity between nodes in the
spectral domain, we can leverage spectral-based GNNs to effectively understand
and model complementary relationships. In this study, we present a novel
approach called Spectral-based Complementary Graph Neural Networks (SComGNN)
that utilizes the spectral properties of complementary item graphs. We make the
first observation that complementary relationships consist of low-frequency and
mid-frequency components, corresponding to the relevance and dissimilarity
attributes, respectively. Based on this spectral observation, we design
spectral graph convolutional networks with low-pass and mid-pass filters to
capture the low-frequency and mid-frequency components. Additionally, we
propose a two-stage attention mechanism to adaptively integrate and balance the
two attributes. Experimental results on four e-commerce datasets demonstrate
the effectiveness of our model, with SComGNN significantly outperforming
existing baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI-24</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D
  Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cindy Xu, Mengyu Chen, Pranav Deshpande, Elvir Azanli, Runqing Yang, Joseph Ligman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a novel system designed to enhance customer
service in the financial and retail sectors through a context-aware 3D virtual
agent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our
approach focuses on enabling data-driven and empathetic interactions that
ensure customer satisfaction by introducing situational awareness of the
physical location, personalized interactions based on customer profiles, and
rigorous privacy and security standards. We discuss our design considerations
critical for deployment in real-world customer service environments, addressing
challenges in user data management and sensitive information handling. We also
outline the system architecture and key features unique to banking and retail
environments. Our work demonstrates the potential of integrating MR and VLMs in
service industries, offering practical insights in customer service delivery
while maintaining high standards of security and personalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>to appear at 1st Workshop on Intelligent XR: Harnessing AI for
  Next-Generation XR User Experiences at International Symposium on Mixed and
  Augmented Reality (ISMAR) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LocoMotion: Learning Motion-Focused Video-Language Representations <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hazel Doughty, Fida Mohammad Thoker, Cees G. M. Snoek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper strives for motion-focused video-language representations.
Existing methods to learn video-language representations use spatial-focused
data, where identifying the objects and scene is often enough to distinguish
the relevant caption. We instead propose LocoMotion to learn from
motion-focused captions that describe the movement and temporal progression of
local object motions. We achieve this by adding synthetic motions to videos and
using the parameters of these motions to generate corresponding captions.
Furthermore, we propose verb-variation paraphrasing to increase the caption
variety and learn the link between primitive motions and high-level verbs. With
this, we are able to learn a motion-focused video-language representation.
Experiments demonstrate our approach is effective for a variety of downstream
tasks, particularly when limited data is available for fine-tuning. Code is
available: https://hazeldoughty.github.io/Papers/LocoMotion/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Long-Text Alignment for Text-to-Image Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11817v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11817v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luping Liu, Chao Du, Tianyu Pang, Zehan Wang, Chongxuan Li, Dong Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of text-to-image (T2I) diffusion models has enabled
them to generate unprecedented results from given texts. However, as text
inputs become longer, existing encoding methods like CLIP face limitations, and
aligning the generated images with long texts becomes challenging. To tackle
these issues, we propose LongAlign, which includes a segment-level encoding
method for processing long texts and a decomposed preference optimization
method for effective alignment training. For segment-level encoding, long texts
are divided into multiple segments and processed separately. This method
overcomes the maximum input length limits of pretrained encoding models. For
preference optimization, we provide decomposed CLIP-based preference models to
fine-tune diffusion models. Specifically, to utilize CLIP-based preference
models for T2I alignment, we delve into their scoring mechanisms and find that
the preference scores can be decomposed into two components: a text-relevant
part that measures T2I alignment and a text-irrelevant part that assesses other
visual aspects of human preference. Additionally, we find that the
text-irrelevant part contributes to a common overfitting problem during
fine-tuning. To address this, we propose a reweighting strategy that assigns
different weights to these two components, thereby reducing overfitting and
enhancing alignment. After fine-tuning $512 \times 512$ Stable Diffusion (SD)
v1.5 for about 20 hours using our method, the fine-tuned SD outperforms
stronger foundation models in T2I alignment, such as PixArt-$\alpha$ and
Kandinsky v2.2. The code is available at
https://github.com/luping-liu/LongAlign.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenxi Wang, Xiang Chen, Ningyu Zhang, Bozhong Tian, Haoming Xu, Shumin Deng, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) frequently exhibit hallucination
phenomena, but the underlying reasons remain poorly understood. In this paper,
we present an empirical analysis and find that, although MLLMs incorrectly
generate the objects in the final output, they are actually able to recognize
visual objects in the preceding layers. We speculate that this may be due to
the strong knowledge priors of the language model suppressing the visual
information, leading to hallucinations. Motivated by this, we propose a novel
dynamic correction decoding method for MLLMs (DeCo), which adaptively selects
the appropriate preceding layers and proportionally integrates knowledge into
the final layer to adjust the output logits. Note that DeCo is model agnostic
and can be seamlessly incorporated with various classic decoding strategies and
applied to different MLLMs. We evaluate DeCo on widely-used benchmarks,
demonstrating that it can reduce hallucination rates by a large margin compared
to baselines, highlighting its potential to mitigate hallucinations. Code is
available at https://github.com/zjunlp/DeCo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Magnifier <span class="highlight-title">Prompt</span>: Tackling Multimodal Hallucination via Extremely Simple
  Instructions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Fu, Ruobing Xie, Jiazhen Liu, Bangxiang Lan, Xingwu Sun, Zhanhui Kang, Xirong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucinations in multimodal large language models (MLLMs) hinder their
practical applications. To address this, we propose a Magnifier Prompt
(MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs
via extremely simple instructions. MagPrompt is based on the following two key
principles, which guide the design of various effective prompts, demonstrating
robustness: (1) MLLMs should focus more on the image. (2) When there are
conflicts between the image and the model's inner knowledge, MLLMs should
prioritize the image. MagPrompt is training-free and can be applied to
open-source and closed-source models, such as GPT-4o and Gemini-pro. It
performs well across many datasets and its effectiveness is comparable or even
better than more complex methods like VCD. Furthermore, our prompt design
principles and experimental analyses provide valuable insights into multimodal
hallucination.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 13 tables, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On-the-fly Modulation for Balanced Multimodal Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11582v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11582v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yake Wei, Di Hu, Henghui Du, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal learning is expected to boost model performance by integrating
information from different modalities. However, its potential is not fully
exploited because the widely-used joint training strategy, which has a uniform
objective for all modalities, leads to imbalanced and under-optimized uni-modal
representations. Specifically, we point out that there often exists modality
with more discriminative information, e.g., vision of playing football and
sound of blowing wind. They could dominate the joint training process,
resulting in other modalities being significantly under-optimized. To alleviate
this problem, we first analyze the under-optimized phenomenon from both the
feed-forward and the back-propagation stages during optimization. Then,
On-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM)
strategies are proposed to modulate the optimization of each modality, by
monitoring the discriminative discrepancy between modalities during training.
Concretely, OPM weakens the influence of the dominant modality by dropping its
feature with dynamical probability in the feed-forward stage, while OGM
mitigates its gradient in the back-propagation stage. In experiments, our
methods demonstrate considerable improvement across a variety of multimodal
tasks. These simple yet effective strategies not only enhance performance in
vanilla and task-oriented multimodal models, but also in more complex
multimodal tasks, showcasing their effectiveness and flexibility. The source
code is available at \url{https://github.com/GeWu-Lab/BML_TPAMI2024}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by T-PAMI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging LLM Embeddings for Cross <span class="highlight-title">Dataset</span> Label Alignment and Zero
  Shot Music Emotion Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renhang Liu, Abhinaba Roy, Dorien Herremans
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present a novel method for music emotion recognition that
leverages Large Language Model (LLM) embeddings for label alignment across
multiple datasets and zero-shot prediction on novel categories. First, we
compute LLM embeddings for emotion labels and apply non-parametric clustering
to group similar labels, across multiple datasets containing disjoint labels.
We use these cluster centers to map music features (MERT) to the LLM embedding
space. To further enhance the model, we introduce an alignment regularization
that enables dissociation of MERT embeddings from different clusters. This
further enhances the model's ability to better adaptation to unseen datasets.
We demonstrate the effectiveness of our approach by performing zero-shot
inference on a new dataset, showcasing its ability to generalize to unseen
labels without additional training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VidCompress: Memory-Enhanced Temporal Compression for Video
  Understanding in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaohan Lan, Yitian Yuan, Zequn Jie, Lin Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video-based multimodal large language models (Video-LLMs) possess significant
potential for video understanding tasks. However, most Video-LLMs treat videos
as a sequential set of individual frames, which results in insufficient
temporal-spatial interaction that hinders fine-grained comprehension and
difficulty in processing longer videos due to limited visual token capacity. To
address these challenges, we propose VidCompress, a novel Video-LLM featuring
memory-enhanced temporal compression. VidCompress employs a dual-compressor
approach: a memory-enhanced compressor captures both short-term and long-term
temporal relationships in videos and compresses the visual tokens using a
multiscale transformer with a memory-cache mechanism, while a text-perceived
compressor generates condensed visual tokens by utilizing Q-Former and
integrating temporal contexts into query embeddings with cross attention.
Experiments on several VideoQA datasets and comprehensive benchmarks
demonstrate that VidCompress efficiently models complex temporal-spatial
relations and significantly outperforms existing Video-LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VIA: Unified Spatiotemporal Video Adaptation Framework for Global and
  Local Video Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12831v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12831v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Gu, Yuwei Fang, Ivan Skorokhodov, Peter Wonka, Xinya Du, Sergey Tulyakov, Xin Eric Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video editing is a cornerstone of digital media, from entertainment and
education to professional communication. However, previous methods often
overlook the necessity of comprehensively understanding both global and local
contexts, leading to inaccurate and inconsistent edits in the spatiotemporal
dimension, especially for long videos. In this paper, we introduce VIA, a
unified spatiotemporal Video Adaptation framework for global and local video
editing, pushing the limits of consistently editing minute-long videos. First,
to ensure local consistency within individual frames, we designed test-time
editing adaptation to adapt a pre-trained image editing model for improving
consistency between potential editing directions and the text instruction, and
adapt masked latent variables for precise local control. Furthermore, to
maintain global consistency over the video sequence, we introduce
spatiotemporal adaptation that recursively gather consistent attention
variables in key frames and strategically applies them across the whole
sequence to realize the editing effects. Extensive experiments demonstrate
that, compared to baseline methods, our VIA approach produces edits that are
more faithful to the source videos, more coherent in the spatiotemporal
context, and more precise in local control. More importantly, we show that VIA
can achieve consistent long video editing in minutes, unlocking the potential
for advanced video editing tasks over long video sequences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FineFake: A Knowledge-Enriched <span class="highlight-title">Dataset</span> for Fine-Grained Multi-Domain
  Fake News Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01336v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01336v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyi Zhou, Xiaoming Zhang, Litian Zhang, Jiacheng Liu, Senzhang Wang, Zheng Liu, Xi Zhang, Chaozhuo Li, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for fake news detection have significantly contributed to
the advancement of models in assessing the authenticity of news content.
However, these benchmarks typically focus solely on news pertaining to a single
semantic topic or originating from a single platform, thereby failing to
capture the diversity of multi-domain news in real scenarios. In order to
understand fake news across various domains, the external knowledge and
fine-grained annotations are indispensable to provide precise evidence and
uncover the diverse underlying strategies for fabrication, which are also
ignored by existing benchmarks. To address this gap, we introduce a novel
multi-domain knowledge-enhanced benchmark with fine-grained annotations, named
\textbf{FineFake}. FineFake encompasses 16,909 data samples spanning six
semantic topics and eight platforms. Each news item is enriched with
multi-modal content, potential social context, semi-manually verified common
knowledge, and fine-grained annotations that surpass conventional binary
labels. Furthermore, we formulate three challenging tasks based on FineFake and
propose a knowledge-enhanced domain adaptation network. Extensive experiments
are conducted on FineFake under various scenarios, providing accurate and
reliable benchmarks for future endeavors. The entire FineFake project is
publicly accessible as an open-source repository at
\url{https://github.com/Accuser907/FineFake}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-14T00:00:00Z">2024-10-14</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SGUQ: Staged Graph Convolution Neural Network for Alzheimer's Disease
  Diagnosis using Multi-Omics Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Tao, Yixin Xie, Jeffrey D Deng, Hui Shen, Hong-Wen Deng, Weihua Zhou, Chen Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Alzheimer's disease (AD) is a chronic neurodegenerative disorder and the
leading cause of dementia, significantly impacting cost, mortality, and burden
worldwide. The advent of high-throughput omics technologies, such as genomics,
transcriptomics, proteomics, and epigenomics, has revolutionized the molecular
understanding of AD. Conventional AI approaches typically require the
completion of all omics data at the outset to achieve optimal AD diagnosis,
which are inefficient and may be unnecessary. To reduce the clinical cost and
improve the accuracy of AD diagnosis using multi-omics data, we propose a novel
staged graph convolutional network with uncertainty quantification (SGUQ). SGUQ
begins with mRNA and progressively incorporates DNA methylation and miRNA data
only when necessary, reducing overall costs and exposure to harmful tests.
Experimental results indicate that 46.23% of the samples can be reliably
predicted using only single-modal omics data (mRNA), while an additional 16.04%
of the samples can achieve reliable predictions when combining two omics data
types (mRNA + DNA methylation). In addition, the proposed staged SGUQ achieved
an accuracy of 0.858 on ROSMAP dataset, which outperformed existing methods
significantly. The proposed SGUQ can not only be applied to AD diagnosis using
multi-omics data but also has the potential for clinical decision-making using
multi-viewed data. Our implementation is publicly available at
https://github.com/chenzhao2023/multiomicsuncertainty.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GraFPrint: A GNN-Based Approach for Audio Identification <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aditya Bhattacharjee, Shubhr Singh, Emmanouil Benetos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces GraFPrint, an audio identification framework that
leverages the structural learning capabilities of Graph Neural Networks (GNNs)
to create robust audio fingerprints. Our method constructs a k-nearest neighbor
(k-NN) graph from time-frequency representations and applies max-relative graph
convolutions to encode local and global information. The network is trained
using a self-supervised contrastive approach, which enhances resilience to
ambient distortions by optimizing feature representation. GraFPrint
demonstrates superior performance on large-scale datasets at various levels of
granularity, proving to be both lightweight and scalable, making it suitable
for real-world applications with extensive reference databases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Model Parameters for Controlling: Parameter Diffusion for
  Controllable Multi-Task Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenglei Shen, Jiahao Zhao, Xiao Zhang, Weijie Yu, Ming He, Jianping Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Commercial recommender systems face the challenge that task requirements from
platforms or users often change dynamically (e.g., varying preferences for
accuracy or diversity). Ideally, the model should be re-trained after resetting
a new objective function, adapting to these changes in task requirements.
However, in practice, the high computational costs associated with retraining
make this process impractical for models already deployed to online
environments. This raises a new challenging problem: how to efficiently adapt
the learning model to different task requirements by controlling model
parameters after deployment, without the need for retraining. To address this
issue, we propose a novel controllable learning approach via Parameter
Diffusion for controllable multi-task Recommendation (PaDiRec), which allows
the customization and adaptation of recommendation model parameters to new task
requirements without retraining. Specifically, we first obtain the optimized
model parameters through adapter tunning based on the feasible task
requirements. Then, we utilize the diffusion model as a parameter generator,
employing classifier-free guidance in conditional training to learn the
distribution of optimized model parameters under various task requirements.
Finally, the diffusion model is applied to effectively generate model
parameters in a test-time adaptation manner given task requirements. As a
model-agnostic approach, PaDiRec can leverage existing recommendation models as
backbones to enhance their controllability. Extensive experiments on public
datasets and a dataset from a commercial app, indicate that PaDiRec can
effectively enhance controllability through efficient model parameter
generation. The code is released at
https://anonymous.4open.science/r/PaDiRec-DD13.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality
  Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is an effective technique that enables
large language models (LLMs) to utilize external knowledge sources for
generation. However, current RAG systems are solely based on text, rendering it
impossible to utilize vision information like layout and images that play
crucial roles in real-world multi-modality documents. In this paper, we
introduce VisRAG, which tackles this issue by establishing a vision-language
model (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the
document to obtain text, the document is directly embedded using a VLM as an
image and then retrieved to enhance the generation of a VLM. Compared to
traditional text-based RAG, VisRAG maximizes the retention and utilization of
the data information in the original documents, eliminating the information
loss introduced during the parsing process. We collect both open-source and
synthetic data to train the retriever in VisRAG and explore a variety of
generation methods. Experiments demonstrate that VisRAG outperforms traditional
RAG in both the retrieval and generation stages, achieving a 25--39\%
end-to-end performance gain over traditional text-based RAG pipeline. Further
analysis reveals that VisRAG is effective in utilizing training data and
demonstrates strong generalization capability, positioning it as a promising
solution for RAG on multi-modality documents. Our code and data are available
at https://github.com/openbmb/visrag .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era
  of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study investigates judgment prediction in a realistic scenario within
the context of Indian judgments, utilizing a range of transformer-based models,
including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and
GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are
predicted at the point when a case is presented for a decision in court, using
only the information available at that time, such as the facts of the case,
statutes, precedents, and arguments. This approach mimics real-world
conditions, where decisions must be made without the benefit of hindsight,
unlike retrospective analyses often found in previous studies. For transformer
models, we experiment with hierarchical transformers and the summarization of
judgment facts to optimize input for these models. Our experiments with LLMs
reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust
performance in judgment prediction. Furthermore, incorporating additional legal
information, such as statutes and precedents, significantly improves the
outcome of the prediction task. The LLMs also provide explanations for their
predictions. To evaluate the quality of these predictions and explanations, we
introduce two human evaluation metrics: Clarity and Linking. Our findings from
both automatic and human evaluations indicate that, despite advancements in
LLMs, they are yet to achieve expert-level performance in judgment prediction
and explanation tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted on NLLP at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Academic Knowledge Retrieval via LLM-enhanced Representation
  Similarity Fusion <span class="chip">KDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Dai, Peng Fu, Chunjing Gan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In an era marked by robust technological growth and swift information
renewal, furnishing researchers and the populace with top-tier, avant-garde
academic insights spanning various domains has become an urgent necessity. The
KDD Cup 2024 AQA Challenge is geared towards advancing retrieval models to
identify pertinent academic terminologies from suitable papers for scientific
inquiries. This paper introduces the LLM-KnowSimFuser proposed by Robo Space,
which wins the 2nd place in the competition. With inspirations drawed from the
superior performance of LLMs on multiple tasks, after careful analysis of the
provided datasets, we firstly perform fine-tuning and inference using
LLM-enhanced pre-trained retrieval models to introduce the tremendous language
understanding and open-domain knowledge of LLMs into this task, followed by a
weighted fusion based on the similarity matrix derived from the inference
results. Finally, experiments conducted on the competition datasets show the
superiority of our proposal, which achieved a score of 0.20726 on the final
leaderboard.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 2nd Place of KDD Cup 2024 OAG-Challenge AQA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Medico: Towards Hallucination Detection and Correction with Multi-source
  Evidence Fusion <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10408v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10408v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Jindi Yu, Zhenyu Liu, Jifang Wang, Dongfang Li, Yibin Chen, Baotian Hu, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As we all know, hallucinations prevail in Large Language Models (LLMs), where
the generated content is coherent but factually incorrect, which inflicts a
heavy blow on the widespread application of LLMs. Previous studies have shown
that LLMs could confidently state non-existent facts rather than answering ``I
don't know''. Therefore, it is necessary to resort to external knowledge to
detect and correct the hallucinated content. Since manual detection and
correction of factual errors is labor-intensive, developing an automatic
end-to-end hallucination-checking approach is indeed a needful thing. To this
end, we present Medico, a Multi-source evidence fusion enhanced hallucination
detection and correction framework. It fuses diverse evidence from multiple
sources, detects whether the generated content contains factual errors,
provides the rationale behind the judgment, and iteratively revises the
hallucinated content. Experimental results on evidence retrieval (0.964 HR@5,
0.908 MRR@5), hallucination detection (0.927-0.951 F1), and hallucination
correction (0.973-0.979 approval rate) manifest the great potential of Medico.
A video demo of Medico can be found at https://youtu.be/RtsO6CSesBI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures, 6 tables. Accepted by EMNLP 2024's demo track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative filtering based on nonnegative/binary matrix factorization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yukino Terui, Yuka Inoue, Yohei Hamakawa, Kosuke Tatsumura, Kazue Kudo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Collaborative filtering generates recommendations based on user-item
similarities through rating data, which may involve numerous unrated items. To
predict scores for unrated items, matrix factorization techniques, such as
nonnegative matrix factorization (NMF), are often employed to predict scores
for unrated items. Nonnegative/binary matrix factorization (NBMF), which is an
extension of NMF, approximates a nonnegative matrix as the product of
nonnegative and binary matrices. Previous studies have employed NBMF for image
analysis where the data were dense. In this paper, we propose a modified NBMF
algorithm that can be applied to collaborative filtering where data are sparse.
In the modified method, unrated elements in a rating matrix are masked, which
improves the collaborative filtering performance. Utilizing a low-latency Ising
machine in NBMF is advantageous in terms of the computation time, making the
proposed method beneficial.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BookWorm: A <span class="highlight-title">Dataset</span> for Character Description and Analysis <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Argyrios Papoudakis, Mirella Lapata, Frank Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Characters are at the heart of every story, driving the plot and engaging
readers. In this study, we explore the understanding of characters in
full-length books, which contain complex narratives and numerous interacting
characters. We define two tasks: character description, which generates a brief
factual profile, and character analysis, which offers an in-depth
interpretation, including character development, personality, and social
context. We introduce the BookWorm dataset, pairing books from the Gutenberg
Project with human-written descriptions and analyses. Using this dataset, we
evaluate state-of-the-art long-context models in zero-shot and fine-tuning
settings, utilizing both retrieval-based and hierarchical processing for
book-length inputs. Our findings show that retrieval-based approaches
outperform hierarchical ones in both tasks. Additionally, fine-tuned models
using coreference-based retrieval produce the most factual descriptions, as
measured by fact- and entailment-based metrics. We hope our dataset,
experiments, and analysis will inspire further research in character-based
narrative understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 2 figures, EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hybrid Filtering for Micro-video Hashtag Recommendation using
  Graph-based Deep Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubhi Bansal, Kushaan Gowda, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Nagendra Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the growing volume of user generated content, hashtags are employed as
topic indicators to manage content efficiently on social media platforms.
However, finding these vital topics is challenging in microvideos since they
contain substantial information in a short duration. Existing methods that
recommend hashtags for microvideos primarily focus on content and
personalization while disregarding relatedness among users. Moreover, the cold
start user issue prevails in hashtag recommendation systems. Considering the
above, we propose a hybrid filtering based MIcro-video haSHtag recommendatiON
MISHON technique to recommend hashtags for micro-videos. Besides content based
filtering, we employ user-based collaborative filtering to enhance
recommendations. Since hashtags reflect users topical interests, we find
similar users based on historical tagging behavior to model user relatedness.
We employ a graph-based deep neural network to model user to user, modality to
modality, and user to modality interactions. We then use refined modality
specific and user representations to recommend pertinent hashtags for
microvideos. The empirical results on three real world datasets demonstrate
that MISHON attains a comparative enhancement of 3.6, 2.8, and 6.5 reported in
percentage concerning the F1 score, respectively. Since cold start users exist
whose historical tagging information is unavailable, we also propose a content
and social influence based technique to model the relatedness of cold start
users with influential users. The proposed solution shows a relative
improvement of 15.8 percent in the F1 score over its content only counterpart.
These results show that the proposed framework mitigates the cold start user
problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parenting: Optimizing Knowledge Selection of Retrieval-Augmented
  Language Models with Parameter Decoupling and Tailored Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10360v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10360v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) offers an effective solution to the
issues faced by Large Language Models (LLMs) in hallucination generation and
knowledge obsolescence by incorporating externally retrieved knowledge.
However, due to potential conflicts between internal and external knowledge, as
well as retrieval noise, LLMs often struggle to effectively integrate external
evidence, leading to a decline in performance. Although existing methods
attempt to tackle these challenges, they often struggle to strike a balance
between model adherence and robustness, resulting in significant learning
variance. Inspired by human cognitive processes, we propose Parenting, a novel
framework that decouples adherence and robustness within the parameter space of
LLMs. Specifically, Parenting utilizes a key parameter mining method based on
forward activation gain to identify and isolate the crucial parameter units
that are strongly linked to adherence and robustness. Then, Parenting employs a
type-guided tailored tuning strategy, applying specific and appropriate
fine-tuning methods to parameter units representing different capabilities,
aiming to achieve a balanced enhancement of adherence and robustness. Extensive
experiments on various datasets and models validate the effectiveness and
generalizability of our methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Attributed Graph Networks with Alignment and Uniformity
  Constraints for Session-based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Chaochao Chen, Jiajie Su, Yizhao Zhang, Baotian Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based Recommendation (SBR), seeking to predict a user's next action
based on an anonymous session, has drawn increasing attention for its
practicability. Most SBR models only rely on the contextual transitions within
a short session to learn item representations while neglecting additional
valuable knowledge. As such, their model capacity is largely limited by the
data sparsity issue caused by short sessions. A few studies have exploited the
Modeling of Item Attributes (MIA) to enrich item representations. However, they
usually involve specific model designs that can hardly transfer to existing
attribute-agnostic SBR models and thus lack universality. In this paper, we
propose a model-agnostic framework, named AttrGAU (Attributed Graph Networks
with Alignment and Uniformity Constraints), to bring the MIA's superiority into
existing attribute-agnostic models, to improve their accuracy and robustness
for recommendation. Specifically, we first build a bipartite attributed graph
and design an attribute-aware graph convolution to exploit the rich attribute
semantics hidden in the heterogeneous item-attribute relationship. We then
decouple existing attribute-agnostic SBR models into the graph neural network
and attention readout sub-modules to satisfy the non-intrusive requirement.
Lastly, we design two representation constraints, i.e., alignment and
uniformity, to optimize distribution discrepancy in representation between the
attribute semantics and collaborative semantics. Extensive experiments on three
public benchmark datasets demonstrate that the proposed AttrGAU framework can
significantly enhance backbone models' recommendation performance and
robustness against data sparsity and data noise issues. Our implementation
codes will be available at https://github.com/ItsukiFujii/AttrGAU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures, 5 tables. Accepted by ICWS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10293v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10293v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang Li, Baotian Hu, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It
mainly consists of retrieval and generation. The retrieval modules (a.k.a.
retrievers) aim to find useful information used to facilitate generation
modules (a.k.a. generators). As such, generators' performance largely depends
on the effectiveness and efficiency of retrievers. However, the retrieval
paradigm that we design and use remains flat, which treats the retrieval
procedures as a one-off deal with constant granularity. Despite effectiveness,
we argue that they suffer from two limitations: (1) flat retrieval exerts a
significant burden on one retriever; (2) constant granularity limits the
ceiling of retrieval performance. In this work, we propose a progressive
retrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,
so as to balance effectiveness and efficiency. Specifically, FunnelRAG
establishes a progressive retrieval pipeline by collaborating coarse-to-fine
granularity, large-to-small quantity, and low-to-high capacity, which can
relieve the burden on one retriever and also promote the ceiling of retrieval
performance. Extensive experiments manifest that FunnelRAG achieves comparable
retrieval performance while the time overhead is reduced by nearly 40 percent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 6 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Back-of-the-Book Index Automation for Arabic Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10286v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10286v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nawal Haidar, Fadi A. Zaraket
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Back-of-the-book indexes are crucial for book readability. Their manual
creation is laborious and error prone. In this paper, we consider automating
back-of-the-book index extraction for Arabic books to help simplify both the
creation and review tasks. Given a back-of-the-book index, we aim to check and
identify the accurate occurrences of index terms relative to the associated
pages. To achieve this, we first define a pool of candidates for each term by
extracting all possible noun phrases from paragraphs appearing on the relevant
index pages. These noun phrases, identified through part-of-speech analysis,
are stored in a vector database for efficient retrieval. We use several
metrics, including exact matches, lexical similarity, and semantic similarity,
to determine the most appropriate occurrence. The candidate with the highest
score based on these metrics is chosen as the occurrence of the term. We
fine-tuned a heuristic method, that considers the above metrics and that
achieves an F1-score of .966 (precision=.966, recall=.966). These excellent
results open the door for future work related to automation of back-of-the-book
index generation and checking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DecKG: Decentralized Collaborative Learning with Knowledge Graph
  Enhancement for POI Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiqi Zheng, Liang Qu, Guanhua Ye, Tong Chen, Yuhui Shi, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decentralized collaborative learning for Point-of-Interest (POI)
recommendation has gained research interest due to its advantages in privacy
preservation and efficiency, as it keeps data locally and leverages
collaborative learning among clients to train models in a decentralized manner.
However, since local data is often limited and insufficient for training
accurate models, a common solution is integrating external knowledge as
auxiliary information to enhance model performance. Nevertheless, this solution
poses challenges for decentralized collaborative learning. Due to private
nature of local data, identifying relevant auxiliary information specific to
each user is non-trivial. Furthermore, resource-constrained local devices
struggle to accommodate all auxiliary information, which places heavy burden on
local storage. To fill the gap, we propose a novel decentralized collaborative
learning with knowledge graph enhancement framework for POI recommendation
(DecKG). Instead of directly uploading interacted items, users generate
desensitized check-in data by uploading general categories of interacted items
and sampling similar items from same category. The server then pretrains KG
without sensitive user-item interactions and deploys relevant partitioned
sub-KGs to individual users. Entities are further refined on the device,
allowing client to client communication to exchange knowledge learned from
local data and sub-KGs. Evaluations across two real-world datasets demonstrate
DecKG's effectiveness recommendation performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MAIR: A Massive Benchmark for Evaluating Instructed Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10127v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10127v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiwei Sun, Zhengliang Shi, Jiulong Wu, Lingyong Yan, Xinyu Ma, Yiding Liu, Min Cao, Dawei Yin, Zhaochun Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent information retrieval (IR) models are pre-trained and
instruction-tuned on massive datasets and tasks, enabling them to perform well
on a wide range of tasks and potentially generalize to unseen tasks with
instructions. However, existing IR benchmarks focus on a limited scope of
tasks, making them insufficient for evaluating the latest IR models. In this
paper, we propose MAIR (Massive Instructed Retrieval Benchmark), a
heterogeneous IR benchmark that includes 126 distinct IR tasks across 6
domains, collected from existing datasets. We benchmark state-of-the-art
instruction-tuned text embedding models and re-ranking models. Our experiments
reveal that instruction-tuned models generally achieve superior performance
compared to non-instruction-tuned models on MAIR. Additionally, our results
suggest that current instruction-tuned text embedding models and re-ranking
models still lack effectiveness in specific long-tail tasks. MAIR is publicly
available at https://github.com/sunnweiwei/Mair.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Feature Decorrelation in Cloth-Changing Person Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05536v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05536v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjun Wang, Jiyuan Chen, Renhe Jiang, Xuan Song, Yinqiang Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cloth-changing person re-identification (CC-ReID) poses a significant
challenge in computer vision. A prevailing approach is to prompt models to
concentrate on causal attributes, like facial features and hairstyles, rather
than confounding elements such as clothing appearance. Traditional methods to
achieve this involve integrating multi-modality data or employing manually
annotated clothing labels, which tend to complicate the model and require
extensive human effort. In our study, we demonstrate that simply reducing
feature correlations during training can significantly enhance the baseline
model's performance. We theoretically elucidate this effect and introduce a
novel regularization technique based on density ratio estimation. This
technique aims to minimize feature correlation in the training process of
cloth-changing ReID baselines. Our approach is model-independent, offering
broad enhancements without needing additional data or labels. We validate our
method through comprehensive experiments on prevalent CC-ReID datasets, showing
its effectiveness in improving baseline models' generalization capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pure Message Passing Can Estimate Common Neighbor for Link Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.00976v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.00976v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiwen Dong, Zhichun Guo, Nitesh V. Chawla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto}
standard in graph representation learning. However, when it comes to link
prediction, they often struggle, surpassed by simple heuristics such as Common
Neighbor (CN). This discrepancy stems from a fundamental limitation: while
MPNNs excel in node-level representation, they stumble with encoding the joint
structural features essential to link prediction, like CN. To bridge this gap,
we posit that, by harnessing the orthogonality of input vectors, pure
message-passing can indeed capture joint structural features. Specifically, we
study the proficiency of MPNNs in approximating CN heuristics. Based on our
findings, we introduce the Message Passing Link Predictor (MPLP), a novel link
prediction model. MPLP taps into quasi-orthogonal vectors to estimate
link-level structural features, all while preserving the node-level
complexities. Moreover, our approach demonstrates that leveraging
message-passing to capture structural features could offset MPNNs'
expressiveness limitations at the expense of estimation variance. We conduct
experiments on benchmark datasets from various domains, where our method
consistently outperforms the baseline methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Neurips'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ mGTE: Generalized Long-Context Text Representation and Reranking Models
  for Multilingual Text Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.19669v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.19669v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie, Ziqi Dai, Jialong Tang, Huan Lin, Baosong Yang, Pengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present systematic efforts in building long-context multilingual text
representation model (TRM) and reranker from scratch for text retrieval. We
first introduce a text encoder (base size) enhanced with RoPE and unpadding,
pre-trained in a native 8192-token context (longer than 512 of previous
multilingual encoders). Then we construct a hybrid TRM and a cross-encoder
reranker by contrastive learning. Evaluations show that our text encoder
outperforms the same-sized previous state-of-the-art XLM-R. Meanwhile, our TRM
and reranker match the performance of large-sized state-of-the-art BGE-M3
models and achieve better results on long-context retrieval benchmarks. Further
analysis demonstrate that our proposed models exhibit higher efficiency during
both training and inference. We believe their efficiency and effectiveness
could benefit various researches and industrial applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready version of EMNLP 2024: Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized Item Representations in Federated Multimodal Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08478v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08478v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiwei Li, Guodong Long, Jing Jiang, Chengqi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated recommendation systems are essential for providing personalized
recommendations while protecting user privacy. However, current methods mainly
rely on ID-based item embeddings, neglecting the rich multimodal information of
items. To address this, we propose a Federated Multimodal Recommendation
System, called FedMR. FedMR uses a foundation model on the server to encode
multimodal item data, such as images and text. To handle data heterogeneity
caused by user preference differences, FedMR introduces a Mixing Feature Fusion
Module on each client, which adjusts fusion strategy weights based on user
interaction history to generate personalized item representations that capture
users' fine-grained preferences. FedMR is compatible with existing ID-based
federated recommendation systems, improving performance without modifying the
original framework. Experiments on four real-world multimodal datasets
demonstrate FedMR's effectiveness. The code is available at
https://anonymous.4open.science/r/FedMR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures, 5 tables, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent
  Classification <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.16504v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.16504v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-turn intent classification is notably challenging due to the complexity
and evolving nature of conversational contexts. This paper introduces LARA, a
Linguistic-Adaptive Retrieval-Augmentation framework to enhance accuracy in
multi-turn classification tasks across six languages, accommodating a large
number of intents in chatbot interactions. LARA combines a fine-tuned smaller
model with a retrieval-augmented mechanism, integrated within the architecture
of LLMs. The integration allows LARA to dynamically utilize past dialogues and
relevant intents, thereby improving the understanding of the context.
Furthermore, our adaptive retrieval techniques bolster the cross-lingual
capabilities of LLMs without extensive retraining and fine-tuning.
Comprehensive experiments demonstrate that LARA achieves state-of-the-art
performance on multi-turn intent classification tasks, enhancing the average
accuracy by 3.67\% from state-of-the-art single-turn intent classifiers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Model Powered Digital Biology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Pickard, Marc Andrew Choi, Natalie Oliven, Cooper Stansbury, Jillian Cwycyshyn, Nicholas Galioto, Alex Gorodetsky, Alvaro Velasquez, Indika Rajapakse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) are transforming biology,
computer science, and many other research fields, as well as impacting everyday
life. While transformer-based technologies are currently being deployed in
biology, no available agentic system has been developed to tackle
bioinformatics workflows. We present a prototype Bioinformatics Retrieval
Augmented Data (BRAD) digital assistant. BRAD is a chatbot and agentic system
that integrates a suite of tools to handle bioinformatics tasks, from code
execution to online search. We demonstrate its capabilities through (1)
improved question-and-answering with retrieval augmented generation (RAG), (2)
the ability to run complex software pipelines, and (3) the ability to organize
and distribute tasks in agentic workflows. We use BRAD for automation,
performing tasks ranging from gene enrichment and searching the archive to
automatic code generation for running biomarker identification pipelines. BRAD
is a step toward autonomous, self-driving labs for digital biology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 3 tables, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Dense Retrievers' Robustness with Group-level Reweighting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.16605v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.16605v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peixuan Han, Zhenghao Liu, Zhiyuan Liu, Chenyan Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The anchor-document data derived from web graphs offers a wealth of paired
information for training dense retrieval models in an unsupervised manner.
However, unsupervised data contains diverse patterns across the web graph and
often exhibits significant imbalance, leading to suboptimal performance in
underrepresented or difficult groups. In this paper, we introduce WebDRO, an
efficient approach for clustering the web graph data and optimizing group
weights to enhance the robustness of dense retrieval models. Initially, we
build an embedding model for clustering anchor-document pairs. Specifically, we
contrastively train the embedding model for link prediction, which guides the
embedding model in capturing the document features behind the web graph links.
Subsequently, we employ the group distributional robust optimization to
recalibrate the weights across different clusters of anchor-document pairs
during training retrieval models. During training, we direct the model to
assign higher weights to clusters with higher loss and focus more on worst-case
scenarios. This approach ensures that the model has strong generalization
ability on all data patterns. Our experiments on MS MARCO and BEIR demonstrate
that our method can effectively improve retrieval performance in unsupervised
training and finetuning settings. Further analysis confirms the stability and
validity of group weights learned by WebDRO. The code of this paper can be
obtained from https://github.com/Hanpx20/GroupDRO_Dense_Retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatial-Aware Efficient Projector for MLLMs via Multi-Layer Feature
  Aggregation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shun Qian, Bingquan Liu, Chengjie Sun, Zhen Xu, Baoxun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The projector plays a crucial role in multi-modal language models (MLLMs).
The number of visual tokens it outputs affects the efficiency of the MLLM,
while the quality of the visual tokens influences the visual understanding
capabilities of the MLLM. Current explorations on the projector focus on
reducing the number of visual tokens to improve efficiency, often overlooking
the inherent spatial discrepancy between the serialized 2-dimensional visual
token sequences and natural language token sequences. A Spatial-Aware Efficient
Projector (SAEP) is proposed to address this issue. In detail, our SAEP method
employs an modified separable depthwise convolution module on multi-layer
visual features to enhance the spatial information of visual tokens. As a
result, our SAEP method can not only largely reduce the number of visual tokens
by 75\%, but also significantly improve the multimodal spatial understanding
capability of MLLMs. Moreover, compared to existing projectors, our SAEP gets
best performances on massive multimodal evaluation benchmarks, which denotes
its effectiveness on bridging the modality gap.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10291v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10291v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our benchmark and code are available at
  https://github.com/zhuxiangru/SemVarBench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GUISE: Graph GaUssIan Shading watErmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.10178v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.10178v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renyi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the expanding field of generative artificial intelligence, integrating
robust watermarking technologies is essential to protect intellectual property
and maintain content authenticity. Traditionally, watermarking techniques have
been developed primarily for rich information media such as images and audio.
However, these methods have not been adequately adapted for graph-based data,
particularly molecular graphs. Latent 3D graph diffusion(LDM-3DG) is an
ascendant approach in the molecular graph generation field. This model
effectively manages the complexities of molecular structures, preserving
essential symmetries and topological features. We adapt the Gaussian Shading, a
proven performance lossless watermarking technique, to the latent graph
diffusion domain to protect this sophisticated new technology. Our adaptation
simplifies the watermark diffusion process through duplication and padding,
making it adaptable and suitable for various message types. We conduct several
experiments using the LDM-3DG model on publicly available datasets QM9 and
Drugs, to assess the robustness and effectiveness of our technique. Our results
demonstrate that the watermarked molecules maintain statistical parity in 9 out
of 10 performance metrics compared to the original. Moreover, they exhibit a
100% detection rate and a 99% extraction rate in a 2D decoded pipeline, while
also showing robustness against post-editing attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Audio-Visual Deepfakes with Fine-Grained Inconsistencies <span class="chip">BMVC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06753v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06753v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcella Astrid, Enjie Ghorbel, Djamila Aouada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods on audio-visual deepfake detection mainly focus on
high-level features for modeling inconsistencies between audio and visual data.
As a result, these approaches usually overlook finer audio-visual artifacts,
which are inherent to deepfakes. Herein, we propose the introduction of
fine-grained mechanisms for detecting subtle artifacts in both spatial and
temporal domains. First, we introduce a local audio-visual model capable of
capturing small spatial regions that are prone to inconsistencies with audio.
For that purpose, a fine-grained mechanism based on a spatially-local distance
coupled with an attention module is adopted. Second, we introduce a
temporally-local pseudo-fake augmentation to include samples incorporating
subtle temporal inconsistencies in our training set. Experiments on the DFDC
and the FakeAVCeleb datasets demonstrate the superiority of the proposed method
in terms of generalization as compared to the state-of-the-art under both
in-dataset and cross-dataset settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in BMVC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Track MusicLDM: Towards Versatile Music Generation with Latent
  Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02845v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02845v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tornike Karchkhadze, Mohammad Rasool Izadi, Ke Chen, Gerard Assayag, Shlomo Dubnov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have shown promising results in cross-modal generation tasks
involving audio and music, such as text-to-sound and text-to-music generation.
These text-controlled music generation models typically focus on generating
music by capturing global musical attributes like genre and mood. However,
music composition is a complex, multilayered task that often involves musical
arrangement as an integral part of the process. This process involves composing
each instrument to align with existing ones in terms of beat, dynamics,
harmony, and melody, requiring greater precision and control over tracks than
text prompts usually provide. In this work, we address these challenges by
extending the MusicLDM, a latent diffusion model for music, into a multi-track
generative model. By learning the joint probability of tracks sharing a
context, our model is capable of generating music across several tracks that
correspond well to each other, either conditionally or unconditionally.
Additionally, our model is capable of arrangement generation, where the model
can generate any subset of tracks given the others (e.g., generating a piano
track complementing given bass and drum tracks). We compared our model with an
existing multi-track generative model and demonstrated that our model achieves
considerable improvements across objective metrics for both total and
arrangement generation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Proceedings of The second international workshop on eXplainable AI for
  the Arts (XAIxArts) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14485v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14485v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nick Bryan-Kinns, Corey Ford, Shuoyang Zheng, Helen Kennedy, Alan Chamberlain, Makayla Lewis, Drew Hemment, Zijin Li, Qiong Wu, Lanxi Xiao, Gus Xia, Jeba Rezwana, Michael Clemens, Gabriel Vigliensoni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This second international workshop on explainable AI for the Arts (XAIxArts)
brought together a community of researchers in HCI, Interaction Design, AI,
explainable AI (XAI), and digital arts to explore the role of XAI for the Arts.
Workshop held at the 16th ACM Conference on Creativity and Cognition (C&C
2024), Chicago, USA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of The second international workshop on eXplainable AI
  for the Arts (XAIxArts)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Multimodal Learning with Multi-Loss Gradient Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.07930v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.07930v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantinos Kontras, Christos Chatzichristos, Matthew Blaschko, Maarten De Vos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from multiple modalities, such as audio and video, offers
opportunities for leveraging complementary information, enhancing robustness,
and improving contextual understanding and performance. However, combining such
modalities presents challenges, especially when modalities differ in data
structure, predictive contribution, and the complexity of their learning
processes. It has been observed that one modality can potentially dominate the
learning process, hindering the effective utilization of information from other
modalities and leading to sub-optimal model performance. To address this issue
the vast majority of previous works suggest to assess the unimodal
contributions and dynamically adjust the training to equalize them. We improve
upon previous work by introducing a multi-loss objective and further refining
the balancing process, allowing it to dynamically adjust the learning pace of
each modality in both directions, acceleration and deceleration, with the
ability to phase out balancing effects upon convergence. We achieve superior
results across three audio-video datasets: on CREMA-D, models with ResNet
backbone encoders surpass the previous best by 1.9% to 12.4%, and Conformer
backbone models deliver improvements ranging from 2.8% to 14.1% across
different fusion methods. On AVE, improvements range from 2.7% to 7.7%, while
on UCF101, gains reach up to 6.1%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with
  Panoramic Gaussian Splatting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13711v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13711v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenrui Li, Fucheng Cai, Yapeng Mi, Zhe Yang, Wangmeng Zuo, Xingtao Wang, Xiaopeng Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-driven 3D scene generation has seen significant advancements recently.
However, most existing methods generate single-view images using generative
models and then stitch them together in 3D space. This independent generation
for each view often results in spatial inconsistency and implausibility in the
3D scenes. To address this challenge, we proposed a novel text-driven
3D-consistent scene generation model: SceneDreamer360. Our proposed method
leverages a text-driven panoramic image generation model as a prior for 3D
scene generation and employs 3D Gaussian Splatting (3DGS) to ensure consistency
across multi-view panoramic images. Specifically, SceneDreamer360 enhances the
fine-tuned Panfusion generator with a three-stage panoramic enhancement,
enabling the generation of high-resolution, detail-rich panoramic images.
During the 3D scene construction, a novel point cloud fusion initialization
method is used, producing higher quality and spatially consistent point clouds.
Our extensive experiments demonstrate that compared to other methods,
SceneDreamer360 with its panoramic image generation and 3DGS can produce higher
quality, spatially consistent, and visually appealing 3D scenes from any text
prompt. Our codes are available at
\url{https://github.com/liwrui/SceneDreamer360}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-13T00:00:00Z">2024-10-13</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Customer Feedback for Multi-modal Insight Extraction <span class="chip">NAACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Sricharan Mukku, Abinesh Kanagarajan, Pushpendu Ghosh, Chetan Aggarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Businesses can benefit from customer feedback in different modalities, such
as text and images, to enhance their products and services. However, it is
difficult to extract actionable and relevant pairs of text segments and images
from customer feedback in a single pass. In this paper, we propose a novel
multi-modal method that fuses image and text information in a latent space and
decodes it to extract the relevant feedback segments using an image-text
grounded text decoder. We also introduce a weakly-supervised data generation
technique that produces training data for this task. We evaluate our model on
unseen data and demonstrate that it can effectively mine actionable insights
from multi-modal customer feedback, outperforming the existing baselines by
$14$ points in F1 score.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Rank for Multiple Retrieval-Augmented Models through
  Iterative Utility Maximization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09942v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09942v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Salemi, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the design of a unified search engine to serve
multiple retrieval-augmented generation (RAG) agents, each with a distinct
task, backbone large language model (LLM), and retrieval-augmentation strategy.
We introduce an iterative approach where the search engine generates retrieval
results for these RAG agents and gathers feedback on the quality of the
retrieved documents during an offline phase. This feedback is then used to
iteratively optimize the search engine using a novel expectation-maximization
algorithm, with the goal of maximizing each agent's utility function.
Additionally, we adapt this approach to an online setting, allowing the search
engine to refine its behavior based on real-time individual agents feedback to
better serve the results for each of them. Experiments on diverse datasets from
the Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our
approach significantly on average outperforms competitive baselines across 18
RAG models. We also demonstrate that our method effectively ``personalizes''
the retrieval process for each RAG agent based on the collected feedback.
Finally, we provide a comprehensive ablation study to explore various aspects
of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Role of Fake Users in Sequential Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09936v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09936v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Filippo Betello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential Recommender Systems (SRSs) are widely used to model user behavior
over time, yet their robustness remains an under-explored area of research. In
this paper, we conduct an empirical study to assess how the presence of fake
users, who engage in random interactions, follow popular or unpopular items, or
focus on a single genre, impacts the performance of SRSs in real-world
scenarios. We evaluate two SRS models across multiple datasets, using
established metrics such as Normalized Discounted Cumulative Gain (NDCG) and
Rank Sensitivity List (RLS) to measure performance. While traditional metrics
like NDCG remain relatively stable, our findings reveal that the presence of
fake users severely degrades RLS metrics, often reducing them to near-zero
values. These results highlight the need for further investigation into the
effects of fake users on training data and emphasize the importance of
developing more resilient SRSs that can withstand different types of
adversarial attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analysis and Design of a Personalized Recommendation System Based on a
  Dynamic User Interest Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09923v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09923v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chunyan Mao, Shuaishuai Huang, Mingxiu Sui, Haowei Yang, Xueshe Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of the internet and the explosion of information,
providing users with accurate personalized recommendations has become an
important research topic. This paper designs and analyzes a personalized
recommendation system based on a dynamic user interest model. The system
captures user behavior data, constructs a dynamic user interest model, and
combines multiple recommendation algorithms to provide personalized content to
users. The research results show that this system significantly improves
recommendation accuracy and user satisfaction. This paper discusses the
system's architecture design, algorithm implementation, and experimental
results in detail and explores future research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person
  Re-identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09875v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09875v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Mao, Chong Tan, Jingqi Hu, Min Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Person re-identification(ReID), as a crucial technology in the field of
security, plays a vital role in safety inspections, personnel counting, and
more. Most current ReID approaches primarily extract features from images,
which are easily affected by objective conditions such as clothing changes and
occlusions. In addition to cameras, we leverage widely available routers as
sensing devices by capturing gait information from pedestrians through the
Channel State Information (CSI) in WiFi signals and contribute a multimodal
dataset. We employ a two-stream network to separately process video
understanding and signal analysis tasks, and conduct multi-modal fusion and
contrastive learning on pedestrian video and WiFi data. Extensive experiments
in real-world scenarios demonstrate that our method effectively uncovers the
correlations between heterogeneous data, bridges the gap between visual and
signal modalities, significantly expands the sensing range, and improves ReID
accuracy across multiple sensors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Comparative Study of PDF Parsing Tools Across Diverse Document
  Categories 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09871v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09871v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Narayan S. Adhikari, Shradha Agarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  PDF is one of the most prominent data formats, making PDF parsing crucial for
information extraction and retrieval, particularly with the rise of RAG
systems. While various PDF parsing tools exist, their effectiveness across
different document types remains understudied, especially beyond academic
papers. Our research aims to address this gap by comparing 10 popular PDF
parsing tools across 6 document categories using the DocLayNet dataset. These
tools include PyPDF, pdfminer.six, PyMuPDF, pdfplumber, pypdfium2,
Unstructured, Tabula, Camelot, as well as the deep learning-based tools Nougat
and Table Transformer(TATR). We evaluated both text extraction and table
detection capabilities. For text extraction, PyMuPDF and pypdfium generally
outperformed others, but all parsers struggled with Scientific and Patent
documents. For these challenging categories, learning-based tools like Nougat
demonstrated superior performance. In table detection, TATR excelled in the
Financial, Patent, Law & Regulations, and Scientific categories. Table
detection tool Camelot performed best for tender documents, while PyMuPDF
performed superior in the Manual category. Our findings highlight the
importance of selecting appropriate parsing tools based on document type and
specific tasks, providing valuable insights for researchers and practitioners
working with diverse document sources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages,11 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Driving Simulations via Conversation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rimvydas Rubavicius, Antonio Valerio Miceli-Barone, Alex Lascarides, Subramanian Ramamoorthy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cyber-physical systems like autonomous vehicles are tested in simulation
before deployment, using domain-specific programs for scenario specification.
To aid the testing of autonomous vehicles in simulation, we design a natural
language interface, using an instruction-following large language model, to
assist a non-coding domain expert in synthesising the desired scenarios and
vehicle behaviours. We show that using it to convert utterances to the symbolic
program is feasible, despite the very small training dataset. Human experiments
show that dialogue is critical to successful simulation generation, leading to
a 4.5 times higher success rate than a generation without engaging in extended
conversation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For
  Restless Bandits Via Deep RL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09781v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09781v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhanqiu Guo, Wayne Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study introduces ContextWIN, a novel architecture that extends the
Neural Whittle Index Network (NeurWIN) model to address Restless Multi-Armed
Bandit (RMAB) problems with a context-aware approach. By integrating a mixture
of experts within a reinforcement learning framework, ContextWIN adeptly
utilizes contextual information to inform decision-making in dynamic
environments, particularly in recommendation systems. A key innovation is the
model's ability to assign context-specific weights to a subset of NeurWIN
networks, thus enhancing the efficiency and accuracy of the Whittle index
computation for each arm. The paper presents a thorough exploration of
ContextWIN, from its conceptual foundation to its implementation and potential
applications. We delve into the complexities of RMABs and the significance of
incorporating context, highlighting how ContextWIN effectively harnesses these
elements. The convergence of both the NeurWIN and ContextWIN models is
rigorously proven, ensuring theoretical robustness. This work lays the
groundwork for future advancements in applying contextual information to
complex decision-making scenarios, recognizing the need for comprehensive
dataset exploration and environment development for full potential realization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ChartKG: A Knowledge-Graph-Based Representation for Chart Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiguang Zhou, Haoxuan Wang, Zhengqing Zhao, Fengling Zheng, Yongheng Wang, Wei Chen, Yong Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chart images, such as bar charts, pie charts, and line charts, are
explosively produced due to the wide usage of data visualizations. Accordingly,
knowledge mining from chart images is becoming increasingly important, which
can benefit downstream tasks like chart retrieval and knowledge graph
completion. However, existing methods for chart knowledge mining mainly focus
on converting chart images into raw data and often ignore their visual
encodings and semantic meanings, which can result in information loss for many
downstream tasks. In this paper, we propose ChartKG, a novel knowledge graph
(KG) based representation for chart images, which can model the visual elements
in a chart image and semantic relations among them including visual encodings
and visual insights in a unified manner. Further, we develop a general
framework to convert chart images to the proposed KG-based representation. It
integrates a series of image processing techniques to identify visual elements
and relations, e.g., CNNs to classify charts, yolov5 and optical character
recognition to parse charts, and rule-based methods to construct graphs. We
present four cases to illustrate how our knowledge-graph-based representation
can model the detailed visual elements and semantic relations in charts, and
further demonstrate how our approach can benefit downstream applications such
as semantic-aware chart retrieval and chart question answering. We also conduct
quantitative evaluations to assess the two fundamental building blocks of our
chart-to-KG framework, i.e., object recognition and optical character
recognition. The results provide support for the usefulness and effectiveness
of ChartKG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Online Digital Investigative Journalism using SociaLens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11890v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11890v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hasan M. Jamil, Sajratul Y. Rubaiat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Media companies witnessed a significant transformation with the rise of the
internet, bigdata, machine learning (ML) and AI. Recent emergence of large
language models (LLM) have added another aspect to this transformation.
Researchers believe that with the help of these technologies, investigative
digital journalism will enter a new era. Using a smart set of data gathering
and analysis tools, journalists will be able to create data driven contents and
insights in unprecedented ways. In this paper, we introduce a versatile and
autonomous investigative journalism tool, called {\em SociaLens}, for
identifying and extracting query specific data from online sources, responding
to probing queries and drawing conclusions entailed by large volumes of data
using ML analytics fully autonomously. We envision its use in investigative
journalism, law enforcement and social policy planning. The proposed system
capitalizes on the integration of ML technology with LLMs and advanced bigdata
search techniques. We illustrate the functionality of SociaLens using a focused
case study on rape incidents in a developing country and demonstrate that
journalists can gain nuanced insights without requiring coding expertise they
might lack. SociaLens is designed as a ChatBot that is capable of contextual
conversation, find and collect data relevant to queries, initiate ML tasks to
respond to queries, generate textual and visual reports, all fully autonomously
within the ChatBot environment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agentic Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weinan Zhang, Junwei Liao, Ning Li, Kounianhua Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  What will information entry look like in the next generation of digital
products? Since the 1970s, user access to relevant information has relied on
domain-specific architectures of information retrieval (IR). Over the past two
decades, the advent of modern IR systems, including web search engines and
personalized recommender systems, has greatly improved the efficiency of
retrieving relevant information from vast data corpora. However, the core
paradigm of these IR systems remains largely unchanged, relying on filtering a
predefined set of candidate items. Since 2022, breakthroughs in large language
models (LLMs) have begun transforming how information is accessed, establishing
a new technical paradigm. In this position paper, we introduce Agentic
Information Retrieval (Agentic IR), a novel IR paradigm shaped by the
capabilities of LLM agents. Agentic IR expands the scope of accessible tasks
and leverages a suite of new techniques to redefine information retrieval. We
discuss three types of cutting-edge applications of agentic IR and the
challenges faced. We propose that agentic IR holds promise for generating
innovative applications, potentially becoming a central information entry point
in future digital ecosystems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, position paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Col<span class="highlight-title">BERT</span> Retrieval and Ensemble Response Scoring for Language Model
  Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Gichamba, Tewodros Kederalah Idris, Brian Ebiyau, Eric Nyberg, Teruko Mitamura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain-specific question answering remains challenging for language models,
given the deep technical knowledge required to answer questions correctly. This
difficulty is amplified for smaller language models that cannot encode as much
information in their parameters as larger models. The "Specializing Large
Language Models for Telecom Networks" challenge aimed to enhance the
performance of two small language models, Phi-2 and Falcon-7B in
telecommunication question answering. In this paper, we present our question
answering systems for this challenge. Our solutions achieved leading marks of
81.9% accuracy for Phi-2 and 57.3% for Falcon-7B. We have publicly released our
code and fine-tuned models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 2 figures, and 8 tables. This paper has been accepted at the
  2024 IEEE Global Communications (GLOBECOM) Workshops</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating D-MERIT of Partial-annotation on Information Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16048v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16048v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Royi Rassin, Yaron Fairstein, Oren Kalinsky, Guy Kushilevitz, Nachshon Cohen, Alexander Libov, Yoav Goldberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval models are often evaluated on partially-annotated datasets. Each
query is mapped to a few relevant texts and the remaining corpus is assumed to
be irrelevant. As a result, models that successfully retrieve false negatives
are punished in evaluation. Unfortunately, completely annotating all texts for
every query is not resource efficient. In this work, we show that using
partially-annotated datasets in evaluation can paint a distorted picture. We
curate D-MERIT, a passage retrieval evaluation set from Wikipedia, aspiring to
contain all relevant passages for each query. Queries describe a group (e.g.,
"journals about linguistics") and relevant passages are evidence that entities
belong to the group (e.g., a passage indicating that "Language" is a journal
about linguistics). We show that evaluating on a dataset containing annotations
for only a subset of the relevant passages might result in misleading ranking
of the retrieval systems and that as more relevant texts are included in the
evaluation set, the rankings converge. We propose our dataset as a resource for
evaluation and our study as a recommendation for balance between
resource-efficiency and reliable evaluation when annotating evaluation sets for
text retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 main track. Our dataset can be downloaded from
  https://D-MERIT.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Grained Embedding Dimension Optimization During Training for
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinyi Luo, Penghan Wang, Wei Zhang, Fan Lai, Jiachen Mao, Xiaohan Wei, Jun Song, Wei-Yu Tsai, Shuai Yang, Yuxi Hu, Xuehai Qian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Huge embedding tables in modern deep learning recommender models (DLRM)
require prohibitively large memory during training and inference. This paper
proposes FIITED, a system to automatically reduce the memory footprint via
FIne-grained In-Training Embedding Dimension pruning. By leveraging the key
insight that embedding vectors are not equally important, FIITED adaptively
adjusts the dimension of each individual embedding vector during model
training, assigning larger dimensions to more important embeddings while
adapting to dynamic changes in data. We prioritize embedding dimensions with
higher frequencies and gradients as more important. To enable efficient pruning
of embeddings and their dimensions during model training, we propose an
embedding storage system based on virtually-hashed physically-indexed hash
tables. Experiments on two industry models and months of realistic datasets
show that FIITED can reduce DLRM embedding size by more than 65% while
preserving model quality, outperforming state-of-the-art in-training embedding
pruning methods. On public datasets, FIITED can reduce the size of embedding
tables by 2.1x to 800x with negligible accuracy drop, while improving model
throughput.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EHI: End-to-end Learning of Hierarchical Index for Efficient Dense
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.08891v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.08891v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramnath Kumar, Anshul Mittal, Nilesh Gupta, Aditya Kusupati, Inderjit Dhillon, Prateek Jain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense embedding-based retrieval is widely used for semantic search and
ranking. However, conventional two-stage approaches, involving contrastive
embedding learning followed by approximate nearest neighbor search (ANNS), can
suffer from misalignment between these stages. This mismatch degrades retrieval
performance. We propose End-to-end Hierarchical Indexing (EHI), a novel method
that directly addresses this issue by jointly optimizing embedding generation
and ANNS structure. EHI leverages a dual encoder for embedding queries and
documents while simultaneously learning an inverted file index (IVF)-style tree
structure. To facilitate the effective learning of this discrete structure, EHI
introduces dense path embeddings that encodes the path traversed by queries and
documents within the tree. Extensive evaluations on standard benchmarks,
including MS MARCO (Dev set) and TREC DL19, demonstrate EHI's superiority over
traditional ANNS index. Under the same computational constraints, EHI
outperforms existing state-of-the-art methods by +1.45% in MRR@10 on MS MARCO
(Dev) and +8.2% in nDCG@10 on TREC DL19, highlighting the benefits of our
end-to-end approach.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Reproducible Learning-based Compression <span class="chip">SP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Pang, Muhammad Asad Lodhi, Junghyun Ahn, Yuning Huang, Dong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A deep learning system typically suffers from a lack of reproducibility that
is partially rooted in hardware or software implementation details. The
irreproducibility leads to skepticism in deep learning technologies and it can
hinder them from being deployed in many applications. In this work, the
irreproducibility issue is analyzed where deep learning is employed in
compression systems while the encoding and decoding may be run on devices from
different manufacturers. The decoding process can even crash due to a single
bit difference, e.g., in a learning-based entropy coder. For a given deep
learning-based module with limited resources for protection, we first suggest
that reproducibility can only be assured when the mismatches are bounded. Then
a safeguarding mechanism is proposed to tackle the challenges. The proposed
method may be applied for different levels of protection either at the
reconstruction level or at a selected decoding level. Furthermore, the overhead
introduced for the protection can be scaled down accordingly when the error
bound is being suppressed. Experiments demonstrate the effectiveness of the
proposed approach for learning-based compression systems, e.g., in image
compression and point cloud compression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at MMSP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VidMuse: A Simple Video-to-Music Generation Framework with
  Long-Short-Term Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04321v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04321v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyue Tian, Zhaoyang Liu, Ruibin Yuan, Jiahao Pan, Qifeng Liu, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we systematically study music generation conditioned solely on
the video. First, we present a large-scale dataset comprising 360K video-music
pairs, including various genres such as movie trailers, advertisements, and
documentaries. Furthermore, we propose VidMuse, a simple framework for
generating music aligned with video inputs. VidMuse stands out by producing
high-fidelity music that is both acoustically and semantically aligned with the
video. By incorporating local and global visual cues, VidMuse enables the
creation of musically coherent audio tracks that consistently match the video
content through Long-Short-Term modeling. Through extensive experiments,
VidMuse outperforms existing models in terms of audio quality, diversity, and
audio-visual alignment. The code and datasets will be available at
https://github.com/ZeyueT/VidMuse/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code and datasets will be available at
  https://github.com/ZeyueT/VidMuse/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption
  Generation and Fine-Grained NLI Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13984v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13984v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitris Gkoumas, Maria Liakata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific language models drive research innovation but require extensive
fine-tuning on large datasets. This work enhances such models by improving
their inference and evaluation capabilities with minimal or no additional
training. Focusing on molecule caption generation, we explore synergies between
alignment fine-tuning and model merging in a cross-modal setup. We reveal
intriguing insights into the behaviour and suitability of such methods while
significantly surpassing state-of-the-art models. Moreover, we propose a novel
atomic-level evaluation method leveraging off-the-shelf Natural Language
Inference (NLI) models for use in the unseen chemical domain. Our experiments
demonstrate that our evaluation operates at the right level of granularity,
effectively handling multiple content units and subsentence reasoning, while
widely adopted NLI methods consistently misalign with assessment criteria.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-12T00:00:00Z">2024-10-12</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">11</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthetic Knowledge Ingestion: Towards Knowledge Refinement and
  Injection for Enhancing Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09629v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09629v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxin Zhang, Wendi Cui, Yiran Huang, Kamalika Das, Sricharan Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are proficient in capturing factual knowledge
across various domains. However, refining their capabilities on previously seen
knowledge or integrating new knowledge from external sources remains a
significant challenge. In this work, we propose a novel synthetic knowledge
ingestion method called Ski, which leverages fine-grained synthesis,
interleaved generation, and assemble augmentation strategies to construct
high-quality data representations from raw knowledge sources. We then integrate
Ski and its variations with three knowledge injection techniques: Retrieval
Augmented Generation (RAG), Supervised Fine-tuning (SFT), and Continual
Pre-training (CPT) to inject and refine knowledge in language models. Extensive
empirical experiments are conducted on various question-answering tasks
spanning finance, biomedicine, and open-generation domains to demonstrate that
Ski significantly outperforms baseline methods by facilitating effective
knowledge injection. We believe that our work is an important step towards
enhancing the factual accuracy of LLM outputs by refining knowledge
representation and injection capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main conference long paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toward General Instruction-Following Alignment for Retrieval-Augmented
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanting Dong, Xiaoshuai Song, Yutao Zhu, Runqi Qiao, Zhicheng Dou, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following natural instructions is crucial for the effective application of
Retrieval-Augmented Generation (RAG) systems. Despite recent advancements in
Large Language Models (LLMs), research on assessing and improving
instruction-following (IF) alignment within the RAG domain remains limited. To
address this issue, we propose VIF-RAG, the first automated, scalable, and
verifiable synthetic pipeline for instruction-following alignment in RAG
systems. We start by manually crafting a minimal set of atomic instructions
(<100) and developing combination rules to synthesize and verify complex
instructions for a seed set. We then use supervised models for instruction
rewriting while simultaneously generating code to automate the verification of
instruction quality via a Python executor. Finally, we integrate these
instructions with extensive RAG and general data samples, scaling up to a
high-quality VIF-RAG-QA dataset (>100k) through automated processes. To further
bridge the gap in instruction-following auto-evaluation for RAG systems, we
introduce FollowRAG Benchmark, which includes approximately 3K test samples,
covering 22 categories of general instruction constraints and four
knowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG
can seamlessly integrate with different RAG benchmarks. Using FollowRAG and
eight widely-used IF and foundational abilities benchmarks for LLMs, we
demonstrate that VIF-RAG markedly enhances LLM performance across a broad range
of general instruction constraints while effectively leveraging its
capabilities in RAG scenarios. Further analysis offers practical insights for
achieving IF alignment in RAG systems. Our code and datasets are released at
https://FollowRAG.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Working in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Scalable Semantic Representation for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taolin Zhang, Junwei Pan, Jinpeng Wang, Yaohua Zha, Tao Dai, Bin Chen, Ruisheng Luo, Xiaoxiang Deng, Yuan Wang, Ming Yue, Jie Jiang, Shu-Tao Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With recent advances in large language models (LLMs), there has been emerging
numbers of research in developing Semantic IDs based on LLMs to enhance the
performance of recommendation systems. However, the dimension of these
embeddings needs to match that of the ID embedding in recommendation, which is
usually much smaller than the original length. Such dimension compression
results in inevitable losses in discriminability and dimension robustness of
the LLM embeddings, which motivates us to scale up the semantic representation.
In this paper, we propose Mixture-of-Codes, which first constructs multiple
independent codebooks for LLM representation in the indexing stage, and then
utilizes the Semantic Representation along with a fusion module for the
downstream recommendation stage. Extensive analysis and experiments demonstrate
that our method achieves superior discriminability and dimension robustness
scalability, leading to the best scale-up performance in recommendations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Eco-Aware Graph Neural Networks for Sustainable Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09514v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09514v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Purificato, Fabrizio Silvestri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems play a crucial role in alleviating information overload
by providing personalized recommendations tailored to users' preferences and
interests. Recently, Graph Neural Networks (GNNs) have emerged as a promising
approach for recommender systems, leveraging their ability to effectively
capture complex relationships and dependencies between users and items by
representing them as nodes in a graph structure. In this study, we investigate
the environmental impact of GNN-based recommender systems, an aspect that has
been largely overlooked in the literature. Specifically, we conduct a
comprehensive analysis of the carbon emissions associated with training and
deploying GNN models for recommendation tasks. We evaluate the energy
consumption and carbon footprint of different GNN architectures and
configurations, considering factors such as model complexity, training
duration, hardware specifications and embedding size. By addressing the
environmental impact of resource-intensive algorithms in recommender systems,
this study contributes to the ongoing efforts towards sustainable and
responsible artificial intelligence, promoting the development of eco-friendly
recommendation technologies that balance performance and environmental
considerations. Code is available at:
https://github.com/antoniopurificato/gnn_recommendation_and_environment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 tables, 3 figures, RecSoGood Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Green Recommender Systems: Optimizing <span class="highlight-title">Dataset</span> Size for Energy-Efficient
  Algorithm Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09359v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09359v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ardalan Arabzadeh, Tobias Vente, Joeran Beel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As recommender systems become increasingly prevalent, the environmental
impact and energy efficiency of training large-scale models have come under
scrutiny. This paper investigates the potential for energy-efficient algorithm
performance by optimizing dataset sizes through downsampling techniques in the
context of Green Recommender Systems. We conducted experiments on the MovieLens
100K, 1M, 10M, and Amazon Toys and Games datasets, analyzing the performance of
various recommender algorithms under different portions of dataset size. Our
results indicate that while more training data generally leads to higher
algorithm performance, certain algorithms, such as FunkSVD and BiasedMF,
particularly with unbalanced and sparse datasets like Amazon Toys and Games,
maintain high-quality recommendations with up to a 50% reduction in training
data, achieving nDCG@10 scores within approximately 13% of full dataset
performance. These findings suggest that strategic dataset reduction can
decrease computational and environmental costs without substantially
compromising recommendation quality. This study advances sustainable and green
recommender systems by providing insights for reducing energy consumption while
maintaining effectiveness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ALNSynergy: a graph convolutional network with multi-representation
  alignment for drug synergy prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16207v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16207v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinxing Yang, Jiachen Li, Xiao Kang, Guojin Pei, Keyu Liu, Genke Yang, Jian Chu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Drug combination refers to the use of two or more drugs to treat a specific
disease at the same time. It is currently the mainstream way to treat complex
diseases. Compared with single drugs, drug combinations have better efficacy
and can better inhibit toxicity and drug resistance. The computational model
based on deep learning concatenates the representation of multiple drugs and
the corresponding cell line feature as input, and the output is whether the
drug combination can have an inhibitory effect on the cell line. However, this
strategy of concatenating multiple representations has the following defects:
the alignment of drug representation and cell line representation is ignored,
resulting in the synergistic relationship not being reflected positionally in
the embedding space. Moreover, the alignment measurement function in deep
learning cannot be suitable for drug synergy prediction tasks due to
differences in input types. Therefore, in this work, we propose ALNSynergy, a
graph convolutional network with multi-representation alignment for predicting
drug synergy. In the ALNSynergy model, we designed a multi-representation
alignment function suitable for the drug synergy prediction task so that the
positional relationship between drug representations and cell line
representation is reflected in the embedding space. In addition, the vector
modulus of drug representations and cell line representation is considered to
improve the accuracy of calculation results and accelerate model convergence.
Finally, many relevant experiments were run on multiple drug synergy datasets
to verify the effectiveness of the above innovative elements and the excellence
of the ALNSynergy model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages;</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Search and Society: Reimagining Information Access for Radical Futures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17901v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17901v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhaskar Mitra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval (IR) technologies and research are undergoing
transformative changes. It is our perspective that the community should accept
this opportunity to re-center our research agendas on societal needs while
dismantling the artificial separation between the work on fairness,
accountability, transparency, and ethics in IR and the rest of IR research.
Instead of adopting a reactionary strategy of trying to mitigate potential
social harms from emerging technologies, the community should aim to
proactively set the research agenda for the kinds of systems we should build
inspired by diverse explicitly stated sociotechnical imaginaries. The
sociotechnical imaginaries that underpin the design and development of
information access technologies needs to be explicitly articulated, and we need
to develop theories of change in context of these diverse perspectives. Our
guiding future imaginaries must be informed by other academic fields, such as
social and political sciences, and should be co-developed with
cross-disciplinary scholars, legal and policy experts, civil rights and social
justice activists, and artists, among others. In this perspective paper, we
motivate why the community must consider this radical shift in how we do
research and what we work on, and sketch a path forward towards this
transformation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding and Guiding Weakly Supervised Entity Alignment with
  Potential Isomorphism Propagation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03025v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03025v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanyi Wang, Wei Tang, Haifeng Sun, Zirui Zhuang, Xiaoyuan Fu, Jingyu Wang, Qi Qi, Jianxin Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent
entities across diverse knowledge graphs (KGs) using only a limited number of
seed alignments. Despite substantial advances in aggregation-based weakly
supervised EA, the underlying mechanisms in this setting remain unexplored. In
this paper, we present a propagation perspective to analyze weakly supervised
EA and explain the existing aggregation-based EA models. Our theoretical
analysis reveals that these models essentially seek propagation operators for
pairwise entity similarities. We further prove that, despite the structural
heterogeneity of different KGs, the potentially aligned entities within
aggregation-based EA models have isomorphic subgraphs, which is the core
premise of EA but has not been investigated. Leveraging this insight, we
introduce a potential isomorphism propagation operator to enhance the
propagation of neighborhood information across KGs. We develop a general EA
framework, PipEA, incorporating this operator to improve the accuracy of every
type of aggregation-based model without altering the learning process.
Extensive experiments substantiate our theoretical findings and demonstrate
PipEA's significant performance gains over state-of-the-art weakly supervised
EA methods. Our work not only advances the field but also enhances our
comprehension of aggregation-based weakly supervised EA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Information Discovery in e-Commerce 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05763v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05763v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaochun Ren, Xiangnan He, Dawei Yin, Maarten de Rijke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electronic commerce, or e-commerce, is the buying and selling of goods and
services, or the transmitting of funds or data online. E-commerce platforms
come in many kinds, with global players such as Amazon, Airbnb, Alibaba, eBay
and platforms targeting specific geographic regions. Information retrieval has
a natural role to play in e-commerce, especially in connecting people to goods
and services. Information discovery in e-commerce concerns different types of
search (e.g., exploratory search vs. lookup tasks), recommender systems, and
natural language processing in e-commerce portals. The rise in popularity of
e-commerce sites has made research on information discovery in e-commerce an
increasingly active research area. This is witnessed by an increase in
publications and dedicated workshops in this space. Methods for information
discovery in e-commerce largely focus on improving the effectiveness of
e-commerce search and recommender systems, on enriching and using knowledge
graphs to support e-commerce, and on developing innovative question answering
and bot-based solutions that help to connect people to goods and services. In
this survey, an overview is given of the fundamental infrastructure,
algorithms, and technical solutions for information discovery in e-commerce.
The topics covered include user behavior and profiling, search, recommendation,
and language technology in e-commerce.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic-aware Representation Learning for Homography Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13284v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13284v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Liu, Qianxin Huang, Siqi Hui, Jingwen Fu, Sanping Zhou, Kangyi Wu, Pengna Li, Jinjun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Homography estimation is the task of determining the transformation from an
image pair. Our approach focuses on employing detector-free feature matching
methods to address this issue. Previous work has underscored the importance of
incorporating semantic information, however there still lacks an efficient way
to utilize semantic information. Previous methods suffer from treating the
semantics as a pre-processing, causing the utilization of semantics overly
coarse-grained and lack adaptability when dealing with different tasks. In our
work, we seek another way to use the semantic information, that is
semantic-aware feature representation learning framework.Based on this, we
propose SRMatcher, a new detector-free feature matching method, which
encourages the network to learn integrated semantic feature
representation.Specifically, to capture precise and rich semantics, we leverage
the capabilities of recently popularized vision foundation models (VFMs)
trained on extensive datasets. Then, a cross-images Semantic-aware Fusion Block
(SFB) is proposed to integrate its fine-grained semantic features into the
feature representation space. In this way, by reducing errors stemming from
semantic inconsistencies in matching pairs, our proposed SRMatcher is able to
deliver more accurate and realistic outcomes. Extensive experiments show that
SRMatcher surpasses solid baselines and attains SOTA results on multiple
real-world datasets. Compared to the previous SOTA approach GeoFormer,
SRMatcher increases the area under the cumulative curve (AUC) by about 11% on
HPatches. Additionally, the SRMatcher could serve as a plug-and-play framework
for other matching methods like LoFTR, yielding substantial precision
improvement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Orthogonal Nonnegative Matrix Factorization with the Kullback-Leibler
  divergence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07786v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07786v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jean Pacifique Nkurunziza, Fulgence Nahayo, Nicolas Gillis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Orthogonal nonnegative matrix factorization (ONMF) has become a standard
approach for clustering. As far as we know, most works on ONMF rely on the
Frobenius norm to assess the quality of the approximation. This paper presents
a new model and algorithm for ONMF that minimizes the Kullback-Leibler (KL)
divergence. As opposed to the Frobenius norm which assumes Gaussian noise, the
KL divergence is the maximum likelihood estimator for Poisson-distributed data,
which can model better sparse vectors of word counts in document data sets and
photo counting processes in imaging. We develop an algorithm based on
alternating optimization, KL-ONMF, and show that it performs favorably with the
Frobenius-norm based ONMF for document classification and hyperspectral image
unmixing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, corrected some typos</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Making Beshbarmak: Games for Central Asian Cultural Heritage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09670v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09670v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amina Kobenova, Adina Kaiymova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces "Making Beshbarmak", an interactive cooking game that
celebrates the nomadic ancestry and cultural heritage of Central Asian
communities worldwide. Designed to promote cultural appreciation and identity
formation, the game invites players to learn and recreate the traditional dish
Beshbarmak through an engaging step-by-step process, incorporating storytelling
elements that explain the cultural significance of the meal. Our project
contributes to digital cultural heritage and games research by offering an
accessible, open-source prototype on p5.js, enabling users to connect with and
explore Central Asian traditions. "Making Beshbarmak" serves as both an
educational tool and a platform for cultural preservation, fostering a sense of
belonging among Central Asian immigrant populations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures, EAI ArtsIT Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ STanH : Parametric Quantization for Variable Rate Learned Image
  Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00557v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00557v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alberto Presta, Enzo Tartaglione, Attilio Fiandrotti, Marco Grangetto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In end-to-end learned image compression, encoder and decoder are jointly
trained to minimize a $R + {\lambda}D$ cost function, where ${\lambda}$
controls the trade-off between rate of the quantized latent representation and
image quality. Unfortunately, a distinct encoder-decoder pair with millions of
parameters must be trained for each ${\lambda}$, hence the need to switch
encoders and to store multiple encoders and decoders on the user device for
every target rate. This paper proposes to exploit a differentiable quantizer
designed around a parametric sum of hyperbolic tangents, called STanH , that
relaxes the step-wise quantization function. STanH is implemented as a
differentiable activation layer with learnable quantization parameters that can
be plugged into a pre-trained fixed rate model and refined to achieve different
target bitrates. Experimental results show that our method enables variable
rate coding with comparable efficiency to the state-of-the-art, yet with
significant savings in terms of ease of deployment, training time, and storage
costs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE Transactions on Image Processing</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-11T00:00:00Z">2024-10-11</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">11</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ACER: Automatic Language Model Context Extension via Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09141v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09141v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luyu Gao, Yunyi Zhang, Jamie Callan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context modeling is one of the critical capabilities of language AI for
digesting and reasoning over complex information pieces. In practice,
long-context capabilities are typically built into a pre-trained language
model~(LM) through a carefully designed context extension stage, with the goal
of producing generalist long-context capabilities. In our preliminary
experiments, however, we discovered that the current open-weight generalist
long-context models are still lacking in practical long-context processing
tasks. While this means perfectly effective long-context modeling demands
task-specific data, the cost can be prohibitive. In this paper, we draw
inspiration from how humans process a large body of information: a lossy
\textbf{retrieval} stage ranks a large set of documents while the reader ends
up reading deeply only the top candidates. We build an \textbf{automatic} data
synthesis pipeline that mimics this process using short-context LMs. The
short-context LMs are further tuned using these self-generated data to obtain
task-specific long-context capabilities. Similar to how pre-training learns
from imperfect data, we hypothesize and further demonstrate that the
short-context model can bootstrap over the synthetic data, outperforming not
only long-context generalist models but also the retrieval and read pipeline
used to synthesize the training data in real-world tasks such as long-context
retrieval augmented generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interdependency Matters: Graph Alignment for Multivariate Time Series
  Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanyi Wang, Haifeng Sun, Chengsen Wang, Mengde Zhu, Jingyu Wang, Wei Tang, Qi Qi, Zirui Zhuang, Jianxin Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection in multivariate time series (MTS) is crucial for various
applications in data mining and industry. Current industrial methods typically
approach anomaly detection as an unsupervised learning task, aiming to identify
deviations by estimating the normal distribution in noisy, label-free datasets.
These methods increasingly incorporate interdependencies between channels
through graph structures to enhance accuracy. However, the role of
interdependencies is more critical than previously understood, as shifts in
interdependencies between MTS channels from normal to anomalous data are
significant. This observation suggests that \textit{anomalies could be detected
by changes in these interdependency graph series}. To capitalize on this
insight, we introduce MADGA (MTS Anomaly Detection via Graph Alignment), which
redefines anomaly detection as a graph alignment (GA) problem that explicitly
utilizes interdependencies for anomaly detection. MADGA dynamically transforms
subsequences into graphs to capture the evolving interdependencies, and Graph
alignment is performed between these graphs, optimizing an alignment plan that
minimizes cost, effectively minimizing the distance for normal data and
maximizing it for anomalous data. Uniquely, our GA approach involves explicit
alignment of both nodes and edges, employing Wasserstein distance for nodes and
Gromov-Wasserstein distance for edges. To our knowledge, this is the first
application of GA to MTS anomaly detection that explicitly leverages
interdependency for this purpose. Extensive experiments on diverse real-world
datasets validate the effectiveness of MADGA, demonstrating its capability to
detect anomalies and differentiate interdependencies, consistently achieving
state-of-the-art across various scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Methodology for Evaluating RAG Systems: A Case Study On Configuration
  Dependency Validation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08801v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08801v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Simon, Alina Mailach, Johannes Dorn, Norbert Siegmund
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is an umbrella of different components,
design decisions, and domain-specific adaptations to enhance the capabilities
of large language models and counter their limitations regarding hallucination
and outdated and missing knowledge. Since it is unclear which design decisions
lead to a satisfactory performance, developing RAG systems is often
experimental and needs to follow a systematic and sound methodology to gain
sound and reliable results. However, there is currently no generally accepted
methodology for RAG evaluation despite a growing interest in this technology.
In this paper, we propose a first blueprint of a methodology for a sound and
reliable evaluation of RAG systems and demonstrate its applicability on a
real-world software engineering research task: the validation of configuration
dependencies across software technologies. In summary, we make two novel
contributions: (i) A novel, reusable methodological design for evaluating RAG
systems, including a demonstration that represents a guideline, and (ii) a RAG
system, which has been developed following this methodology, that achieves the
highest accuracy in the field of dependency validation. For the blueprint's
demonstration, the key insights are the crucial role of choosing appropriate
baselines and metrics, the necessity for systematic RAG refinements derived
from qualitative failure analysis, as well as the reporting practices of key
design decision to foster replication and evaluation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hespi: A pipeline for automatically detecting information from hebarium
  specimen sheets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08740v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08740v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Turnbull, Emily Fitzgerald, Karen Thompson, Joanne L. Birch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Specimen associated biodiversity data are sought after for biological,
environmental, climate, and conservation sciences. A rate shift is required for
the extraction of data from specimen images to eliminate the bottleneck that
the reliance on human-mediated transcription of these data represents. We
applied advanced computer vision techniques to develop the `Hespi' (HErbarium
Specimen sheet PIpeline), which extracts a pre-catalogue subset of collection
data on the institutional labels on herbarium specimens from their digital
images. The pipeline integrates two object detection models; the first detects
bounding boxes around text-based labels and the second detects bounding boxes
around text-based data fields on the primary institutional label. The pipeline
classifies text-based institutional labels as printed, typed, handwritten, or a
combination and applies Optical Character Recognition (OCR) and Handwritten
Text Recognition (HTR) for data extraction. The recognized text is then
corrected against authoritative databases of taxon names. The extracted text is
also corrected with the aide of a multimodal Large Language Model (LLM). Hespi
accurately detects and extracts text for test datasets including specimen sheet
images from international herbaria. The components of the pipeline are modular
and users can train their own models with their own data and use them in place
of the models provided.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TIGER: Temporally Improved Graph Entity Linker 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengyu Zhang, Congfeng Cao, Paul Groth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge graphs change over time, for example, when new entities are
introduced or entity descriptions change. This impacts the performance of
entity linking, a key task in many uses of knowledge graphs such as web search
and recommendation. Specifically, entity linking models exhibit temporal
degradation - their performance decreases the further a knowledge graph moves
from its original state on which an entity linking model was trained. To tackle
this challenge, we introduce \textbf{TIGER}: a \textbf{T}emporally
\textbf{I}mproved \textbf{G}raph \textbf{E}ntity Linke\textbf{r}. By
incorporating structural information between entities into the model, we
enhance the learned representation, making entities more distinguishable over
time. The core idea is to integrate graph-based information into text-based
information, from which both distinct and shared embeddings are based on an
entity's feature and structural relationships and their interaction.
Experiments on three datasets show that our model can effectively prevent
temporal degradation, demonstrating a 16.24\% performance boost over the
state-of-the-art in a temporal setting when the time gap is one year and an
improvement to 20.93\% as the gap expands to three years. The code and data are
made available at
\url{https://github.com/pengyu-zhang/TIGER-Temporally-Improved-Graph-Entity-Linker}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieving Contextual Information for Long-Form Question Answering using
  Weak Supervision <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philipp Christmann, Svitlana Vakulenko, Ionut Teodor Sorodoc, Bill Byrne, Adrià de Gispert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-form question answering (LFQA) aims at generating in-depth answers to
end-user questions, providing relevant information beyond the direct answer.
However, existing retrievers are typically optimized towards information that
directly targets the question, missing out on such contextual information.
Furthermore, there is a lack of training data for relevant context. To this
end, we propose and compare different weak supervision techniques to optimize
retrieval for contextual information. Experiments demonstrate improvements on
the end-to-end QA performance on ASQA, a dataset for long-form question
answering. Importantly, as more contextual information is retrieved, we improve
the relevant page recall for LFQA by 14.7% and the groundedness of generated
long-form answers by 12.5%. Finally, we show that long-form answers often
anticipate likely follow-up questions, via experiments on a conversational QA
dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intent-Enhanced Data Augmentation for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Chen, Zhoujun Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The research on intent-enhanced sequential recommendation algorithms focuses
on how to better mine dynamic user intent based on user behavior data for
sequential recommendation tasks. Various data augmentation methods are widely
applied in current sequential recommendation algorithms, effectively enhancing
the ability to capture user intent. However, these widely used data
augmentation methods often rely on a large amount of random sampling, which can
introduce excessive noise into the training data, blur user intent, and thus
negatively affect recommendation performance. Additionally, these methods have
limited approaches to utilizing augmented data, failing to fully leverage the
augmented samples. We propose an intent-enhanced data augmentation method for
sequential recommendation(\textbf{IESRec}), which constructs positive and
negative samples based on user behavior sequences through intent-segment
insertion. On one hand, the generated positive samples are mixed with the
original training data, and they are trained together to improve recommendation
performance. On the other hand, the generated positive and negative samples are
used to build a contrastive loss function, enhancing recommendation performance
through self-supervised training. Finally, the main recommendation task is
jointly trained with the contrastive learning loss minimization task.
Experiments on three real-world datasets validate the effectiveness of our
IESRec model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Legal Entity Recognition Using a Hybrid <span class="highlight-title">Transformer</span> Model and
  Semantic Filtering Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08521v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08521v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duraimurugan Rajamanickam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal Entity Recognition (LER) is critical in automating legal workflows such
as contract analysis, compliance monitoring, and litigation support. Existing
approaches, including rule-based systems and classical machine learning models,
struggle with the complexity of legal documents and domain specificity,
particularly in handling ambiguities and nested entity structures. This paper
proposes a novel hybrid model that enhances the accuracy and precision of
Legal-BERT, a transformer model fine-tuned for legal text processing, by
introducing a semantic similarity-based filtering mechanism. We evaluate the
model on a dataset of 15,000 annotated legal documents, achieving an F1 score
of 93.4%, demonstrating significant improvements in precision and recall over
previous methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Quick, trustworthy spectral knowledge Q&A system leveraging
  retrieval-augmented generation on LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11557v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11557v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiheng Liang, Ziru Yu, Zujie Xie, Xiangyang Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) has demonstrated significant success in a range of
natural language processing (NLP) tasks within general domain. The emergence of
LLM has introduced innovative methodologies across diverse fields, including
the natural sciences. Researchers aim to implement automated, concurrent
process driven by LLM to supplant conventional manual, repetitive and
labor-intensive work. In the domain of spectral analysis and detection, it is
imperative for researchers to autonomously acquire pertinent knowledge across
various research objects, which encompasses the spectroscopic techniques and
the chemometric methods that are employed in experiments and analysis.
Paradoxically, despite the recognition of spectroscopic detection as an
effective analytical method, the fundamental process of knowledge retrieval
remains both time-intensive and repetitive. In response to this challenge, we
first introduced the Spectral Detection and Analysis Based Paper(SDAAP)
dataset, which is the first open-source textual knowledge dataset for spectral
analysis and detection and contains annotated literature data as well as
corresponding knowledge instruction data. Subsequently, we also designed an
automated Q\&A framework based on the SDAAP dataset, which can retrieve
relevant knowledge and generate high-quality responses by extracting entities
in the input as retrieval parameters. It is worth noting that: within this
framework, LLM is only used as a tool to provide generalizability, while RAG
technique is used to accurately capture the source of the knowledge.This
approach not only improves the quality of the generated responses, but also
ensures the traceability of the knowledge. Experimental results show that our
framework generates responses with more reliable expertise compared to the
baseline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages,10 figures,3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OAEI-LLM: A Benchmark <span class="highlight-title">Dataset</span> for Understanding Large Language Model
  Hallucinations in Ontology Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14038v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14038v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucinations of large language models (LLMs) commonly occur in
domain-specific downstream tasks, with no exception in ontology matching (OM).
The prevalence of using LLMs for OM raises the need for benchmarks to better
understand LLM hallucinations. The OAEI-LLM dataset is an extended version of
the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate
LLM-specific hallucinations in OM tasks. We outline the methodology used in
dataset construction and schema extension, and provide examples of potential
use cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Positional Attention for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.02793v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.02793v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Luo, Haibo He, Juan Zhang, Shenghui Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-attention-based networks have achieved remarkable performance in
sequential recommendation tasks. A crucial component of these models is
positional encoding. In this study, we delve into the learned positional
embedding, demonstrating that it often captures the distance between tokens.
Building on this insight, we introduce novel attention models that directly
learn positional relations. Extensive experiments reveal that our proposed
models, \textbf{PARec} and \textbf{FPARec} outperform previous
self-attention-based approaches.Our code is available at the link for anonymous
review: https://anonymous.4open.science/ r/FPARec-2C55/
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interdependency Matters: Graph Alignment for Multivariate Time Series
  Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08877v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08877v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanyi Wang, Haifeng Sun, Chengsen Wang, Mengde Zhu, Jingyu Wang, Wei Tang, Qi Qi, Zirui Zhuang, Jianxin Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection in multivariate time series (MTS) is crucial for various
applications in data mining and industry. Current industrial methods typically
approach anomaly detection as an unsupervised learning task, aiming to identify
deviations by estimating the normal distribution in noisy, label-free datasets.
These methods increasingly incorporate interdependencies between channels
through graph structures to enhance accuracy. However, the role of
interdependencies is more critical than previously understood, as shifts in
interdependencies between MTS channels from normal to anomalous data are
significant. This observation suggests that \textit{anomalies could be detected
by changes in these interdependency graph series}. To capitalize on this
insight, we introduce MADGA (MTS Anomaly Detection via Graph Alignment), which
redefines anomaly detection as a graph alignment (GA) problem that explicitly
utilizes interdependencies for anomaly detection. MADGA dynamically transforms
subsequences into graphs to capture the evolving interdependencies, and Graph
alignment is performed between these graphs, optimizing an alignment plan that
minimizes cost, effectively minimizing the distance for normal data and
maximizing it for anomalous data. Uniquely, our GA approach involves explicit
alignment of both nodes and edges, employing Wasserstein distance for nodes and
Gromov-Wasserstein distance for edges. To our knowledge, this is the first
application of GA to MTS anomaly detection that explicitly leverages
interdependency for this purpose. Extensive experiments on diverse real-world
datasets validate the effectiveness of MADGA, demonstrating its capability to
detect anomalies and differentiate interdependencies, consistently achieving
state-of-the-art across various scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contrastive Knowledge Distillation for Robust Multimodal Sentiment
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongyi Sang, Kotaro Funakoshi, Manabu Okumura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal sentiment analysis (MSA) systems leverage information from
different modalities to predict human sentiment intensities. Incomplete
modality is an important issue that may cause a significant performance drop in
MSA systems. By generative imputation, i.e., recovering the missing data from
available data, systems may achieve robust performance but will lead to high
computational costs. This paper introduces a knowledge distillation method,
called `Multi-Modal Contrastive Knowledge Distillation' (MM-CKD), to address
the issue of incomplete modality in video sentiment analysis with lower
computation cost, as a novel non-imputation-based method. We employ Multi-view
Supervised Contrastive Learning (MVSC) to transfer knowledge from a teacher
model to student models. This approach not only leverages cross-modal knowledge
but also introduces cross-sample knowledge with supervision, jointly improving
the performance of both teacher and student models through online learning. Our
method gives competitive results with significantly lower computational costs
than state-of-the-art imputation-based methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ More than Memes: A Multimodal Topic Modeling Approach to Conspiracy
  Theories on Telegram 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elisabeth Steffen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on conspiracy theories and related content online has traditionally
focused on textual data. To address the increasing prevalence of (audio-)visual
data on social media, and to capture the evolving and dynamic nature of this
communication, researchers have begun to explore the potential of unsupervised
approaches for analyzing multimodal online content. Our research contributes to
this field by exploring the potential of multimodal topic modeling for
analyzing conspiracy theories in German-language Telegram channels. Our work
uses the BERTopic topic modeling approach in combination with CLIP for the
analysis of textual and visual data. We analyze a corpus of ~40, 000 Telegram
messages posted in October 2023 in 571 German-language Telegram channels known
for disseminating conspiracy theories and other deceptive content. We explore
the potentials and challenges of this approach for studying a medium-sized
corpus of user-generated, text-image online content. We offer insights into the
dominant topics across modalities, different text and image genres discovered
during the analysis, quantitative inter-modal topic analyses, and a qualitative
case study of textual, visual, and multimodal narrative strategies in the
communication of conspiracy theories.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Natural Language Induced Adversarial Images <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopei Zhu, Peiyang Xu, Guanning Zeng, Yingpeng Dong, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research of adversarial attacks is important for AI security because it shows
the vulnerability of deep learning models and helps to build more robust
models. Adversarial attacks on images are most widely studied, which include
noise-based attacks, image editing-based attacks, and latent space-based
attacks. However, the adversarial examples crafted by these methods often lack
sufficient semantic information, making it challenging for humans to understand
the failure modes of deep learning models under natural conditions. To address
this limitation, we propose a natural language induced adversarial image attack
method. The core idea is to leverage a text-to-image model to generate
adversarial images given input prompts, which are maliciously constructed to
lead to misclassification for a target model. To adopt commercial text-to-image
models for synthesizing more natural adversarial images, we propose an adaptive
genetic algorithm (GA) for optimizing discrete adversarial prompts without
requiring gradients and an adaptive word space reduction method for improving
query efficiency. We further used CLIP to maintain the semantic consistency of
the generated images. In our experiments, we found that some high-frequency
semantic information such as "foggy", "humid", "stretching", etc. can easily
cause classifier errors. This adversarial semantic information exists not only
in generated images but also in photos captured in the real world. We also
found that some adversarial semantic information can be transferred to unknown
classification tasks. Furthermore, our attack method can transfer to different
text-to-image models (e.g., Midjourney, DALL-E 3, etc.) and image classifiers.
Our code is available at:
https://github.com/zxp555/Natural-Language-Induced-Adversarial-Images.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Carmera-ready version. To appear in ACM MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ego3DT: Tracking Every 3D Object in Ego-centric Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengyu Hao, Wenhao Chai, Zhonghan Zhao, Meiqi Sun, Wendi Hu, Jieyang Zhou, Yixian Zhao, Qi Li, Yizhou Wang, Xi Li, Gaoang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing interest in embodied intelligence has brought ego-centric
perspectives to contemporary research. One significant challenge within this
realm is the accurate localization and tracking of objects in ego-centric
videos, primarily due to the substantial variability in viewing angles.
Addressing this issue, this paper introduces a novel zero-shot approach for the
3D reconstruction and tracking of all objects from the ego-centric video. We
present Ego3DT, a novel framework that initially identifies and extracts
detection and segmentation information of objects within the ego environment.
Utilizing information from adjacent video frames, Ego3DT dynamically constructs
a 3D scene of the ego view using a pre-trained 3D scene reconstruction model.
Additionally, we have innovated a dynamic hierarchical association mechanism
for creating stable 3D tracking trajectories of objects in ego-centric videos.
Moreover, the efficacy of our approach is corroborated by extensive experiments
on two newly compiled datasets, with 1.04x - 2.90x in HOTA, showcasing the
robustness and accuracy of our method in diverse ego-centric scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM Multimedia 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Symbolic Music Generation with Fine-grained Interactive Textural
  Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingyu Zhu, Haoyu Liu, Zhimin Jiang, Zeyu Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The problem of symbolic music generation presents unique challenges due to
the combination of limited data availability and the need for high precision in
note pitch. To overcome these difficulties, we introduce Fine-grained Textural
Guidance (FTG) within diffusion models to correct errors in the learned
distributions. By incorporating FTG, the diffusion models improve the accuracy
of music generation, which makes them well-suited for advanced tasks such as
progressive music generation, improvisation and interactive music creation. We
derive theoretical characterizations for both the challenges in symbolic music
generation and the effect of the FTG approach. We provide numerical experiments
and a demo page for interactive music generation with user input to showcase
the effectiveness of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Large Language Models into a Tri-Modal Architecture for
  Automated Depression Classification on the DAIC-WOZ 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.19340v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.19340v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santosh V. Patapati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Major Depressive Disorder (MDD) is a pervasive mental health condition that
affects 300 million people worldwide. This work presents a novel, BiLSTM-based
tri-modal model-level fusion architecture for the binary classification of
depression from clinical interview recordings. The proposed architecture
incorporates Mel Frequency Cepstral Coefficients, Facial Action Units, and uses
a two-shot learning based GPT-4 model to process text data. This is the first
work to incorporate large language models into a multi-modal architecture for
this task. It achieves impressive results on the DAIC-WOZ AVEC 2016 Challenge
cross-validation split and Leave-One-Subject-Out cross-validation split,
surpassing all baseline models and multiple state-of-the-art models. In
Leave-One-Subject-Out testing, it achieves an accuracy of 91.01%, an F1-Score
of 85.95%, a precision of 80%, and a recall of 92.86%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Keywords: Multi-Modal Neural Networks, Deep Learning, Large Language
  Models, Depression Diagnosis, Biomedical Informatics, DAIC-WOZ</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Low-complexity Image and Video Coding Based on an Approximate Discrete
  Tchebichef Transform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/1609.07630v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/1609.07630v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A. Madanayake, V. A. Coutinho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The usage of linear transformations has great relevance for data
decorrelation applications, like image and video compression. In that sense,
the discrete Tchebichef transform (DTT) possesses useful coding and
decorrelation properties. The DTT transform kernel does not depend on the input
data and fast algorithms can be developed to real time applications. However,
the DTT fast algorithm presented in literature possess high computational
complexity. In this work, we introduce a new low-complexity approximation for
the DTT. The fast algorithm of the proposed transform is multiplication-free
and requires a reduced number of additions and bit-shifting operations. Image
and video compression simulations in popular standards shows good performance
of the proposed transform. Regarding hardware resource consumption for FPGA
shows 43.1% reduction of configurable logic blocks and ASIC place and route
realization shows 57.7% reduction in the area-time figure when compared with
the 2-D version of the exact DTT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Fixed typo in $C_g$ and $\eta$ measurements from Table 1 (W A S
  Aleixo); 11 pages, 5 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-10T00:00:00Z">2024-10-10</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Effects of Hallucinations in Synthetic Training Data for Relation
  Extraction <span class="chip">ISWC'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08393v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08393v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Steven Rogulsky, Nicholas Popovic, Michael Färber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Relation extraction is crucial for constructing knowledge graphs, with large
high-quality datasets serving as the foundation for training, fine-tuning, and
evaluating models. Generative data augmentation (GDA) is a common approach to
expand such datasets. However, this approach often introduces hallucinations,
such as spurious facts, whose impact on relation extraction remains
underexplored. In this paper, we examine the effects of hallucinations on the
performance of relation extraction on the document and sentence levels. Our
empirical study reveals that hallucinations considerably compromise the ability
of models to extract relations from text, with recall reductions between 19.1%
and 39.2%. We identify that relevant hallucinations impair the model's
performance, while irrelevant hallucinations have a minimal impact.
Additionally, we develop methods for the detection of hallucinations to improve
data quality and model performance. Our approaches successfully classify texts
as either 'hallucinated' or 'clean,' achieving high F1-scores of 83.8% and
92.2%. These methods not only assist in removing hallucinations but also help
in estimating their prevalence within datasets, which is crucial for selecting
high-quality data. Overall, our work confirms the profound impact of relevant
hallucinations on the effectiveness of relation extraction models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at KBC-LM@ISWC'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revealing COVID-19's Social Dynamics: Diachronic Semantic Analysis of
  Vaccine and Symptom Discourse on Twitter 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08352v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08352v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeqiang Wang, Jiageng Wu, Yuqi Wang, Wei Wang, Jie Yang, Jon Johnson, Nishanth Sastry, Suparna De
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media is recognized as an important source for deriving insights into
public opinion dynamics and social impacts due to the vast textual data
generated daily and the 'unconstrained' behavior of people interacting on these
platforms. However, such analyses prove challenging due to the semantic shift
phenomenon, where word meanings evolve over time. This paper proposes an
unsupervised dynamic word embedding method to capture longitudinal semantic
shifts in social media data without predefined anchor words. The method
leverages word co-occurrence statistics and dynamic updating to adapt
embeddings over time, addressing the challenges of data sparseness, imbalanced
distributions, and synergistic semantic effects. Evaluated on a large COVID-19
Twitter dataset, the method reveals semantic evolution patterns of vaccine- and
symptom-related entities across different pandemic stages, and their potential
correlations with real-world statistics. Our key contributions include the
dynamic embedding technique, empirical analysis of COVID-19 semantic shifts,
and discussions on enhancing semantic shift modeling for computational social
science research. This study enables capturing longitudinal semantic dynamics
on social media to understand public discourse and collective phenomena.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The language of sound search: Examining User Queries in Audio Search
  Engines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benno Weck, Frederic Font
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study examines textual, user-written search queries within the context
of sound search engines, encompassing various applications such as foley, sound
effects, and general audio retrieval. Current research inadequately addresses
real-world user needs and behaviours in designing text-based audio retrieval
systems. To bridge this gap, we analysed search queries from two sources: a
custom survey and Freesound website query logs. The survey was designed to
collect queries for an unrestricted, hypothetical sound search engine,
resulting in a dataset that captures user intentions without the constraints of
existing systems. This dataset is also made available for sharing with the
research community. In contrast, the Freesound query logs encompass
approximately 9 million search requests, providing a comprehensive view of
real-world usage patterns. Our findings indicate that survey queries are
generally longer than Freesound queries, suggesting users prefer detailed
queries when not limited by system constraints. Both datasets predominantly
feature keyword-based queries, with few survey participants using full
sentences. Key factors influencing survey queries include the primary sound
source, intended usage, perceived location, and the number of sound sources.
These insights are crucial for developing user-centred, effective text-based
audio retrieval systems, enhancing our understanding of user behaviour in sound
search contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at DCASE 2024. Supplementary materials at
  https://doi.org/10.5281/zenodo.13622537</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rewriting Conversational Utterances with Instructed Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07797v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07797v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elnara Galimzhanova, Cristina Ioana Muntean, Franco Maria Nardini, Raffaele Perego, Guido Rocchietti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many recent studies have shown the ability of large language models (LLMs) to
achieve state-of-the-art performance on many NLP tasks, such as question
answering, text summarization, coding, and translation. In some cases, the
results provided by LLMs are on par with those of human experts. These models'
most disruptive innovation is their ability to perform tasks via zero-shot or
few-shot prompting. This capability has been successfully exploited to train
instructed LLMs, where reinforcement learning with human feedback is used to
guide the model to follow the user's requests directly. In this paper, we
investigate the ability of instructed LLMs to improve conversational search
effectiveness by rewriting user questions in a conversational setting. We study
which prompts provide the most informative rewritten utterances that lead to
the best retrieval performance. Reproducible experiments are conducted on
publicly-available TREC CAST datasets. The results show that rewriting
conversational utterances with instructed LLMs achieves significant
improvements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and
11.5% in Recall@500 over state-of-the-art techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Firzen: Firing Strict Cold-Start Items with Frozen Heterogeneous and
  Homogeneous Graphs for Recommendation <span class="chip">ICDE 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07654v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07654v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hulingxiao He, Xiangteng He, Yuxin Peng, Zifei Shan, Xin Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommendation models utilizing unique identities (IDs) to represent distinct
users and items have dominated the recommender systems literature for over a
decade. Since multi-modal content of items (e.g., texts and images) and
knowledge graphs (KGs) may reflect the interaction-related users' preferences
and items' characteristics, they have been utilized as useful side information
to further improve the recommendation quality. However, the success of such
methods often limits to either warm-start or strict cold-start item
recommendation in which some items neither appear in the training data nor have
any interactions in the test stage: (1) Some fail to learn the embedding of a
strict cold-start item since side information is only utilized to enhance the
warm-start ID representations; (2) The others deteriorate the performance of
warm-start recommendation since unrelated multi-modal content or entities in
KGs may blur the final representations. In this paper, we propose a unified
framework incorporating multi-modal content of items and KGs to effectively
solve both strict cold-start and warm-start recommendation termed Firzen, which
extracts the user-item collaborative information over frozen heterogeneous
graph (collaborative knowledge graph), and exploits the item-item semantic
structures and user-user behavioral association over frozen homogeneous graphs
(item-item relation graph and user-user co-occurrence graph). Furthermore, we
build four unified strict cold-start evaluation benchmarks based on publicly
available Amazon datasets and a real-world industrial dataset from Weixin
Channels via rearranging the interaction data and constructing KGs. Extensive
empirical results demonstrate that our model yields significant improvements
for strict cold-start recommendation and outperforms or matches the
state-of-the-art performance in the warm-start scenario.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICDE 2024. The code is available at
  https://github.com/PKU-ICST-MIPL/Firzen_ICDE2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07610v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07610v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Po-han Li, Sandeep P. Chinchali, Ufuk Topcu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal encoders like CLIP excel in tasks such as zero-shot image
classification and cross-modal retrieval. However, they require excessive
training data. We propose canonical similarity analysis (CSA), which uses two
unimodal encoders to replicate multimodal encoders using limited data. CSA maps
unimodal features into a multimodal space, using a new similarity score to
retain only the multimodal information. CSA only involves the inference of
unimodal encoders and a cubic-complexity matrix decomposition, eliminating the
need for extensive GPU-based model training. Experiments show that CSA
outperforms CLIP while requiring $300,000\times$ fewer multimodal data pairs
and $6\times$ fewer unimodal data for ImageNet classification and
misinformative news captions detection. CSA surpasses the state-of-the-art
method to map unimodal features to multimodal features. We also demonstrate the
ability of CSA with modalities beyond image and text, paving the way for future
modality pairs with limited paired multimodal data but abundant unpaired
unimodal data, such as lidar and text.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ No Free Lunch: Retrieval-Augmented Generation Undermines Fairness in
  LLMs, Even for Vigilant Users 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengxuan Hu, Hongyi Wu, Zihan Guan, Ronghang Zhu, Dongliang Guo, Daiqing Qi, Sheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) is widely adopted for its effectiveness
and cost-efficiency in mitigating hallucinations and enhancing the
domain-specific generation capabilities of large language models (LLMs).
However, is this effectiveness and cost-efficiency truly a free lunch? In this
study, we comprehensively investigate the fairness costs associated with RAG by
proposing a practical three-level threat model from the perspective of user
awareness of fairness. Specifically, varying levels of user fairness awareness
result in different degrees of fairness censorship on the external dataset. We
examine the fairness implications of RAG using uncensored, partially censored,
and fully censored datasets. Our experiments demonstrate that fairness
alignment can be easily undermined through RAG without the need for fine-tuning
or retraining. Even with fully censored and supposedly unbiased external
datasets, RAG can lead to biased outputs. Our findings underscore the
limitations of current alignment methods in the context of RAG-based LLMs and
highlight the urgent need for new strategies to ensure fairness. We propose
potential mitigations and call for further research to develop robust fairness
safeguards in RAG-based LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improved Estimation of Ranks for Learning Item Recommenders with
  Negative Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06371v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06371v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anushya Subbiah, Steffen Rendle, Vikram Aggarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recommendation systems, there has been a growth in the number of
recommendable items (# of movies, music, products). When the set of
recommendable items is large, training and evaluation of item recommendation
models becomes computationally expensive. To lower this cost, it has become
common to sample negative items. However, the recommendation quality can suffer
from biases introduced by traditional negative sampling mechanisms. In this
work, we demonstrate the benefits from correcting the bias introduced by
sampling of negatives. We first provide sampled batch version of the
well-studied WARP and LambdaRank methods. Then, we present how these methods
can benefit from improved ranking estimates. Finally, we evaluate the
recommendation quality as a result of correcting rank estimates and demonstrate
that WARP and LambdaRank can be learned efficiently with negative sampling and
our proposed correction technique.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TiM4Rec: An Efficient Sequential Recommendation Model Based on
  Time-Aware Structured State Space Duality Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16182v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16182v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Fan, Mengyi Zhu, Yanrong Hu, Hailin Feng, Zhijie He, Hongjiu Liu, Qingyang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation represents a pivotal branch of recommendation
systems, centered around dynamically analyzing the sequential dependencies
between user preferences and their interactive behaviors. Despite the
Transformer architecture-based models achieving commendable performance within
this domain, their quadratic computational complexity relative to the sequence
dimension impedes efficient modeling. In response, the innovative Mamba
architecture, characterized by linear computational complexity, has emerged.
Mamba4Rec further pioneers the application of Mamba in sequential
recommendation. Nonetheless, Mamba 1's hardware-aware algorithm struggles to
efficiently leverage modern matrix computational units, which lead to the
proposal of the improved State Space Duality (SSD), also known as Mamba 2.
While the SSD4Rec successfully adapts the SSD architecture for sequential
recommendation, showing promising results in high-dimensional contexts, it
suffers significant performance drops in low-dimensional scenarios crucial for
pure ID sequential recommendation tasks. Addressing this challenge, we propose
a novel sequential recommendation backbone model, TiM4Rec, which ameliorates
the low-dimensional performance loss of the SSD architecture while preserving
its computational efficiency. Drawing inspiration from TiSASRec, we develop a
time-aware enhancement method tailored for the linear computation demands of
the SSD architecture, thereby enhancing its adaptability and achieving
state-of-the-art (SOTA) performance in both low and high-dimensional modeling.
The code for our model is publicly accessible at
https://github.com/AlwaysFHao/TiM4Rec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-based SPARQL Query Generation from Natural Language over Federated
  Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a Retrieval-Augmented Generation (RAG) system for translating
user questions into accurate federated SPARQL queries over bioinformatics
knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance
accuracy and reduce hallucinations in query generation, our system utilises
metadata from the KGs, including query examples and schema information, and
incorporates a validation step to correct generated queries. The system is
available online at chat.expasy.org.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cryptanalysis of the SIMON Cypher Using Neo4j <span class="chip">CEC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04735v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04735v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Cook, Sabih ur Rehman, M. Arif Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential growth in the number of Internet of Things (IoT) devices has
seen the introduction of several Lightweight Encryption Algorithms (LEA). While
LEAs are designed to enhance the integrity, privacy and security of data
collected and transmitted by IoT devices, it is hazardous to assume that all
LEAs are secure and exhibit similar levels of protection. To improve encryption
strength, cryptanalysts and algorithm designers routinely probe LEAs using
various cryptanalysis techniques to identify vulnerabilities and limitations of
LEAs. Despite recent improvements in the efficiency of cryptanalysis utilising
heuristic methods and a Partial Difference Distribution Table (PDDT), the
process remains inefficient, with the random nature of the heuristic inhibiting
reproducible results. However, the use of a PDDT presents opportunities to
identify relationships between differentials utilising knowledge graphs,
leading to the identification of efficient paths throughout the PDDT. This
paper introduces the novel use of knowledge graphs to identify intricate
relationships between differentials in the SIMON LEA, allowing for the
identification of optimal paths throughout the differentials, and increasing
the effectiveness of the differential security analyses of SIMON.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>J. Cook, S. u. Rehman and M. A. Khan, "Cryptanalysis of the SIMON
  Cypher Using Neo4j," 2024 International Conference on Electrical, Computer
  and Energy Technologies (ICECET, Sydney, Australia, 2024, pp. 1-6, doi:
  10.1109/ICECET61485.2024.10698687. 979-8-3503-9591-4/24/$31.00
  \c{opyright}2024 IEEE https://ieeexplore.ieee.org/document/10698687</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HiNet: Novel Multi-Scenario & Multi-Task Learning with Hierarchical
  Information Extraction <span class="chip">ICDE2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.06095v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.06095v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Zhou, Xianshuai Cao, Wenhao Li, Lin Bo, Kun Zhang, Chuan Luo, Qian Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-scenario & multi-task learning has been widely applied to many
recommendation systems in industrial applications, wherein an effective and
practical approach is to carry out multi-scenario transfer learning on the
basis of the Mixture-of-Expert (MoE) architecture. However, the MoE-based
method, which aims to project all information in the same feature space, cannot
effectively deal with the complex relationships inherent among various
scenarios and tasks, resulting in unsatisfactory performance. To tackle the
problem, we propose a Hierarchical information extraction Network (HiNet) for
multi-scenario and multi-task recommendation, which achieves hierarchical
extraction based on coarse-to-fine knowledge transfer scheme. The multiple
extraction layers of the hierarchical network enable the model to enhance the
capability of transferring valuable information across scenarios while
preserving specific features of scenarios and tasks. Furthermore, a novel
scenario-aware attentive network module is proposed to model correlations
between scenarios explicitly. Comprehensive experiments conducted on real-world
industrial datasets from Meituan Meishi platform demonstrate that HiNet
achieves a new state-of-the-art performance and significantly outperforms
existing solutions. HiNet is currently fully deployed in two scenarios and has
achieved 2.87% and 1.75% order quantity gain respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper has been accepted by ICDE2023</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sample then Identify: A General Framework for Risk Control and
  Assessment in Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08174v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08174v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingni Wang, Tiantian Geng, Zhiyuan Wang, Teng Wang, Bo Fu, Feng Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) exhibit promising advancements
across various tasks, yet they still encounter significant trustworthiness
issues. Prior studies apply Split Conformal Prediction (SCP) in language
modeling to construct prediction sets with statistical guarantees. However,
these methods typically rely on internal model logits or are restricted to
multiple-choice settings, which hampers their generalizability and adaptability
in dynamic, open-ended environments. In this paper, we introduce TRON, a
two-step framework for risk control and assessment, applicable to any MLLM that
supports sampling in both open-ended and closed-ended scenarios. TRON comprises
two main components: (1) a novel conformal score to sample response sets of
minimum size, and (2) a nonconformity score to identify high-quality responses
based on self-consistency theory, controlling the error rates by two specific
risk levels. Furthermore, we investigate semantic redundancy in prediction sets
within open-ended contexts for the first time, leading to a promising
evaluation metric for MLLMs based on average set size. Our comprehensive
experiments across four Video Question-Answering (VideoQA) datasets utilizing
eight MLLMs show that TRON achieves desired error rates bounded by two
user-specified risk levels. Additionally, deduplicated prediction sets maintain
adaptiveness while being more efficient and stable for risk assessment under
different risk levels.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HeGraphAdapter: Tuning Multi-Modal Vision-Language Models with
  Heterogeneous Graph Adapter 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07854v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07854v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yumiao Zhao, Bo Jiang, Xiao Wang, Qin Xu, Jin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adapter-based tuning methods have shown significant potential in transferring
knowledge from pre-trained Vision-Language Models to the downstream tasks.
However, after reviewing existing adapters, we find they generally fail to
fully explore the interactions between different modalities in constructing
task-specific knowledge. Also, existing works usually only focus on similarity
matching between positive text prompts, making it challenging to distinguish
the classes with high similar visual contents. To address these issues, in this
paper, we propose a novel Heterogeneous Graph Adapter to achieve tuning VLMs
for the downstream tasks. To be specific, we first construct a unified
heterogeneous graph mode, which contains i) visual nodes, positive text nodes
and negative text nodes, and ii) several types of edge connections to
comprehensively model the intra-modality, inter-modality and inter-class
structure knowledge together. Next, we employ a specific Heterogeneous Graph
Neural Network to excavate multi-modality structure knowledge for adapting both
visual and textual features for the downstream tasks. Finally, after
HeGraphAdapter, we construct both text-based and visual-based classifiers
simultaneously to comprehensively enhance the performance of the CLIP model.
Experimental results on 11 benchmark datasets demonstrate the effectiveness and
benefits of the proposed HeGraphAdapter.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Food Portion Estimation via 3D Object Scaling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gautham Vinod, Jiangpeng He, Zeman Shao, Fengqing Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image-based methods to analyze food images have alleviated the user burden
and biases associated with traditional methods. However, accurate portion
estimation remains a major challenge due to the loss of 3D information in the
2D representation of foods captured by smartphone cameras or wearable devices.
In this paper, we propose a new framework to estimate both food volume and
energy from 2D images by leveraging the power of 3D food models and physical
reference in the eating scene. Our method estimates the pose of the camera and
the food object in the input image and recreates the eating occasion by
rendering an image of a 3D model of the food with the estimated poses. We also
introduce a new dataset, SimpleFood45, which contains 2D images of 45 food
items and associated annotations including food volume, weight, and energy. Our
method achieves an average error of 31.10 kCal (17.67%) on this dataset,
outperforming existing portion estimation methods. The dataset can be accessed
at: https://lorenz.ecn.purdue.edu/~gvinod/simplefood45/ and the code can be
accessed at: https://gitlab.com/viper-purdue/monocular-food-volume-3d
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking VLMs' Reasoning About Persuasive Atypical Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10719v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10719v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sina Malakouti, Aysan Aghazadeh, Ashmit Khandelwal, Adriana Kovashka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision language models (VLMs) have shown strong zero-shot generalization
across various tasks, especially when integrated with large language models
(LLMs). However, their ability to comprehend rhetorical and persuasive visual
media, such as advertisements, remains understudied. Ads often employ atypical
imagery, using surprising object juxtapositions to convey shared properties.
For example, Fig. 1 (e) shows a beer with a feather-like texture. This requires
advanced reasoning to deduce that this atypical representation signifies the
beer's lightness. We introduce three novel tasks, Multi-label Atypicality
Classification, Atypicality Statement Retrieval, and Aypical Object
Recognition, to benchmark VLMs' understanding of atypicality in persuasive
images. We evaluate how well VLMs use atypicality to infer an ad's message and
test their reasoning abilities by employing semantically challenging negatives.
Finally, we pioneer atypicality-aware verbalization by extracting comprehensive
image descriptions sensitive to atypical elements. Our findings reveal that:
(1) VLMs lack advanced reasoning capabilities compared to LLMs; (2) simple,
effective strategies can extract atypicality-aware information, leading to
comprehensive image verbalization; (3) atypicality aids persuasive
advertisement understanding. Code and data will be made available.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-09T00:00:00Z">2024-10-09</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">19</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploiting Distribution Constraints for Scalable and Efficient Image
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Omama, Po-han Li, Sandeep P. Chinchali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image retrieval is crucial in robotics and computer vision, with downstream
applications in robot place recognition and vision-based product
recommendations. Modern retrieval systems face two key challenges: scalability
and efficiency. State-of-the-art image retrieval systems train specific neural
networks for each dataset, an approach that lacks scalability. Furthermore,
since retrieval speed is directly proportional to embedding size, existing
systems that use large embeddings lack efficiency. To tackle scalability,
recent works propose using off-the-shelf foundation models. However, these
models, though applicable across datasets, fall short in achieving performance
comparable to that of dataset-specific models. Our key observation is that,
while foundation models capture necessary subtleties for effective retrieval,
the underlying distribution of their embedding space can negatively impact
cosine similarity searches. We introduce Autoencoders with Strong Variance
Constraints (AE-SVC), which, when used for projection, significantly improves
the performance of foundation models. We provide an in-depth theoretical
analysis of AE-SVC. Addressing efficiency, we introduce Single-shot Similarity
Space Distillation ((SS)$_2$D), a novel approach to learn embeddings with
adaptive sizes that offers a better trade-off between size and performance. We
conducted extensive experiments on four retrieval datasets, including Stanford
Online Products (SoP) and Pittsburgh30k, using four different off-the-shelf
foundation models, including DinoV2 and CLIP. AE-SVC demonstrates up to a
$16\%$ improvement in retrieval performance, while (SS)$_2$D shows a further
$10\%$ improvement for smaller embedding sizes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An <span class="highlight-title">Overview</span> of zbMATH Open Digital Library 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06948v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06948v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Madhurima Deb, Isabel Beckenbach, Matteo Petrera, Dariush Ehsani, Marcel Fuhrmann, Yun Hao, Olaf Teschke, Moritz Schubotz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical research thrives on the effective dissemination and discovery of
knowledge.
  zbMATH Open has emerged as a pivotal platform in this landscape, offering a
comprehensive repository of mathematical literature. Beyond indexing and
abstracting, it serves as a unified quality-assured infrastructure for finding,
evaluating, and connecting mathematical information that advances mathematical
research as well as interdisciplinary exploration. zbMATH Open enables
scientific quality control by post-publication reviews and promotes connections
between researchers, institutions, and research outputs. This paper represents
the functionalities of the most significant features of this open-access
service, highlighting its role in shaping the future of mathematical
information retrieval.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performance Evaluation in Multimedia Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06654v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06654v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loris Sauter, Ralph Gasser, Heiko Schuldt, Abraham Bernstein, Luca Rossetto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Performance evaluation in multimedia retrieval, as in the information
retrieval domain at large, relies heavily on retrieval experiments, employing a
broad range of techniques and metrics. These can involve human-in-the-loop and
machine-only settings for the retrieval process itself and the subsequent
verification of results. Such experiments can be elaborate and
use-case-specific, which can make them difficult to compare or replicate. In
this paper, we present a formal model to express all relevant aspects of such
retrieval experiments, as well as a flexible open-source evaluation
infrastructure that implements the model. These contributions intend to make a
step towards lowering the hurdles for conducting retrieval experiments and
improving their reproducibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Does Vec2Text Pose a New Corpus Poisoning Threat? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengyao Zhuang, Bevan Koopman, Guido Zuccon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of Vec2Text -- a method for text embedding inversion -- has
raised serious privacy concerns for dense retrieval systems which use text
embeddings. This threat comes from the ability for an attacker with access to
embeddings to reconstruct the original text. In this paper, we take a new look
at Vec2Text and investigate how much of a threat it poses to the different
attacks of corpus poisoning, whereby an attacker injects adversarial passages
into a retrieval corpus with the intention of misleading dense retrievers.
Theoretically, Vec2Text is far more dangerous than previous attack methods
because it does not need access to the embedding model's weights and it can
efficiently generate many adversarial passages. We show that under certain
conditions, corpus poisoning with Vec2Text can pose a serious threat to dense
retriever system integrity and user experience by injecting adversarial
passaged into top ranked positions. Code and data are made available at
https://github.com/ielab/vec2text-corpus-poisoning
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2402.12784</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decomposing Relationship from 1-to-N into N 1-to-1 for Text-Video
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xiao, Zhenzhen Hu, Jia Li, Richang Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-video retrieval (TVR) has seen substantial advancements in recent years,
fueled by the utilization of pre-trained models and large language models
(LLMs). Despite these advancements, achieving accurate matching in TVR remains
challenging due to inherent disparities between video and textual modalities
and irregularities in data representation. In this paper, we propose
Text-Video-ProxyNet (TV-ProxyNet), a novel framework designed to decompose the
conventional 1-to-N relationship of TVR into N distinct 1-to-1 relationships.
By replacing a single text query with a series of text proxies, TV-ProxyNet not
only broadens the query scope but also achieves a more precise expansion. Each
text proxy is crafted through a refined iterative process, controlled by
mechanisms we term as the director and dash, which regulate the proxy's
direction and distance relative to the original text query. This setup not only
facilitates more precise semantic alignment but also effectively manages the
disparities and noise inherent in multimodal data. Our experiments on three
representative video-text retrieval benchmarks, MSRVTT, DiDeMo, and ActivityNet
Captions, demonstrate the effectiveness of TV-ProxyNet. The results show an
improvement of 2.0% to 3.3% in R@1 over the baseline. TV-ProxyNet achieved
state-of-the-art performance on MSRVTT and ActivityNet Captions, and a 2.0%
improvement on DiDeMo compared to existing methods, validating our approach's
ability to enhance semantic mapping and reduce error propensity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Legal Case Retrieval via Scaling High-quality Synthetic
  Query-Candidate Pairs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06581v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06581v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Gao, Chaojun Xiao, Zhenghao Liu, Huimin Chen, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal case retrieval (LCR) aims to provide similar cases as references for a
given fact description. This task is crucial for promoting consistent judgments
in similar cases, effectively enhancing judicial fairness and improving work
efficiency for judges. However, existing works face two main challenges for
real-world applications: existing works mainly focus on case-to-case retrieval
using lengthy queries, which does not match real-world scenarios; and the
limited data scale, with current datasets containing only hundreds of queries,
is insufficient to satisfy the training requirements of existing data-hungry
neural models. To address these issues, we introduce an automated method to
construct synthetic query-candidate pairs and build the largest LCR dataset to
date, LEAD, which is hundreds of times larger than existing datasets. This data
construction method can provide ample training signals for LCR models.
Experimental results demonstrate that model training with our constructed data
can achieve state-of-the-art results on two widely-used LCR benchmarks.
Besides, the construction method can also be applied to civil cases and achieve
promising results. The data and codes can be found in
https://github.com/thunlp/LEAD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 3 figures, accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Recommender Systems with Soft Target: A Decoupled Perspective <span class="chip">DASFAA 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06536v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06536v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhang, Mingyue Cheng, Qi Liu, Yucong Luo, Rui Li, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning recommender systems with multi-class optimization objective is a
prevalent setting in recommendation. However, as observed user feedback often
accounts for a tiny fraction of the entire item pool, the standard Softmax loss
tends to ignore the difference between potential positive feedback and truly
negative feedback. To address this challenge, we propose a novel decoupled soft
label optimization framework to consider the objectives as two aspects by
leveraging soft labels, including target confidence and the latent interest
distribution of non-target items. Futhermore, based on our carefully
theoretical analysis, we design a decoupled loss function to flexibly adjust
the importance of these two aspects. To maximize the performance of the
proposed method, we additionally present a sensible soft-label generation
algorithm that models a label propagation algorithm to explore users' latent
interests in unobserved feedback via neighbors. We conduct extensive
experiments on various recommendation system models and public datasets, the
results demonstrate the effectiveness and generality of the proposed method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by DASFAA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Post-Userist Recommender Systems : A Manifesto <span class="chip">RecSys</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11870v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11870v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin Burke, Morgan Sylvester
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We define userist recommendation as an approach to recommender systems framed
solely in terms of the relation between the user and system. Post-userist
recommendation posits a larger field of relations in which stakeholders are
embedded and distinguishes the recommendation function (which can potentially
connect creators with audiences) from generative media. We argue that in the
era of generative media, userist recommendation becomes indistinguishable from
personalized media generation, and therefore post-userist recommendation is the
only path forward for recommender systems research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended abstract for paper presented at AltRecSys Workshop 2024.
  Held at the 18th ACM Conference on Recommender Systems, Bari, Italy. October
  18, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ERCache: An Efficient and Reliable Caching Framework for Large-Scale
  User Representations in Meta's Ads System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fang Zhou, Yaning Huang, Dong Liang, Dai Li, Zhongke Zhang, Kai Wang, Xiao Xin, Abdallah Aboelela, Zheliang Jiang, Yang Wang, Jeff Song, Wei Zhang, Chen Liang, Huayu Li, ChongLin Sun, Hang Yang, Lei Qu, Zhan Shu, Mindi Yuan, Emanuele Maccherani, Taha Hayat, John Guo, Varna Puvvada, Uladzimir Pashkevich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing complexity of deep learning models used for calculating user
representations presents significant challenges, particularly with limited
computational resources and strict service-level agreements (SLAs). Previous
research efforts have focused on optimizing model inference but have overlooked
a critical question: is it necessary to perform user model inference for every
ad request in large-scale social networks? To address this question and these
challenges, we first analyze user access patterns at Meta and find that most
user model inferences occur within a short timeframe. T his observation reveals
a triangular relationship among model complexity, embedding freshness, and
service SLAs. Building on this insight, we designed, implemented, and evaluated
ERCache, an efficient and robust caching framework for large-scale user
representations in ads recommendation systems on social networks. ERCache
categorizes cache into direct and failover types and applies customized
settings and eviction policies for each model, effectively balancing model
complexity, embedding freshness, and service SLAs, even considering the
staleness introduced by caching. ERCache has been deployed at Meta for over six
months, supporting more than 30 ranking models while efficiently conserving
computational resources and complying with service SLA requirements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Categorizing Social Media Screenshots for Identifying Author
  Misattribution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06443v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06443v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashlyn M. Farris, Michael L. Nelson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mis/disinformation is a common and dangerous occurrence on social media.
Misattribution is a form of mis/disinformation that deals with a false claim of
authorship, which means a user is claiming someone said (posted) something they
never did. We discuss the difference between misinformation and disinformation
and how screenshots are used to spread author misattribution on social media
platforms. It is important to be able to find the original post of a screenshot
to determine if the screenshot is being correctly attributed. To do this we
have built several tools to aid in automating this search process. The first is
a Python script that aims to categorize Twitter posts based on their structure,
extract the metadata from a screenshot, and use this data to group all the
posts within a screenshot together. We tested this process on 75 Twitter posts
containing screenshots collected by hand to determine how well the script
extracted metadata and grouped the individual posts, F1 = 0.80. The second is a
series of scrapers being used to collect a dataset that can train and test a
model to differentiate between various social media platforms. We collected
16,620 screenshots have been collected from Facebook, Instagram, Truth Social,
and Twitter. Screenshots were taken by the scrapers of the web version and
mobile version of each platform in both light and dark mode.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Web Retrieval Agents for Evidence-Based Misinformation Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00009v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00009v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob-Junqi Tian, Hao Yu, Yury Orlovskiy, Tyler Vergho, Mauricio Rivera, Mayank Goel, Zachary Yang, Jean-Francois Godbout, Reihaneh Rabbany, Kellin Pelrine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper develops an agent-based automated fact-checking approach for
detecting misinformation. We demonstrate that combining a powerful LLM agent,
which does not have access to the internet for searches, with an online web
search agent yields better results than when each tool is used independently.
Our approach is robust across multiple models, outperforming alternatives and
increasing the macro F1 of misinformation detection by as much as 20 percent
compared to LLMs without search. We also conduct extensive analyses on the
sources our system leverages and their biases, decisions in the construction of
the system like the search tool and the knowledge base, the type of evidence
needed and its impact on the results, and other parts of the overall process.
By combining strong performance with in-depth understanding, we hope to provide
building blocks for future search-enabled misinformation mitigation systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>1 main figure, 8 tables, 10 pages, 12 figures in Appendix, 7 tables
  in Appendix GitHub URL: https://github.com/ComplexData-MILA/webretrieval</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized <span class="highlight-title">Prompt</span> for Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2205.09666v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2205.09666v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqing Wu, Ruobing Xie, Yongchun Zhu, Fuzhen Zhuang, Xu Zhang, Leyu Lin, Qing He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-training models have shown their power in sequential recommendation.
Recently, prompt has been widely explored and verified for tuning in NLP
pre-training, which could help to more effectively and efficiently extract
useful knowledge from pre-training models for downstream tasks, especially in
cold-start scenarios. However, it is challenging to bring prompt-tuning from
NLP to recommendation, since the tokens in recommendation (i.e., items) do not
have explicit explainable semantics, and the sequence modeling should be
personalized. In this work, we first introduces prompt to recommendation and
propose a novel Personalized prompt-based recommendation (PPR) framework for
cold-start recommendation. Specifically, we build the personalized soft prefix
prompt via a prompt generator based on user profiles and enable a sufficient
training of prompts via a prompt-oriented contrastive learning with both
prompt- and behavior-based augmentations. We conduct extensive evaluations on
various tasks. In both few-shot and zero-shot recommendation, PPR models
achieve significant improvements over baselines on various metrics in three
large-scale open datasets. We also conduct ablation tests and sparsity analysis
for a better understanding of PPR. Moreover, We further verify PPR's
universality on different pre-training models, and conduct explorations on
PPR's other promising downstream tasks including cross-domain recommendation
and user profile prediction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by TKDE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploiting Positional Bias for Query-Agnostic Generative Content in
  Search <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00469v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00469v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Parry, Sean MacAvaney, Debasis Ganguly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, neural ranking models (NRMs) have been shown to
substantially outperform their lexical counterparts in text retrieval. In
traditional search pipelines, a combination of features leads to well-defined
behaviour. However, as neural approaches become increasingly prevalent as the
final scoring component of engines or as standalone systems, their robustness
to malicious text and, more generally, semantic perturbation needs to be better
understood. We posit that the transformer attention mechanism can induce
exploitable defects through positional bias in search models, leading to an
attack that could generalise beyond a single query or topic. We demonstrate
such defects by showing that non-relevant text--such as promotional
content--can be easily injected into a document without adversely affecting its
position in search results. Unlike previous gradient-based attacks, we
demonstrate these biases in a query-agnostic fashion. In doing so, without the
knowledge of topicality, we can still reduce the negative effects of
non-relevant content injection by controlling injection position. Our
experiments are conducted with simulated on-topic promotional text
automatically generated by prompting LLMs with topical context from target
documents. We find that contextualisation of a non-relevant text further
reduces negative effects whilst likely circumventing existing content filtering
mechanisms. In contrast, lexical models are found to be more resilient to such
content injection attacks. We then investigate a simple yet effective
compensation for the weaknesses of the NRMs in search, validating our
hypotheses regarding transformer bias.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 main figures, 7 appendix pages, 2 appendix figures,
  Accepted to ACL 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Deep Tree-based Retriever for Efficient Recommendation: Theory
  and Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11345v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11345v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ze Liu, Jin Zhang, Chao Feng, Defu Lian, Jie Wang, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although advancements in deep learning have significantly enhanced the
recommendation accuracy of deep recommendation models, these methods still
suffer from low recommendation efficiency. Recently proposed tree-based deep
recommendation models alleviate the problem by directly learning tree structure
and representations under the guidance of recommendation objectives. To
guarantee the effectiveness of beam search for recommendation accuracy, these
models strive to ensure that the tree adheres to the max-heap assumption, where
a parent node's preference should be the maximum among its children's
preferences. However, they employ a one-versus-all strategy, framing the
training task as a series of independent binary classification objectives for
each node, which limits their ability to fully satisfy the max-heap assumption.
To this end, we propose a Deep Tree-based Retriever (DTR for short) for
efficient recommendation. DTR frames the training task as a softmax-based
multi-class classification over tree nodes at the same level, enabling explicit
horizontal competition and more discriminative top-k selection among them,
which mimics the beam search behavior during training. To mitigate the
suboptimality induced by the labeling of non-leaf nodes, we propose a
rectification method for the loss function, which further aligns with the
max-heap assumption in expectation. As the number of tree nodes grows
exponentially with the levels, we employ sampled softmax to approximate
optimization and thereby enhance efficiency. Furthermore, we propose a
tree-based sampling method to reduce the bias inherent in sampled softmax.
Theoretical results reveal DTR's generalization capability, and both the
rectification method and tree-based sampling contribute to improved
generalization. The experiments are conducted on four real-world datasets,
validating the effectiveness of the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06096v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06096v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michele Mancusi, Yurii Halychanskyi, Kin Wai Cheuk, Chieh-Hsin Lai, Stefan Uhlich, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Yuki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music timbre transfer is a challenging task that involves modifying the
timbral characteristics of an audio signal while preserving its melodic
structure. In this paper, we propose a novel method based on dual diffusion
bridges, trained using the CocoChorales Dataset, which consists of unpaired
monophonic single-instrument audio data. Each diffusion model is trained on a
specific instrument with a Gaussian prior. During inference, a model is
designated as the source model to map the input audio to its corresponding
Gaussian prior, and another model is designated as the target model to
reconstruct the target audio from this Gaussian prior, thereby facilitating
timbre transfer. We compare our approach against existing unsupervised timbre
transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental
results demonstrate that our method achieves both better Fr\'echet Audio
Distance (FAD) and melody preservation, as reflected by lower pitch distances
(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise
level from the Gaussian prior, $\sigma$, can be adjusted to control the degree
of melody preservation and amount of timbre transferred.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FELLAS: Enhancing Federated Sequential Recommendation with LLM as
  External Services 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04927v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04927v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Yuan, Chaoqun Yang, Guanhua Ye, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated sequential recommendation (FedSeqRec) has gained growing attention
due to its ability to protect user privacy. Unfortunately, the performance of
FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to
be lightweight to accommodate communication bandwidth and clients' on-device
computational resource constraints. Recently, large language models (LLMs) have
exhibited strong transferable and generalized language understanding abilities
and therefore, in the NLP area, many downstream tasks now utilize LLMs as a
service to achieve superior performance without constructing complex models.
Inspired by this successful practice, we propose a generic FedSeqRec framework,
FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external
service. Specifically, FELLAS employs an LLM server to provide both item-level
and sequence-level representation assistance. The item-level representation
service is queried by the central server to enrich the original ID-based item
embedding with textual information, while the sequence-level representation
service is accessed by each client. However, invoking the sequence-level
representation service requires clients to send sequences to the external LLM
server. To safeguard privacy, we implement dx-privacy satisfied sequence
perturbation, which protects clients' sensitive data with guarantees.
Additionally, a contrastive learning-based method is designed to transfer
knowledge from the noisy sequence representation to clients' sequential
recommendation models. Furthermore, to empirically validate the privacy
protection capability of FELLAS, we propose two interacted item inference
attacks. Extensive experiments conducted on three datasets with two widely used
sequential recommendation models demonstrate the effectiveness and
privacy-preserving capability of FELLAS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RankSHAP: Shapley Value Based Feature Attributions for Learning to Rank 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01848v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01848v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tanya Chowdhury, Yair Zick, James Allan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous works propose post-hoc, model-agnostic explanations for learning to
rank, focusing on ordering entities by their relevance to a query through
feature attribution methods. However, these attributions often weakly correlate
or contradict each other, confusing end users. We adopt an axiomatic
game-theoretic approach, popular in the feature attribution community, to
identify a set of fundamental axioms that every ranking-based feature
attribution method should satisfy. We then introduce Rank-SHAP, extending
classical Shapley values to ranking. We evaluate the RankSHAP framework through
extensive experiments on two datasets, multiple ranking methods and evaluation
metrics. Additionally, a user study confirms RankSHAP's alignment with human
intuition. We also perform an axiomatic analysis of existing rank attribution
algorithms to determine their compliance with our proposed axioms. Ultimately,
our aim is to equip practitioners with a set of axiomatically backed feature
attribution methods for studying IR ranking models, that ensure generality as
well as consistency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UpDLRM: Accelerating Personalized Recommendation using Real-World PIM
  Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13941v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13941v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sitian Chen, Haobin Tan, Amelie Chi Zhou, Yusen Li, Pavan Balaji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Learning Recommendation Models (DLRMs) have gained popularity in
recommendation systems due to their effectiveness in handling large-scale
recommendation tasks. The embedding layers of DLRMs have become the performance
bottleneck due to their intensive needs on memory capacity and memory
bandwidth. In this paper, we propose UpDLRM, which utilizes real-world
processingin-memory (PIM) hardware, UPMEM DPU, to boost the memory bandwidth
and reduce recommendation latency. The parallel nature of the DPU memory can
provide high aggregated bandwidth for the large number of irregular memory
accesses in embedding lookups, thus offering great potential to reduce the
inference latency. To fully utilize the DPU memory bandwidth, we further
studied the embedding table partitioning problem to achieve good
workload-balance and efficient data caching. Evaluations using real-world
datasets show that, UpDLRM achieves much lower inference time for DLRM compared
to both CPU-only and CPU-GPU hybrid counterparts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by DAC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SR-PredictAO: Session-based Recommendation with High-Capability
  Predictor Add-On 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12218v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12218v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruida Wang, Raymond Chi-Wing Wong, Weile Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Session-based recommendation, aiming at making the prediction of the user's
next item click based on the information in a single session only, even in the
presence of some random user's behavior, is a complex problem. This complex
problem requires a high-capability model of predicting the user's next action.
Most (if not all) existing models follow the encoder-predictor paradigm where
all studies focus on how to optimize the encoder module extensively in the
paradigm, but they overlook how to optimize the predictor module. In this
paper, we discover the critical issue of the low-capability predictor module
among existing models. Motivated by this, we propose a novel framework called
*Session-based Recommendation with Predictor Add-On* (SR-PredictAO). In this
framework, we propose a high-capability predictor module which could alleviate
the effect of random user's behavior for prediction. It is worth mentioning
that this framework could be applied to any existing models, which could give
opportunities for further optimizing the framework. Extensive experiments on
two real-world benchmark datasets for three state-of-the-art models show that
*SR-PredictAO* out-performs the current state-of-the-art model by up to 2.9% in
HR@20 and 2.3% in MRR@20. More importantly, the improvement is consistent
across almost all the existing models on all datasets, and is statistically
significant, which could be regarded as a significant contribution in the
field.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3D2M <span class="highlight-title">Dataset</span>: A 3-Dimension diverse Mesh <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07415v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07415v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sankarshan Dasgupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Three-dimensional (3D) reconstruction has emerged as a prominent area of
research, attracting significant attention from academia and industry alike.
Among the various applications of 3D reconstruction, facial reconstruction
poses some of the most formidable challenges. Additionally, each individuals
facial structure is unique, requiring algorithms to be robust enough to handle
this variability while maintaining fidelity to the original features. This
article presents a comprehensive dataset of 3D meshes featuring a diverse range
of facial structures and corresponding facial landmarks. The dataset comprises
188 3D facial meshes, including 73 from female candidates and 114 from male
candidates. It encompasses a broad representation of ethnic backgrounds, with
contributions from 45 different ethnicities, ensuring a rich diversity in
facial characteristics. Each facial mesh is accompanied by key points that
accurately annotate the relevant features, facilitating precise analysis and
manipulation. This dataset is particularly valuable for applications such as
facial re targeting, the study of facial structure components, and real-time
person representation in video streams. By providing a robust resource for
researchers and developers, it aims to advance the field of 3D facial
reconstruction and related technologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 1 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An undetectable watermark for generative image models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Gunn, Xuandong Zhao, Dawn Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the first undetectable watermarking scheme for generative image
models. Undetectability ensures that no efficient adversary can distinguish
between watermarked and un-watermarked images, even after making many adaptive
queries. In particular, an undetectable watermark does not degrade image
quality under any efficiently computable metric. Our scheme works by selecting
the initial latents of a diffusion model using a pseudorandom error-correcting
code (Christ and Gunn, 2024), a strategy which guarantees undetectability and
robustness. We experimentally demonstrate that our watermarks are
quality-preserving and robust using Stable Diffusion 2.1. Our experiments
verify that, in contrast to every prior scheme we tested, our watermark does
not degrade image quality. Our experiments also demonstrate robustness:
existing watermark removal attacks fail to remove our watermark from images
without significantly degrading the quality of the images. Finally, we find
that we can robustly encode 512 bits in our watermark, and up to 2500 bits when
the images are not subjected to watermark removal attacks. Our code is
available at https://github.com/XuandongZhao/PRC-Watermark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Positive-Augmented Contrastive Learning for Vision-and-Language
  Evaluation and Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.07336v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.07336v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Sarto, Nicholas Moratelli, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant advancements in caption generation, existing evaluation
metrics often fail to capture the full quality or fine-grained details of
captions. This is mainly due to their reliance on non-specific human-written
references or noisy pre-training data. Still, finding an effective metric is
crucial not only for captions evaluation but also for the generation phase.
Metrics can indeed play a key role in the fine-tuning stage of captioning
models, ultimately enhancing the quality of the generated captions. In this
paper, we propose PAC-S++, a learnable metric that leverages the CLIP model,
pre-trained on both web-collected and cleaned data and regularized through
additional pairs of generated visual and textual positive samples. Exploiting
this stronger and curated pre-training, we also apply PAC-S++ as a reward in
the Self-Critical Sequence Training (SCST) stage typically employed to
fine-tune captioning models. Extensive experiments on different image and video
datasets highlight the effectiveness of PAC-S++ compared to popular metrics for
the task, including its sensitivity to object hallucinations. Furthermore, we
show that integrating PAC-S++ into the fine-tuning stage of a captioning model
results in semantically richer captions with fewer repetitions and grammatical
errors. Evaluations on out-of-domain benchmarks further demonstrate the
efficacy of our fine-tuning approach in enhancing model capabilities. Source
code and trained models are publicly available at:
https://github.com/aimagelab/pacscore.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Perceptual Quality Assessment of Octree-RAHT Encoded 3D Point Clouds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongshuai Duan, Honglei Su, Qi Liu, Hui Yuan, Wei Gao, Jiarun Song, Zhou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  No-reference bitstream-layer point cloud quality assessment (PCQA) can be
deployed without full decoding at any network node to achieve real-time quality
monitoring. In this work, we focus on the PCQA problem dedicated to Octree-RAHT
encoding mode. First, to address the issue that existing PCQA databases have a
small scale and limited distortion levels, we establish the WPC5.0 database
which is the first one dedicated to Octree-RAHT encoding mode with a scale of
400 distorted point clouds (PCs) including 4 geometric multiplied by 5 attitude
distortion levels. Then, we propose the first PCQA model dedicated to
Octree-RAHT encoding mode by parsing PC bitstreams without full decoding. The
model introduces texture bitrate (TBPP) to predict texture complexity (TC) and
further derives the texture distortion factor. In addition, the Geometric
Quantization Parameter (PQS) is used to estimate the geometric distortion
factor, which is then integrated into the model along with the texture
distortion factor to obtain the proposed PCQA model named streamPCQ-OR. The
proposed model has been compared with other advanced PCQA methods on the
WPC5.0, BASICS and M-PCCD databases, and experimental results show that our
model has excellent performance while having very low computational complexity,
providing a reliable choice for time-critical applications. To facilitate
subsequent research, the database and source code will be publicly released at
https://github.com/qdushl/Waterloo-Point-Cloud-Database-5.0.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating the Impact of Point Cloud Colorization on Semantic
  Segmentation Accuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinfeng Zhu, Jiaze Cao, Yuanzhi Cai, Lei Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Point cloud semantic segmentation, the process of classifying each point into
predefined categories, is essential for 3D scene understanding. While
image-based segmentation is widely adopted due to its maturity, methods relying
solely on RGB information often suffer from degraded performance due to color
inaccuracies. Recent advancements have incorporated additional features such as
intensity and geometric information, yet RGB channels continue to negatively
impact segmentation accuracy when errors in colorization occur. Despite this,
previous studies have not rigorously quantified the effects of erroneous
colorization on segmentation performance. In this paper, we propose a novel
statistical approach to evaluate the impact of inaccurate RGB information on
image-based point cloud segmentation. We categorize RGB inaccuracies into two
types: incorrect color information and similar color information. Our results
demonstrate that both types of color inaccuracies significantly degrade
segmentation accuracy, with similar color errors particularly affecting the
extraction of geometric features. These findings highlight the critical need to
reassess the role of RGB information in point cloud segmentation and its
implications for future algorithm design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by 2024 IEEE 8th International Conference on Vision, Image
  and Signal Processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performance Evaluation in Multimedia Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06654v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06654v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Loris Sauter, Ralph Gasser, Heiko Schuldt, Abraham Bernstein, Luca Rossetto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Performance evaluation in multimedia retrieval, as in the information
retrieval domain at large, relies heavily on retrieval experiments, employing a
broad range of techniques and metrics. These can involve human-in-the-loop and
machine-only settings for the retrieval process itself and the subsequent
verification of results. Such experiments can be elaborate and
use-case-specific, which can make them difficult to compare or replicate. In
this paper, we present a formal model to express all relevant aspects of such
retrieval experiments, as well as a flexible open-source evaluation
infrastructure that implements the model. These contributions intend to make a
step towards lowering the hurdles for conducting retrieval experiments and
improving their reproducibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decomposing Relationship from 1-to-N into N 1-to-1 for Text-Video
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xiao, Zhenzhen Hu, Jia Li, Richang Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-video retrieval (TVR) has seen substantial advancements in recent years,
fueled by the utilization of pre-trained models and large language models
(LLMs). Despite these advancements, achieving accurate matching in TVR remains
challenging due to inherent disparities between video and textual modalities
and irregularities in data representation. In this paper, we propose
Text-Video-ProxyNet (TV-ProxyNet), a novel framework designed to decompose the
conventional 1-to-N relationship of TVR into N distinct 1-to-1 relationships.
By replacing a single text query with a series of text proxies, TV-ProxyNet not
only broadens the query scope but also achieves a more precise expansion. Each
text proxy is crafted through a refined iterative process, controlled by
mechanisms we term as the director and dash, which regulate the proxy's
direction and distance relative to the original text query. This setup not only
facilitates more precise semantic alignment but also effectively manages the
disparities and noise inherent in multimodal data. Our experiments on three
representative video-text retrieval benchmarks, MSRVTT, DiDeMo, and ActivityNet
Captions, demonstrate the effectiveness of TV-ProxyNet. The results show an
improvement of 2.0% to 3.3% in R@1 over the baseline. TV-ProxyNet achieved
state-of-the-art performance on MSRVTT and ActivityNet Captions, and a 2.0%
improvement on DiDeMo compared to existing methods, validating our approach's
ability to enhance semantic mapping and reduce error propensity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CMMD: Contrastive Multi-Modal Diffusion for Video-Audio Conditional
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05412v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05412v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruihan Yang, Hannes Gamper, Sebastian Braun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a multi-modal diffusion model tailored for the bi-directional
conditional generation of video and audio. We propose a joint contrastive
training loss to improve the synchronization between visual and auditory
occurrences. We present experiments on two datasets to evaluate the efficacy of
our proposed model. The assessment of generation quality and alignment
performance is carried out from various angles, encompassing both objective and
subjective metrics. Our findings demonstrate that the proposed model
outperforms the baseline in terms of quality and generation speed through
introduction of our novel cross-modal easy fusion architectural block.
Furthermore, the incorporation of the contrastive loss results in improvements
in audio-visual alignment, particularly in the high-correlation video-to-audio
generation task.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-10-17T05:27:33.440866081Z">
            2024-10-17 05:27:33 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
